Index: app/src/main/java/com/example/webrtc/android/ConnectActivity.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>/*\r\n *  Copyright 2014 The WebRTC Project Authors. All rights reserved.\r\n *\r\n *  Use of this source code is governed by a BSD-style license\r\n *  that can be found in the LICENSE file in the root of the source\r\n *  tree. An additional intellectual property rights grant can be found\r\n *  in the file PATENTS.  All contributing project authors may\r\n *  be found in the AUTHORS file in the root of the source tree.\r\n */\r\n\r\npackage com.example.webrtc.android;\r\n\r\nimport android.Manifest;\r\nimport android.app.AlertDialog;\r\nimport android.content.Context;\r\nimport android.content.DialogInterface;\r\nimport android.content.Intent;\r\nimport android.content.SharedPreferences;\r\nimport android.content.pm.PackageManager;\r\nimport android.net.Uri;\r\nimport android.os.Bundle;\r\nimport android.preference.PreferenceManager;\r\nimport androidx.core.app.ActivityCompat;\r\nimport androidx.appcompat.app.AppCompatActivity;\r\nimport android.util.Log;\r\nimport android.view.ContextMenu;\r\nimport android.view.KeyEvent;\r\nimport android.view.Menu;\r\nimport android.view.MenuItem;\r\nimport android.view.View;\r\nimport android.view.View.OnClickListener;\r\nimport android.view.inputmethod.EditorInfo;\r\nimport android.webkit.URLUtil;\r\nimport android.widget.AdapterView;\r\nimport android.widget.ArrayAdapter;\r\nimport android.widget.EditText;\r\nimport android.widget.ImageButton;\r\nimport android.widget.ListView;\r\nimport android.widget.TextView;\r\nimport android.widget.Toast;\r\n\r\nimport java.util.ArrayList;\r\nimport java.util.Random;\r\n\r\nimport org.appspot.apprtc.ui.SettingsActivity;\r\nimport org.json.JSONArray;\r\nimport org.json.JSONException;\r\n\r\n\r\n/**\r\n * Handles the initial setup where the user selects which room to join.\r\n */\r\npublic class ConnectActivity extends AppCompatActivity {\r\n  private static final String TAG = \"ConnectActivity\";\r\n  private static final int CONNECTION_REQUEST = 1;\r\n  private static final int REMOVE_FAVORITE_INDEX = 0;\r\n  private static boolean commandLineRun = false;\r\n\r\n  private ImageButton addFavoriteButton;\r\n  private EditText roomEditText;\r\n  private ListView roomListView;\r\n  private SharedPreferences sharedPref;\r\n  private String keyprefResolution;\r\n  private String keyprefFps;\r\n  private String keyprefVideoBitrateType;\r\n  private String keyprefVideoBitrateValue;\r\n  private String keyprefAudioBitrateType;\r\n  private String keyprefAudioBitrateValue;\r\n  private String keyprefRoomServerUrl;\r\n  private String keyprefRoom;\r\n  private String keyprefRoomList;\r\n  private ArrayList<String> roomList;\r\n  private ArrayAdapter<String> adapter;\r\n\r\n  @Override\r\n  public void onCreate(Bundle savedInstanceState) {\r\n    super.onCreate(savedInstanceState);\r\n\r\n    // Get setting keys.\r\n    PreferenceManager.setDefaultValues(this, org.appspot.apprtc.R.xml.preferences, false);\r\n    sharedPref = PreferenceManager.getDefaultSharedPreferences(this);\r\n    keyprefResolution = getString(org.appspot.apprtc.R.string.pref_resolution_key);\r\n    keyprefFps = getString(org.appspot.apprtc.R.string.pref_fps_key);\r\n    keyprefVideoBitrateType = getString(org.appspot.apprtc.R.string.pref_maxvideobitrate_key);\r\n    keyprefVideoBitrateValue = getString(org.appspot.apprtc.R.string.pref_maxvideobitratevalue_key);\r\n    keyprefAudioBitrateType = getString(org.appspot.apprtc.R.string.pref_startaudiobitrate_key);\r\n    keyprefAudioBitrateValue = getString(org.appspot.apprtc.R.string.pref_startaudiobitratevalue_key);\r\n    keyprefRoomServerUrl = getString(org.appspot.apprtc.R.string.pref_room_server_url_key);\r\n    keyprefRoom = getString(org.appspot.apprtc.R.string.pref_room_key);\r\n    keyprefRoomList = getString(org.appspot.apprtc.R.string.pref_room_list_key);\r\n\r\n    setContentView(R.layout.activity_connect);\r\n\r\n    roomEditText = findViewById(R.id.room_edittext);\r\n    roomEditText.setOnEditorActionListener(new TextView.OnEditorActionListener() {\r\n      @Override\r\n      public boolean onEditorAction(TextView textView, int i, KeyEvent keyEvent) {\r\n        if (i == EditorInfo.IME_ACTION_DONE) {\r\n          addFavoriteButton.performClick();\r\n          return true;\r\n        }\r\n        return false;\r\n      }\r\n    });\r\n    roomEditText.requestFocus();\r\n\r\n    roomListView = findViewById(R.id.room_listview);\r\n    roomListView.setEmptyView(findViewById(android.R.id.empty));\r\n    roomListView.setOnItemClickListener(roomListClickListener);\r\n    registerForContextMenu(roomListView);\r\n    ImageButton connectButton = findViewById(R.id.connect_button);\r\n    connectButton.setOnClickListener(connectListener);\r\n    addFavoriteButton = findViewById(R.id.add_favorite_button);\r\n    addFavoriteButton.setOnClickListener(addFavoriteListener);\r\n\r\n    // If an implicit VIEW intent is launching the app, go directly to that URL.\r\n    final Intent intent = getIntent();\r\n    if (\"android.intent.action.VIEW\".equals(intent.getAction()) && !commandLineRun) {\r\n      boolean loopback = intent.getBooleanExtra(CallActivity.EXTRA_LOOPBACK, false);\r\n      int runTimeMs = intent.getIntExtra(CallActivity.EXTRA_RUNTIME, 0);\r\n      boolean useValuesFromIntent =\r\n          intent.getBooleanExtra(CallActivity.EXTRA_USE_VALUES_FROM_INTENT, false);\r\n      String room = sharedPref.getString(keyprefRoom, \"\");\r\n      connectToRoom(room, true, loopback, useValuesFromIntent, runTimeMs);\r\n    }\r\n  }\r\n\r\n  @Override\r\n  public boolean onCreateOptionsMenu(Menu menu) {\r\n    getMenuInflater().inflate(R.menu.connect_menu, menu);\r\n    return true;\r\n  }\r\n\r\n  @Override\r\n  public void onCreateContextMenu(ContextMenu menu, View v, ContextMenu.ContextMenuInfo menuInfo) {\r\n    if (v.getId() == R.id.room_listview) {\r\n      AdapterView.AdapterContextMenuInfo info = (AdapterView.AdapterContextMenuInfo) menuInfo;\r\n      menu.setHeaderTitle(roomList.get(info.position));\r\n      String[] menuItems = getResources().getStringArray(org.appspot.apprtc.R.array.roomListContextMenu);\r\n      for (int i = 0; i < menuItems.length; i++) {\r\n        menu.add(Menu.NONE, i, i, menuItems[i]);\r\n      }\r\n    } else {\r\n      super.onCreateContextMenu(menu, v, menuInfo);\r\n    }\r\n  }\r\n\r\n  @Override\r\n  public boolean onContextItemSelected(MenuItem item) {\r\n    if (item.getItemId() == REMOVE_FAVORITE_INDEX) {\r\n      AdapterView.AdapterContextMenuInfo info =\r\n          (AdapterView.AdapterContextMenuInfo) item.getMenuInfo();\r\n      roomList.remove(info.position);\r\n      adapter.notifyDataSetChanged();\r\n      return true;\r\n    }\r\n\r\n    return super.onContextItemSelected(item);\r\n  }\r\n\r\n  @Override\r\n  public boolean onOptionsItemSelected(MenuItem item) {\r\n    // Handle presses on the action bar items.\r\n    if (item.getItemId() == R.id.action_settings) {\r\n      Intent intent = new Intent(this, SettingsActivity.class);\r\n      startActivity(intent);\r\n      return true;\r\n    } else if (item.getItemId() == R.id.action_loopback) {\r\n      connectToRoom(null, false, true, false, 0);\r\n      return true;\r\n    } else {\r\n      return super.onOptionsItemSelected(item);\r\n    }\r\n  }\r\n\r\n  @Override\r\n  public void onPause() {\r\n    super.onPause();\r\n    String room = roomEditText.getText().toString();\r\n    String roomListJson = new JSONArray(roomList).toString();\r\n    SharedPreferences.Editor editor = sharedPref.edit();\r\n    editor.putString(keyprefRoom, room);\r\n    editor.putString(keyprefRoomList, roomListJson);\r\n    editor.commit();\r\n  }\r\n\r\n  @Override\r\n  public void onResume() {\r\n    super.onResume();\r\n    String room = sharedPref.getString(keyprefRoom, \"\");\r\n    roomEditText.setText(room);\r\n    roomList = new ArrayList<>();\r\n    String roomListJson = sharedPref.getString(keyprefRoomList, null);\r\n    if (roomListJson != null) {\r\n      try {\r\n        JSONArray jsonArray = new JSONArray(roomListJson);\r\n        for (int i = 0; i < jsonArray.length(); i++) {\r\n          roomList.add(jsonArray.get(i).toString());\r\n        }\r\n      } catch (JSONException e) {\r\n        Log.e(TAG, \"Failed to load room list: \" + e.toString());\r\n      }\r\n    }\r\n    adapter = new ArrayAdapter<>(this, android.R.layout.simple_list_item_1, roomList);\r\n    roomListView.setAdapter(adapter);\r\n    if (adapter.getCount() > 0) {\r\n      roomListView.requestFocus();\r\n      roomListView.setItemChecked(0, true);\r\n    }\r\n  }\r\n\r\n  @Override\r\n  protected void onActivityResult(int requestCode, int resultCode, Intent data) {\r\n    if (requestCode == CONNECTION_REQUEST && commandLineRun) {\r\n      Log.d(TAG, \"Return: \" + resultCode);\r\n      setResult(resultCode);\r\n      commandLineRun = false;\r\n      finish();\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Get a value from the shared preference or from the intent, if it does not\r\n   * exist the default is used.\r\n   */\r\n  private String sharedPrefGetString(\r\n      int attributeId, String intentName, int defaultId, boolean useFromIntent) {\r\n    String defaultValue = getString(defaultId);\r\n    if (useFromIntent) {\r\n      String value = getIntent().getStringExtra(intentName);\r\n      if (value != null) {\r\n        return value;\r\n      }\r\n      return defaultValue;\r\n    } else {\r\n      String attributeName = getString(attributeId);\r\n      return sharedPref.getString(attributeName, defaultValue);\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Get a value from the shared preference or from the intent, if it does not\r\n   * exist the default is used.\r\n   */\r\n  private boolean sharedPrefGetBoolean(\r\n      int attributeId, String intentName, int defaultId, boolean useFromIntent) {\r\n    boolean defaultValue = Boolean.parseBoolean(getString(defaultId));\r\n    if (useFromIntent) {\r\n      return getIntent().getBooleanExtra(intentName, defaultValue);\r\n    } else {\r\n      String attributeName = getString(attributeId);\r\n      return sharedPref.getBoolean(attributeName, defaultValue);\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Get a value from the shared preference or from the intent, if it does not\r\n   * exist the default is used.\r\n   */\r\n  private int sharedPrefGetInteger(\r\n      int attributeId, String intentName, int defaultId, boolean useFromIntent) {\r\n    String defaultString = getString(defaultId);\r\n    int defaultValue = Integer.parseInt(defaultString);\r\n    if (useFromIntent) {\r\n      return getIntent().getIntExtra(intentName, defaultValue);\r\n    } else {\r\n      String attributeName = getString(attributeId);\r\n      String value = sharedPref.getString(attributeName, defaultString);\r\n      try {\r\n        return Integer.parseInt(value);\r\n      } catch (NumberFormatException e) {\r\n        Log.e(TAG, \"Wrong setting for: \" + attributeName + \":\" + value);\r\n        return defaultValue;\r\n      }\r\n    }\r\n  }\r\n\r\n  @SuppressWarnings(\"StringSplitter\")\r\n  private void connectToRoom(String roomId, boolean commandLineRun, boolean loopback,\r\n      boolean useValuesFromIntent, int runTimeMs) {\r\n    ConnectActivity.commandLineRun = commandLineRun;\r\n\r\n    // roomId is random for loopback.\r\n    if (loopback) {\r\n      roomId = Integer.toString((new Random()).nextInt(100000000));\r\n    }\r\n\r\n    String roomUrl = sharedPref.getString(\r\n        keyprefRoomServerUrl, getString(org.appspot.apprtc.R.string.pref_room_server_url_default));\r\n\r\n    // Video call enabled flag.\r\n    boolean videoCallEnabled = sharedPrefGetBoolean(org.appspot.apprtc.R.string.pref_videocall_key,\r\n        CallActivity.EXTRA_VIDEO_CALL, org.appspot.apprtc.R.string.pref_videocall_default, useValuesFromIntent);\r\n\r\n    // Use screencapture option.\r\n    boolean useScreencapture = sharedPrefGetBoolean(org.appspot.apprtc.R.string.pref_screencapture_key,\r\n        CallActivity.EXTRA_SCREENCAPTURE, org.appspot.apprtc.R.string.pref_screencapture_default, useValuesFromIntent);\r\n\r\n    // Use Camera2 option.\r\n    boolean useCamera2 = sharedPrefGetBoolean(org.appspot.apprtc.R.string.pref_camera2_key, CallActivity.EXTRA_CAMERA2,\r\n        org.appspot.apprtc.R.string.pref_camera2_default, useValuesFromIntent);\r\n\r\n    // Get default codecs.\r\n    String videoCodec = sharedPrefGetString(org.appspot.apprtc.R.string.pref_videocodec_key,\r\n        CallActivity.EXTRA_VIDEOCODEC, org.appspot.apprtc.R.string.pref_videocodec_default, useValuesFromIntent);\r\n    String audioCodec = sharedPrefGetString(org.appspot.apprtc.R.string.pref_audiocodec_key,\r\n        CallActivity.EXTRA_AUDIOCODEC, org.appspot.apprtc.R.string.pref_audiocodec_default, useValuesFromIntent);\r\n\r\n    // Check HW codec flag.\r\n    boolean hwCodec = sharedPrefGetBoolean(org.appspot.apprtc.R.string.pref_hwcodec_key,\r\n        CallActivity.EXTRA_HWCODEC_ENABLED, org.appspot.apprtc.R.string.pref_hwcodec_default, useValuesFromIntent);\r\n\r\n    // Check Capture to texture.\r\n    boolean captureToTexture = sharedPrefGetBoolean(org.appspot.apprtc.R.string.pref_capturetotexture_key,\r\n        CallActivity.EXTRA_CAPTURETOTEXTURE_ENABLED, org.appspot.apprtc.R.string.pref_capturetotexture_default,\r\n        useValuesFromIntent);\r\n\r\n    // Check FlexFEC.\r\n    boolean flexfecEnabled = sharedPrefGetBoolean(org.appspot.apprtc.R.string.pref_flexfec_key,\r\n        CallActivity.EXTRA_FLEXFEC_ENABLED, org.appspot.apprtc.R.string.pref_flexfec_default, useValuesFromIntent);\r\n\r\n    // Check Disable Audio Processing flag.\r\n    boolean noAudioProcessing = sharedPrefGetBoolean(org.appspot.apprtc.R.string.pref_noaudioprocessing_key,\r\n        CallActivity.EXTRA_NOAUDIOPROCESSING_ENABLED, org.appspot.apprtc.R.string.pref_noaudioprocessing_default,\r\n        useValuesFromIntent);\r\n\r\n    boolean aecDump = sharedPrefGetBoolean(org.appspot.apprtc.R.string.pref_aecdump_key,\r\n        CallActivity.EXTRA_AECDUMP_ENABLED, org.appspot.apprtc.R.string.pref_aecdump_default, useValuesFromIntent);\r\n\r\n    boolean saveInputAudioToFile =\r\n        sharedPrefGetBoolean(org.appspot.apprtc.R.string.pref_enable_save_input_audio_to_file_key,\r\n            CallActivity.EXTRA_SAVE_INPUT_AUDIO_TO_FILE_ENABLED,\r\n            org.appspot.apprtc.R.string.pref_enable_save_input_audio_to_file_default, useValuesFromIntent);\r\n\r\n    // Check OpenSL ES enabled flag.\r\n    boolean useOpenSLES = sharedPrefGetBoolean(org.appspot.apprtc.R.string.pref_opensles_key,\r\n        CallActivity.EXTRA_OPENSLES_ENABLED, org.appspot.apprtc.R.string.pref_opensles_default, useValuesFromIntent);\r\n\r\n    // Check Disable built-in AEC flag.\r\n    boolean disableBuiltInAEC = sharedPrefGetBoolean(org.appspot.apprtc.R.string.pref_disable_built_in_aec_key,\r\n        CallActivity.EXTRA_DISABLE_BUILT_IN_AEC, org.appspot.apprtc.R.string.pref_disable_built_in_aec_default,\r\n        useValuesFromIntent);\r\n\r\n    // Check Disable built-in AGC flag.\r\n    boolean disableBuiltInAGC = sharedPrefGetBoolean(org.appspot.apprtc.R.string.pref_disable_built_in_agc_key,\r\n        CallActivity.EXTRA_DISABLE_BUILT_IN_AGC, org.appspot.apprtc.R.string.pref_disable_built_in_agc_default,\r\n        useValuesFromIntent);\r\n\r\n    // Check Disable built-in NS flag.\r\n    boolean disableBuiltInNS = sharedPrefGetBoolean(org.appspot.apprtc.R.string.pref_disable_built_in_ns_key,\r\n        CallActivity.EXTRA_DISABLE_BUILT_IN_NS, org.appspot.apprtc.R.string.pref_disable_built_in_ns_default,\r\n        useValuesFromIntent);\r\n\r\n    // Check Disable gain control\r\n    boolean disableWebRtcAGCAndHPF = sharedPrefGetBoolean(\r\n        org.appspot.apprtc.R.string.pref_disable_webrtc_agc_and_hpf_key, CallActivity.EXTRA_DISABLE_WEBRTC_AGC_AND_HPF,\r\n        org.appspot.apprtc.R.string.pref_disable_webrtc_agc_and_hpf_key, useValuesFromIntent);\r\n\r\n    // Get video resolution from settings.\r\n    int videoWidth = 0;\r\n    int videoHeight = 0;\r\n    if (useValuesFromIntent) {\r\n      videoWidth = getIntent().getIntExtra(CallActivity.EXTRA_VIDEO_WIDTH, 0);\r\n      videoHeight = getIntent().getIntExtra(CallActivity.EXTRA_VIDEO_HEIGHT, 0);\r\n    }\r\n    if (videoWidth == 0 && videoHeight == 0) {\r\n      String resolution =\r\n          sharedPref.getString(keyprefResolution, getString(org.appspot.apprtc.R.string.pref_resolution_default));\r\n      String[] dimensions = resolution.split(\"[ x]+\");\r\n      if (dimensions.length == 2) {\r\n        try {\r\n          videoWidth = Integer.parseInt(dimensions[0]);\r\n          videoHeight = Integer.parseInt(dimensions[1]);\r\n        } catch (NumberFormatException e) {\r\n          videoWidth = 0;\r\n          videoHeight = 0;\r\n          Log.e(TAG, \"Wrong video resolution setting: \" + resolution);\r\n        }\r\n      }\r\n    }\r\n\r\n    // Get camera fps from settings.\r\n    int cameraFps = 0;\r\n    if (useValuesFromIntent) {\r\n      cameraFps = getIntent().getIntExtra(CallActivity.EXTRA_VIDEO_FPS, 0);\r\n    }\r\n    if (cameraFps == 0) {\r\n      String fps = sharedPref.getString(keyprefFps, getString(org.appspot.apprtc.R.string.pref_fps_default));\r\n      String[] fpsValues = fps.split(\"[ x]+\");\r\n      if (fpsValues.length == 2) {\r\n        try {\r\n          cameraFps = Integer.parseInt(fpsValues[0]);\r\n        } catch (NumberFormatException e) {\r\n          cameraFps = 0;\r\n          Log.e(TAG, \"Wrong camera fps setting: \" + fps);\r\n        }\r\n      }\r\n    }\r\n\r\n    // Check capture quality slider flag.\r\n    boolean captureQualitySlider = sharedPrefGetBoolean(org.appspot.apprtc.R.string.pref_capturequalityslider_key,\r\n        CallActivity.EXTRA_VIDEO_CAPTUREQUALITYSLIDER_ENABLED,\r\n        org.appspot.apprtc.R.string.pref_capturequalityslider_default, useValuesFromIntent);\r\n\r\n    // Get video and audio start bitrate.\r\n    int videoStartBitrate = 0;\r\n    if (useValuesFromIntent) {\r\n      videoStartBitrate = getIntent().getIntExtra(CallActivity.EXTRA_VIDEO_BITRATE, 0);\r\n    }\r\n    if (videoStartBitrate == 0) {\r\n      String bitrateTypeDefault = getString(org.appspot.apprtc.R.string.pref_maxvideobitrate_default);\r\n      String bitrateType = sharedPref.getString(keyprefVideoBitrateType, bitrateTypeDefault);\r\n      if (!bitrateType.equals(bitrateTypeDefault)) {\r\n        String bitrateValue = sharedPref.getString(\r\n            keyprefVideoBitrateValue, getString(org.appspot.apprtc.R.string.pref_maxvideobitratevalue_default));\r\n        videoStartBitrate = Integer.parseInt(bitrateValue);\r\n      }\r\n    }\r\n\r\n    int audioStartBitrate = 0;\r\n    if (useValuesFromIntent) {\r\n      audioStartBitrate = getIntent().getIntExtra(CallActivity.EXTRA_AUDIO_BITRATE, 0);\r\n    }\r\n    if (audioStartBitrate == 0) {\r\n      String bitrateTypeDefault = getString(org.appspot.apprtc.R.string.pref_startaudiobitrate_default);\r\n      String bitrateType = sharedPref.getString(keyprefAudioBitrateType, bitrateTypeDefault);\r\n      if (!bitrateType.equals(bitrateTypeDefault)) {\r\n        String bitrateValue = sharedPref.getString(\r\n            keyprefAudioBitrateValue, getString(org.appspot.apprtc.R.string.pref_startaudiobitratevalue_default));\r\n        audioStartBitrate = Integer.parseInt(bitrateValue);\r\n      }\r\n    }\r\n\r\n    // Check statistics display option.\r\n    boolean displayHud = sharedPrefGetBoolean(org.appspot.apprtc.R.string.pref_displayhud_key,\r\n        CallActivity.EXTRA_DISPLAY_HUD, org.appspot.apprtc.R.string.pref_displayhud_default, useValuesFromIntent);\r\n\r\n    boolean tracing = sharedPrefGetBoolean(org.appspot.apprtc.R.string.pref_tracing_key, CallActivity.EXTRA_TRACING,\r\n        org.appspot.apprtc.R.string.pref_tracing_default, useValuesFromIntent);\r\n\r\n    // Check Enable RtcEventLog.\r\n    boolean rtcEventLogEnabled = sharedPrefGetBoolean(org.appspot.apprtc.R.string.pref_enable_rtceventlog_key,\r\n        CallActivity.EXTRA_ENABLE_RTCEVENTLOG, org.appspot.apprtc.R.string.pref_enable_rtceventlog_default,\r\n        useValuesFromIntent);\r\n\r\n    boolean useLegacyAudioDevice = sharedPrefGetBoolean(org.appspot.apprtc.R.string.pref_use_legacy_audio_device_key,\r\n        CallActivity.EXTRA_USE_LEGACY_AUDIO_DEVICE, org.appspot.apprtc.R.string.pref_use_legacy_audio_device_default,\r\n        useValuesFromIntent);\r\n\r\n    // Get datachannel options\r\n    boolean dataChannelEnabled = sharedPrefGetBoolean(org.appspot.apprtc.R.string.pref_enable_datachannel_key,\r\n        CallActivity.EXTRA_DATA_CHANNEL_ENABLED, org.appspot.apprtc.R.string.pref_enable_datachannel_default,\r\n        useValuesFromIntent);\r\n    boolean ordered = sharedPrefGetBoolean(org.appspot.apprtc.R.string.pref_ordered_key, CallActivity.EXTRA_ORDERED,\r\n        org.appspot.apprtc.R.string.pref_ordered_default, useValuesFromIntent);\r\n    boolean negotiated = sharedPrefGetBoolean(org.appspot.apprtc.R.string.pref_negotiated_key,\r\n        CallActivity.EXTRA_NEGOTIATED, org.appspot.apprtc.R.string.pref_negotiated_default, useValuesFromIntent);\r\n    int maxRetrMs = sharedPrefGetInteger(org.appspot.apprtc.R.string.pref_max_retransmit_time_ms_key,\r\n        CallActivity.EXTRA_MAX_RETRANSMITS_MS, org.appspot.apprtc.R.string.pref_max_retransmit_time_ms_default,\r\n        useValuesFromIntent);\r\n    int maxRetr =\r\n        sharedPrefGetInteger(org.appspot.apprtc.R.string.pref_max_retransmits_key, CallActivity.EXTRA_MAX_RETRANSMITS,\r\n            org.appspot.apprtc.R.string.pref_max_retransmits_default, useValuesFromIntent);\r\n    int id = sharedPrefGetInteger(org.appspot.apprtc.R.string.pref_data_id_key, CallActivity.EXTRA_ID,\r\n        org.appspot.apprtc.R.string.pref_data_id_default, useValuesFromIntent);\r\n    String protocol = sharedPrefGetString(org.appspot.apprtc.R.string.pref_data_protocol_key,\r\n        CallActivity.EXTRA_PROTOCOL, org.appspot.apprtc.R.string.pref_data_protocol_default, useValuesFromIntent);\r\n\r\n    // Start AppRTCMobile activity.\r\n    Log.d(TAG, \"Connecting to room \" + roomId + \" at URL \" + roomUrl);\r\n    if (validateUrl(roomUrl)) {\r\n      Uri uri = Uri.parse(roomUrl);\r\n      Intent intent = new Intent(this, CallActivity.class);\r\n      intent.setData(uri);\r\n      intent.putExtra(CallActivity.EXTRA_ROOMID, roomId);\r\n      intent.putExtra(CallActivity.EXTRA_LOOPBACK, loopback);\r\n      intent.putExtra(CallActivity.EXTRA_VIDEO_CALL, videoCallEnabled);\r\n      intent.putExtra(CallActivity.EXTRA_SCREENCAPTURE, useScreencapture);\r\n      intent.putExtra(CallActivity.EXTRA_CAMERA2, useCamera2);\r\n      intent.putExtra(CallActivity.EXTRA_VIDEO_WIDTH, videoWidth);\r\n      intent.putExtra(CallActivity.EXTRA_VIDEO_HEIGHT, videoHeight);\r\n      intent.putExtra(CallActivity.EXTRA_VIDEO_FPS, cameraFps);\r\n      intent.putExtra(CallActivity.EXTRA_VIDEO_CAPTUREQUALITYSLIDER_ENABLED, captureQualitySlider);\r\n      intent.putExtra(CallActivity.EXTRA_VIDEO_BITRATE, videoStartBitrate);\r\n      intent.putExtra(CallActivity.EXTRA_VIDEOCODEC, videoCodec);\r\n      intent.putExtra(CallActivity.EXTRA_HWCODEC_ENABLED, hwCodec);\r\n      intent.putExtra(CallActivity.EXTRA_CAPTURETOTEXTURE_ENABLED, captureToTexture);\r\n      intent.putExtra(CallActivity.EXTRA_FLEXFEC_ENABLED, flexfecEnabled);\r\n      intent.putExtra(CallActivity.EXTRA_NOAUDIOPROCESSING_ENABLED, noAudioProcessing);\r\n      intent.putExtra(CallActivity.EXTRA_AECDUMP_ENABLED, aecDump);\r\n      intent.putExtra(CallActivity.EXTRA_SAVE_INPUT_AUDIO_TO_FILE_ENABLED, saveInputAudioToFile);\r\n      intent.putExtra(CallActivity.EXTRA_OPENSLES_ENABLED, useOpenSLES);\r\n      intent.putExtra(CallActivity.EXTRA_DISABLE_BUILT_IN_AEC, disableBuiltInAEC);\r\n      intent.putExtra(CallActivity.EXTRA_DISABLE_BUILT_IN_AGC, disableBuiltInAGC);\r\n      intent.putExtra(CallActivity.EXTRA_DISABLE_BUILT_IN_NS, disableBuiltInNS);\r\n      intent.putExtra(CallActivity.EXTRA_DISABLE_WEBRTC_AGC_AND_HPF, disableWebRtcAGCAndHPF);\r\n      intent.putExtra(CallActivity.EXTRA_AUDIO_BITRATE, audioStartBitrate);\r\n      intent.putExtra(CallActivity.EXTRA_AUDIOCODEC, audioCodec);\r\n      intent.putExtra(CallActivity.EXTRA_DISPLAY_HUD, displayHud);\r\n      intent.putExtra(CallActivity.EXTRA_TRACING, tracing);\r\n      intent.putExtra(CallActivity.EXTRA_ENABLE_RTCEVENTLOG, rtcEventLogEnabled);\r\n      intent.putExtra(CallActivity.EXTRA_CMDLINE, commandLineRun);\r\n      intent.putExtra(CallActivity.EXTRA_RUNTIME, runTimeMs);\r\n      intent.putExtra(CallActivity.EXTRA_USE_LEGACY_AUDIO_DEVICE, useLegacyAudioDevice);\r\n\r\n      intent.putExtra(CallActivity.EXTRA_DATA_CHANNEL_ENABLED, dataChannelEnabled);\r\n\r\n      if (dataChannelEnabled) {\r\n        intent.putExtra(CallActivity.EXTRA_ORDERED, ordered);\r\n        intent.putExtra(CallActivity.EXTRA_MAX_RETRANSMITS_MS, maxRetrMs);\r\n        intent.putExtra(CallActivity.EXTRA_MAX_RETRANSMITS, maxRetr);\r\n        intent.putExtra(CallActivity.EXTRA_PROTOCOL, protocol);\r\n        intent.putExtra(CallActivity.EXTRA_NEGOTIATED, negotiated);\r\n        intent.putExtra(CallActivity.EXTRA_ID, id);\r\n      }\r\n\r\n      if (useValuesFromIntent) {\r\n        if (getIntent().hasExtra(CallActivity.EXTRA_VIDEO_FILE_AS_CAMERA)) {\r\n          String videoFileAsCamera =\r\n              getIntent().getStringExtra(CallActivity.EXTRA_VIDEO_FILE_AS_CAMERA);\r\n          intent.putExtra(CallActivity.EXTRA_VIDEO_FILE_AS_CAMERA, videoFileAsCamera);\r\n        }\r\n\r\n        if (getIntent().hasExtra(CallActivity.EXTRA_SAVE_REMOTE_VIDEO_TO_FILE)) {\r\n          String saveRemoteVideoToFile =\r\n              getIntent().getStringExtra(CallActivity.EXTRA_SAVE_REMOTE_VIDEO_TO_FILE);\r\n          intent.putExtra(CallActivity.EXTRA_SAVE_REMOTE_VIDEO_TO_FILE, saveRemoteVideoToFile);\r\n        }\r\n\r\n        if (getIntent().hasExtra(CallActivity.EXTRA_SAVE_REMOTE_VIDEO_TO_FILE_WIDTH)) {\r\n          int videoOutWidth =\r\n              getIntent().getIntExtra(CallActivity.EXTRA_SAVE_REMOTE_VIDEO_TO_FILE_WIDTH, 0);\r\n          intent.putExtra(CallActivity.EXTRA_SAVE_REMOTE_VIDEO_TO_FILE_WIDTH, videoOutWidth);\r\n        }\r\n\r\n        if (getIntent().hasExtra(CallActivity.EXTRA_SAVE_REMOTE_VIDEO_TO_FILE_HEIGHT)) {\r\n          int videoOutHeight =\r\n              getIntent().getIntExtra(CallActivity.EXTRA_SAVE_REMOTE_VIDEO_TO_FILE_HEIGHT, 0);\r\n          intent.putExtra(CallActivity.EXTRA_SAVE_REMOTE_VIDEO_TO_FILE_HEIGHT, videoOutHeight);\r\n        }\r\n      }\r\n\r\n      startCallActivity(intent);\r\n    }\r\n  }\r\n\r\n  private static final String[] PERMISSIONS_START_CALL = {Manifest.permission.CAMERA, Manifest.permission.RECORD_AUDIO};//WRITE_EXTERNAL_STORAGE, CAPTURE_VIDEO_OUTPUT\r\n  private static final int PERMISSIONS_REQUEST_START_CALL = 101;\r\n  private Intent startCallIntent;\r\n\r\n  private void startCallActivity(Intent intent) {\r\n    if(!hasPermissions(this, PERMISSIONS_START_CALL)){\r\n      startCallIntent = intent;\r\n      ActivityCompat.requestPermissions(this, PERMISSIONS_START_CALL, PERMISSIONS_REQUEST_START_CALL);\r\n      return;\r\n    }\r\n    startActivityForResult(intent, CONNECTION_REQUEST);\r\n  }\r\n\r\n  private static boolean hasPermissions(Context context, String... permissions) {\r\n    if (context != null && permissions != null) {\r\n      for (String permission : permissions) {\r\n        if (ActivityCompat.checkSelfPermission(context, permission) != PackageManager.PERMISSION_GRANTED) {\r\n          return false;\r\n        }\r\n      }\r\n    }\r\n    return true;\r\n  }\r\n\r\n  @Override\r\n  public void onRequestPermissionsResult(int requestCode, String[] permissions, int[] grantResults) {\r\n    super.onRequestPermissionsResult(requestCode, permissions, grantResults);\r\n\r\n    switch (requestCode) {\r\n      case PERMISSIONS_REQUEST_START_CALL: {\r\n        if (hasPermissions(this, PERMISSIONS_START_CALL)) {\r\n          // permission was granted, yay!\r\n          if (startCallIntent != null) startActivityForResult(startCallIntent, CONNECTION_REQUEST);\r\n        } else {\r\n          Toast.makeText(this, \"Required permissions denied.\", Toast.LENGTH_LONG).show();\r\n        }\r\n        return;\r\n      }\r\n    }\r\n  }\r\n\r\n  @Override\r\n  protected void onRestoreInstanceState(Bundle savedInstanceState) {\r\n    super.onRestoreInstanceState(savedInstanceState);\r\n    startCallIntent = savedInstanceState.getParcelable(\"startCallIntent\");\r\n  }\r\n\r\n  @Override\r\n  protected void onSaveInstanceState(Bundle outState) {\r\n    super.onSaveInstanceState(outState);\r\n    outState.putParcelable(\"startCallIntent\", startCallIntent);\r\n  }\r\n\r\n  private boolean validateUrl(String url) {\r\n    if (URLUtil.isHttpsUrl(url) || URLUtil.isHttpUrl(url)) {\r\n      return true;\r\n    }\r\n\r\n    new AlertDialog.Builder(this)\r\n        .setTitle(getText(org.appspot.apprtc.R.string.invalid_url_title))\r\n        .setMessage(getString(org.appspot.apprtc.R.string.invalid_url_text, url))\r\n        .setCancelable(false)\r\n        .setNeutralButton(org.appspot.apprtc.R.string.ok,\r\n            new DialogInterface.OnClickListener() {\r\n              @Override\r\n              public void onClick(DialogInterface dialog, int id) {\r\n                dialog.cancel();\r\n              }\r\n            })\r\n        .create()\r\n        .show();\r\n    return false;\r\n  }\r\n\r\n  private final AdapterView.OnItemClickListener roomListClickListener =\r\n      new AdapterView.OnItemClickListener() {\r\n        @Override\r\n        public void onItemClick(AdapterView<?> adapterView, View view, int i, long l) {\r\n          String roomId = ((TextView) view).getText().toString();\r\n          connectToRoom(roomId, false, false, false, 0);\r\n        }\r\n      };\r\n\r\n  private final OnClickListener addFavoriteListener = new OnClickListener() {\r\n    @Override\r\n    public void onClick(View view) {\r\n      String newRoom = roomEditText.getText().toString();\r\n      if (newRoom.length() > 0 && !roomList.contains(newRoom)) {\r\n        adapter.add(newRoom);\r\n        adapter.notifyDataSetChanged();\r\n      }\r\n    }\r\n  };\r\n\r\n  private final OnClickListener connectListener = new OnClickListener() {\r\n    @Override\r\n    public void onClick(View view) {\r\n      connectToRoom(roomEditText.getText().toString(), false, false, false, 0);\r\n    }\r\n  };\r\n}\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/src/main/java/com/example/webrtc/android/ConnectActivity.java	(revision bf540945d88389d00f5acde8206c98ded8cdb2e7)
+++ app/src/main/java/com/example/webrtc/android/ConnectActivity.java	(date 1605933286430)
@@ -211,6 +211,7 @@
 
   @Override
   protected void onActivityResult(int requestCode, int resultCode, Intent data) {
+    super.onActivityResult(requestCode, resultCode, data);
     if (requestCode == CONNECTION_REQUEST && commandLineRun) {
       Log.d(TAG, "Return: " + resultCode);
       setResult(resultCode);
@@ -242,6 +243,7 @@
    * Get a value from the shared preference or from the intent, if it does not
    * exist the default is used.
    */
+
   private boolean sharedPrefGetBoolean(
       int attributeId, String intentName, int defaultId, boolean useFromIntent) {
     boolean defaultValue = Boolean.parseBoolean(getString(defaultId));
Index: app/src/main/java/com/example/webrtc/android/CallActivity.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>/*\r\n *  Copyright 2015 The WebRTC Project Authors. All rights reserved.\r\n *\r\n *  Use of this source code is governed by a BSD-style license\r\n *  that can be found in the LICENSE file in the root of the source\r\n *  tree. An additional intellectual property rights grant can be found\r\n *  in the file PATENTS.  All contributing project authors may\r\n *  be found in the AUTHORS file in the root of the source tree.\r\n */\r\n\r\npackage com.example.webrtc.android;\r\n\r\nimport android.annotation.TargetApi;\r\nimport android.app.Activity;\r\nimport android.app.AlertDialog;\r\nimport android.app.FragmentTransaction;\r\nimport android.content.Context;\r\nimport android.content.DialogInterface;\r\nimport android.content.Intent;\r\nimport android.content.pm.PackageManager;\r\nimport android.media.projection.MediaProjection;\r\nimport android.media.projection.MediaProjectionManager;\r\nimport android.net.Uri;\r\nimport android.os.Build;\r\nimport android.os.Bundle;\r\nimport android.os.Handler;\r\nimport android.util.DisplayMetrics;\r\nimport android.util.Log;\r\nimport android.view.View;\r\nimport android.view.Window;\r\nimport android.view.WindowManager;\r\nimport android.view.WindowManager.LayoutParams;\r\nimport android.widget.Toast;\r\nimport java.io.IOException;\r\nimport java.lang.RuntimeException;\r\nimport java.util.ArrayList;\r\nimport java.util.List;\r\nimport java.util.Set;\r\nimport javax.annotation.Nullable;\r\n\r\nimport org.appspot.apprtc.AppRTCAudioManager;\r\nimport org.appspot.apprtc.AppRTCAudioManager.AudioDevice;\r\nimport org.appspot.apprtc.AppRTCAudioManager.AudioManagerEvents;\r\nimport org.appspot.apprtc.AppRTCClient;\r\nimport org.appspot.apprtc.AppRTCClient.RoomConnectionParameters;\r\nimport org.appspot.apprtc.AppRTCClient.SignalingParameters;\r\nimport org.appspot.apprtc.CpuMonitor;\r\nimport org.appspot.apprtc.DirectRTCClient;\r\nimport org.appspot.apprtc.PeerConnectionClient;\r\nimport org.appspot.apprtc.PeerConnectionClient.DataChannelParameters;\r\nimport org.appspot.apprtc.PeerConnectionClient.PeerConnectionParameters;\r\nimport org.appspot.apprtc.UnhandledExceptionHandler;\r\nimport org.appspot.apprtc.WebSocketRTCClient;\r\nimport org.webrtc.Camera1Enumerator;\r\nimport org.webrtc.Camera2Enumerator;\r\nimport org.webrtc.CameraEnumerator;\r\nimport org.webrtc.EglBase;\r\nimport org.webrtc.FileVideoCapturer;\r\nimport org.webrtc.IceCandidate;\r\nimport org.webrtc.Logging;\r\nimport org.webrtc.PeerConnectionFactory;\r\nimport org.webrtc.RendererCommon.ScalingType;\r\nimport org.webrtc.ScreenCapturerAndroid;\r\nimport org.webrtc.SessionDescription;\r\nimport org.webrtc.StatsReport;\r\nimport org.webrtc.SurfaceViewRenderer;\r\nimport org.webrtc.VideoCapturer;\r\nimport org.webrtc.VideoFileRenderer;\r\nimport org.webrtc.VideoFrame;\r\nimport org.webrtc.VideoSink;\r\n\r\n/**\r\n * Activity for peer connection call setup, call waiting\r\n * and call view.\r\n */\r\npublic class CallActivity extends Activity implements AppRTCClient.SignalingEvents,\r\n                                                      PeerConnectionClient.PeerConnectionEvents,\r\n                                                      CallFragment.OnCallEvents {\r\n  private static final String TAG = \"CallRTCClient\";\r\n\r\n  public static final String EXTRA_ROOMID = \"org.appspot.apprtc.ROOMID\";\r\n  public static final String EXTRA_URLPARAMETERS = \"org.appspot.apprtc.URLPARAMETERS\";\r\n  public static final String EXTRA_LOOPBACK = \"org.appspot.apprtc.LOOPBACK\";\r\n  public static final String EXTRA_VIDEO_CALL = \"org.appspot.apprtc.VIDEO_CALL\";\r\n  public static final String EXTRA_SCREENCAPTURE = \"org.appspot.apprtc.SCREENCAPTURE\";\r\n  public static final String EXTRA_CAMERA2 = \"org.appspot.apprtc.CAMERA2\";\r\n  public static final String EXTRA_VIDEO_WIDTH = \"org.appspot.apprtc.VIDEO_WIDTH\";\r\n  public static final String EXTRA_VIDEO_HEIGHT = \"org.appspot.apprtc.VIDEO_HEIGHT\";\r\n  public static final String EXTRA_VIDEO_FPS = \"org.appspot.apprtc.VIDEO_FPS\";\r\n  public static final String EXTRA_VIDEO_CAPTUREQUALITYSLIDER_ENABLED =\r\n      \"org.appsopt.apprtc.VIDEO_CAPTUREQUALITYSLIDER\";\r\n  public static final String EXTRA_VIDEO_BITRATE = \"org.appspot.apprtc.VIDEO_BITRATE\";\r\n  public static final String EXTRA_VIDEOCODEC = \"org.appspot.apprtc.VIDEOCODEC\";\r\n  public static final String EXTRA_HWCODEC_ENABLED = \"org.appspot.apprtc.HWCODEC\";\r\n  public static final String EXTRA_CAPTURETOTEXTURE_ENABLED = \"org.appspot.apprtc.CAPTURETOTEXTURE\";\r\n  public static final String EXTRA_FLEXFEC_ENABLED = \"org.appspot.apprtc.FLEXFEC\";\r\n  public static final String EXTRA_AUDIO_BITRATE = \"org.appspot.apprtc.AUDIO_BITRATE\";\r\n  public static final String EXTRA_AUDIOCODEC = \"org.appspot.apprtc.AUDIOCODEC\";\r\n  public static final String EXTRA_NOAUDIOPROCESSING_ENABLED =\r\n      \"org.appspot.apprtc.NOAUDIOPROCESSING\";\r\n  public static final String EXTRA_AECDUMP_ENABLED = \"org.appspot.apprtc.AECDUMP\";\r\n  public static final String EXTRA_SAVE_INPUT_AUDIO_TO_FILE_ENABLED =\r\n      \"org.appspot.apprtc.SAVE_INPUT_AUDIO_TO_FILE\";\r\n  public static final String EXTRA_OPENSLES_ENABLED = \"org.appspot.apprtc.OPENSLES\";\r\n  public static final String EXTRA_DISABLE_BUILT_IN_AEC = \"org.appspot.apprtc.DISABLE_BUILT_IN_AEC\";\r\n  public static final String EXTRA_DISABLE_BUILT_IN_AGC = \"org.appspot.apprtc.DISABLE_BUILT_IN_AGC\";\r\n  public static final String EXTRA_DISABLE_BUILT_IN_NS = \"org.appspot.apprtc.DISABLE_BUILT_IN_NS\";\r\n  public static final String EXTRA_DISABLE_WEBRTC_AGC_AND_HPF =\r\n      \"org.appspot.apprtc.DISABLE_WEBRTC_GAIN_CONTROL\";\r\n  public static final String EXTRA_DISPLAY_HUD = \"org.appspot.apprtc.DISPLAY_HUD\";\r\n  public static final String EXTRA_TRACING = \"org.appspot.apprtc.TRACING\";\r\n  public static final String EXTRA_CMDLINE = \"org.appspot.apprtc.CMDLINE\";\r\n  public static final String EXTRA_RUNTIME = \"org.appspot.apprtc.RUNTIME\";\r\n  public static final String EXTRA_VIDEO_FILE_AS_CAMERA = \"org.appspot.apprtc.VIDEO_FILE_AS_CAMERA\";\r\n  public static final String EXTRA_SAVE_REMOTE_VIDEO_TO_FILE =\r\n      \"org.appspot.apprtc.SAVE_REMOTE_VIDEO_TO_FILE\";\r\n  public static final String EXTRA_SAVE_REMOTE_VIDEO_TO_FILE_WIDTH =\r\n      \"org.appspot.apprtc.SAVE_REMOTE_VIDEO_TO_FILE_WIDTH\";\r\n  public static final String EXTRA_SAVE_REMOTE_VIDEO_TO_FILE_HEIGHT =\r\n      \"org.appspot.apprtc.SAVE_REMOTE_VIDEO_TO_FILE_HEIGHT\";\r\n  public static final String EXTRA_USE_VALUES_FROM_INTENT =\r\n      \"org.appspot.apprtc.USE_VALUES_FROM_INTENT\";\r\n  public static final String EXTRA_DATA_CHANNEL_ENABLED = \"org.appspot.apprtc.DATA_CHANNEL_ENABLED\";\r\n  public static final String EXTRA_ORDERED = \"org.appspot.apprtc.ORDERED\";\r\n  public static final String EXTRA_MAX_RETRANSMITS_MS = \"org.appspot.apprtc.MAX_RETRANSMITS_MS\";\r\n  public static final String EXTRA_MAX_RETRANSMITS = \"org.appspot.apprtc.MAX_RETRANSMITS\";\r\n  public static final String EXTRA_PROTOCOL = \"org.appspot.apprtc.PROTOCOL\";\r\n  public static final String EXTRA_NEGOTIATED = \"org.appspot.apprtc.NEGOTIATED\";\r\n  public static final String EXTRA_ID = \"org.appspot.apprtc.ID\";\r\n  public static final String EXTRA_ENABLE_RTCEVENTLOG = \"org.appspot.apprtc.ENABLE_RTCEVENTLOG\";\r\n  public static final String EXTRA_USE_LEGACY_AUDIO_DEVICE =\r\n      \"org.appspot.apprtc.USE_LEGACY_AUDIO_DEVICE\";\r\n\r\n  private static final int CAPTURE_PERMISSION_REQUEST_CODE = 1;\r\n\r\n  // List of mandatory application permissions.\r\n  private static final String[] MANDATORY_PERMISSIONS = {\"android.permission.MODIFY_AUDIO_SETTINGS\",\r\n      \"android.permission.RECORD_AUDIO\", \"android.permission.INTERNET\"};\r\n\r\n  // Peer connection statistics callback period in ms.\r\n  private static final int STAT_CALLBACK_PERIOD = 1000;\r\n\r\n  private static class ProxyVideoSink implements VideoSink {\r\n    private VideoSink target;\r\n\r\n    @Override\r\n    synchronized public void onFrame(VideoFrame frame) {\r\n      if (target == null) {\r\n        Logging.d(TAG, \"Dropping frame in proxy because target is null.\");\r\n        return;\r\n      }\r\n\r\n      target.onFrame(frame);\r\n    }\r\n\r\n    synchronized public void setTarget(VideoSink target) {\r\n      this.target = target;\r\n    }\r\n  }\r\n\r\n  private final ProxyVideoSink remoteProxyRenderer = new ProxyVideoSink();\r\n  private final ProxyVideoSink localProxyVideoSink = new ProxyVideoSink();\r\n  @Nullable\r\n  private PeerConnectionClient peerConnectionClient = null;\r\n  @Nullable\r\n  private AppRTCClient appRtcClient;\r\n  @Nullable\r\n  private SignalingParameters signalingParameters;\r\n  @Nullable\r\n  private AppRTCAudioManager audioManager = null;\r\n  @Nullable\r\n  private SurfaceViewRenderer pipRenderer;\r\n  @Nullable\r\n  private SurfaceViewRenderer fullscreenRenderer;\r\n  @Nullable\r\n  private VideoFileRenderer videoFileRenderer;\r\n  private final List<VideoSink> remoteSinks = new ArrayList<>();\r\n  private Toast logToast;\r\n  private boolean commandLineRun;\r\n  private boolean activityRunning;\r\n  private RoomConnectionParameters roomConnectionParameters;\r\n  @Nullable\r\n  private PeerConnectionParameters peerConnectionParameters;\r\n  private boolean iceConnected;\r\n  private boolean isError;\r\n  private boolean callControlFragmentVisible = true;\r\n  private long callStartedTimeMs = 0;\r\n  private boolean micEnabled = true;\r\n  private boolean screencaptureEnabled = false;\r\n  private static Intent mediaProjectionPermissionResultData;\r\n  private static int mediaProjectionPermissionResultCode;\r\n  // True if local view is in the fullscreen renderer.\r\n  private boolean isSwappedFeeds;\r\n\r\n  // Controls\r\n  private CallFragment callFragment;\r\n  private HudFragment hudFragment;\r\n  private CpuMonitor cpuMonitor;\r\n\r\n  @Override\r\n  // TODO(bugs.webrtc.org/8580): LayoutParams.FLAG_TURN_SCREEN_ON and\r\n  // LayoutParams.FLAG_SHOW_WHEN_LOCKED are deprecated.\r\n  @SuppressWarnings(\"deprecation\")\r\n  public void onCreate(Bundle savedInstanceState) {\r\n    super.onCreate(savedInstanceState);\r\n    Thread.setDefaultUncaughtExceptionHandler(new UnhandledExceptionHandler(this));\r\n\r\n    // Set window styles for fullscreen-window size. Needs to be done before\r\n    // adding content.\r\n    requestWindowFeature(Window.FEATURE_NO_TITLE);\r\n    getWindow().addFlags(LayoutParams.FLAG_FULLSCREEN | LayoutParams.FLAG_KEEP_SCREEN_ON\r\n        | LayoutParams.FLAG_SHOW_WHEN_LOCKED | LayoutParams.FLAG_TURN_SCREEN_ON);\r\n    getWindow().getDecorView().setSystemUiVisibility(getSystemUiVisibility());\r\n    setContentView(R.layout.activity_call);\r\n\r\n    iceConnected = false;\r\n    signalingParameters = null;\r\n\r\n    // Create UI controls.\r\n    pipRenderer = findViewById(R.id.pip_video_view);\r\n    fullscreenRenderer = findViewById(R.id.fullscreen_video_view);\r\n    callFragment = new CallFragment();\r\n    hudFragment = new HudFragment();\r\n\r\n    // Show/hide call control fragment on view click.\r\n    View.OnClickListener listener = new View.OnClickListener() {\r\n      @Override\r\n      public void onClick(View view) {\r\n        toggleCallControlFragmentVisibility();\r\n      }\r\n    };\r\n\r\n    // Swap feeds on pip view click.\r\n    pipRenderer.setOnClickListener(new View.OnClickListener() {\r\n      @Override\r\n      public void onClick(View view) {\r\n        setSwappedFeeds(!isSwappedFeeds);\r\n      }\r\n    });\r\n\r\n    fullscreenRenderer.setOnClickListener(listener);\r\n    remoteSinks.add(remoteProxyRenderer);\r\n\r\n    final Intent intent = getIntent();\r\n    final EglBase eglBase = EglBase.create();\r\n\r\n    // Create video renderers.\r\n    pipRenderer.init(eglBase.getEglBaseContext(), null);\r\n    pipRenderer.setScalingType(ScalingType.SCALE_ASPECT_FIT);\r\n    String saveRemoteVideoToFile = intent.getStringExtra(EXTRA_SAVE_REMOTE_VIDEO_TO_FILE);\r\n\r\n    // When saveRemoteVideoToFile is set we save the video from the remote to a file.\r\n    if (saveRemoteVideoToFile != null) {\r\n      int videoOutWidth = intent.getIntExtra(EXTRA_SAVE_REMOTE_VIDEO_TO_FILE_WIDTH, 0);\r\n      int videoOutHeight = intent.getIntExtra(EXTRA_SAVE_REMOTE_VIDEO_TO_FILE_HEIGHT, 0);\r\n      try {\r\n        videoFileRenderer = new VideoFileRenderer(\r\n            saveRemoteVideoToFile, videoOutWidth, videoOutHeight, eglBase.getEglBaseContext());\r\n        remoteSinks.add(videoFileRenderer);\r\n      } catch (IOException e) {\r\n        throw new RuntimeException(\r\n            \"Failed to open video file for output: \" + saveRemoteVideoToFile, e);\r\n      }\r\n    }\r\n    fullscreenRenderer.init(eglBase.getEglBaseContext(), null);\r\n    fullscreenRenderer.setScalingType(ScalingType.SCALE_ASPECT_FILL);\r\n\r\n    pipRenderer.setZOrderMediaOverlay(true);\r\n    pipRenderer.setEnableHardwareScaler(true /* enabled */);\r\n    fullscreenRenderer.setEnableHardwareScaler(false /* enabled */);\r\n    // Start with local feed in fullscreen and swap it to the pip when the call is connected.\r\n    setSwappedFeeds(true /* isSwappedFeeds */);\r\n\r\n    // Check for mandatory permissions.\r\n    for (String permission : MANDATORY_PERMISSIONS) {\r\n      if (checkCallingOrSelfPermission(permission) != PackageManager.PERMISSION_GRANTED) {\r\n        logAndToast(\"Permission \" + permission + \" is not granted\");\r\n        setResult(RESULT_CANCELED);\r\n        finish();\r\n        return;\r\n      }\r\n    }\r\n\r\n    Uri roomUri = intent.getData();\r\n    if (roomUri == null) {\r\n      logAndToast(getString(org.appspot.apprtc.R.string.missing_url));\r\n      Log.e(TAG, \"Didn't get any URL in intent!\");\r\n      setResult(RESULT_CANCELED);\r\n      finish();\r\n      return;\r\n    }\r\n\r\n    // Get Intent parameters.\r\n    String roomId = intent.getStringExtra(EXTRA_ROOMID);\r\n    Log.d(TAG, \"Room ID: \" + roomId);\r\n    if (roomId == null || roomId.length() == 0) {\r\n      logAndToast(getString(org.appspot.apprtc.R.string.missing_url));\r\n      Log.e(TAG, \"Incorrect room ID in intent!\");\r\n      setResult(RESULT_CANCELED);\r\n      finish();\r\n      return;\r\n    }\r\n\r\n    boolean loopback = intent.getBooleanExtra(EXTRA_LOOPBACK, false);\r\n    boolean tracing = intent.getBooleanExtra(EXTRA_TRACING, false);\r\n\r\n    int videoWidth = intent.getIntExtra(EXTRA_VIDEO_WIDTH, 0);\r\n    int videoHeight = intent.getIntExtra(EXTRA_VIDEO_HEIGHT, 0);\r\n\r\n    screencaptureEnabled = intent.getBooleanExtra(EXTRA_SCREENCAPTURE, false);\r\n    // If capturing format is not specified for screencapture, use screen resolution.\r\n    if (screencaptureEnabled && videoWidth == 0 && videoHeight == 0) {\r\n      DisplayMetrics displayMetrics = getDisplayMetrics();\r\n      videoWidth = displayMetrics.widthPixels;\r\n      videoHeight = displayMetrics.heightPixels;\r\n    }\r\n    DataChannelParameters dataChannelParameters = null;\r\n    if (intent.getBooleanExtra(EXTRA_DATA_CHANNEL_ENABLED, false)) {\r\n      dataChannelParameters = new DataChannelParameters(intent.getBooleanExtra(EXTRA_ORDERED, true),\r\n          intent.getIntExtra(EXTRA_MAX_RETRANSMITS_MS, -1),\r\n          intent.getIntExtra(EXTRA_MAX_RETRANSMITS, -1), intent.getStringExtra(EXTRA_PROTOCOL),\r\n          intent.getBooleanExtra(EXTRA_NEGOTIATED, false), intent.getIntExtra(EXTRA_ID, -1));\r\n    }\r\n    peerConnectionParameters =\r\n        new PeerConnectionParameters(intent.getBooleanExtra(EXTRA_VIDEO_CALL, true), loopback,\r\n            tracing, videoWidth, videoHeight, intent.getIntExtra(EXTRA_VIDEO_FPS, 0),\r\n            intent.getIntExtra(EXTRA_VIDEO_BITRATE, 0), intent.getStringExtra(EXTRA_VIDEOCODEC),\r\n            intent.getBooleanExtra(EXTRA_HWCODEC_ENABLED, true),\r\n            intent.getBooleanExtra(EXTRA_FLEXFEC_ENABLED, false),\r\n            intent.getIntExtra(EXTRA_AUDIO_BITRATE, 0), intent.getStringExtra(EXTRA_AUDIOCODEC),\r\n            intent.getBooleanExtra(EXTRA_NOAUDIOPROCESSING_ENABLED, false),\r\n            intent.getBooleanExtra(EXTRA_AECDUMP_ENABLED, false),\r\n            intent.getBooleanExtra(EXTRA_SAVE_INPUT_AUDIO_TO_FILE_ENABLED, false),\r\n            intent.getBooleanExtra(EXTRA_OPENSLES_ENABLED, false),\r\n            intent.getBooleanExtra(EXTRA_DISABLE_BUILT_IN_AEC, false),\r\n            intent.getBooleanExtra(EXTRA_DISABLE_BUILT_IN_AGC, false),\r\n            intent.getBooleanExtra(EXTRA_DISABLE_BUILT_IN_NS, false),\r\n            intent.getBooleanExtra(EXTRA_DISABLE_WEBRTC_AGC_AND_HPF, false),\r\n            intent.getBooleanExtra(EXTRA_ENABLE_RTCEVENTLOG, false),\r\n            intent.getBooleanExtra(EXTRA_USE_LEGACY_AUDIO_DEVICE, false), dataChannelParameters);\r\n    commandLineRun = intent.getBooleanExtra(EXTRA_CMDLINE, false);\r\n    int runTimeMs = intent.getIntExtra(EXTRA_RUNTIME, 0);\r\n\r\n    Log.d(TAG, \"VIDEO_FILE: '\" + intent.getStringExtra(EXTRA_VIDEO_FILE_AS_CAMERA) + \"'\");\r\n\r\n    // Create connection client. Use DirectRTCClient if room name is an IP otherwise use the\r\n    // standard WebSocketRTCClient.\r\n    if (loopback || !DirectRTCClient.IP_PATTERN.matcher(roomId).matches()) {\r\n      appRtcClient = new WebSocketRTCClient(this);\r\n    } else {\r\n      Log.i(TAG, \"Using DirectRTCClient because room name looks like an IP.\");\r\n      appRtcClient = new DirectRTCClient(this);\r\n    }\r\n    // Create connection parameters.\r\n    String urlParameters = intent.getStringExtra(EXTRA_URLPARAMETERS);\r\n    roomConnectionParameters =\r\n        new RoomConnectionParameters(roomUri.toString(), roomId, loopback, urlParameters);\r\n\r\n    // Create CPU monitor\r\n    if (CpuMonitor.isSupported()) {\r\n      cpuMonitor = new CpuMonitor(this);\r\n      hudFragment.setCpuMonitor(cpuMonitor);\r\n    }\r\n\r\n    // Send intent arguments to fragments.\r\n    callFragment.setArguments(intent.getExtras());\r\n    hudFragment.setArguments(intent.getExtras());\r\n    // Activate call and HUD fragments and start the call.\r\n    FragmentTransaction ft = getFragmentManager().beginTransaction();\r\n    ft.add(R.id.call_fragment_container, callFragment);\r\n    ft.add(R.id.hud_fragment_container, hudFragment);\r\n    ft.commit();\r\n\r\n    // For command line execution run connection for <runTimeMs> and exit.\r\n    if (commandLineRun && runTimeMs > 0) {\r\n      (new Handler()).postDelayed(new Runnable() {\r\n        @Override\r\n        public void run() {\r\n          disconnect();\r\n        }\r\n      }, runTimeMs);\r\n    }\r\n\r\n    // Create peer connection client.\r\n    peerConnectionClient = new PeerConnectionClient(\r\n        getApplicationContext(), eglBase, peerConnectionParameters, CallActivity.this);\r\n    PeerConnectionFactory.Options options = new PeerConnectionFactory.Options();\r\n    if (loopback) {\r\n      options.networkIgnoreMask = 0;\r\n    }\r\n    peerConnectionClient.createPeerConnectionFactory(options);\r\n\r\n    if (screencaptureEnabled) {\r\n      startScreenCapture();\r\n    } else {\r\n      startCall();\r\n    }\r\n  }\r\n\r\n  @TargetApi(17)\r\n  private DisplayMetrics getDisplayMetrics() {\r\n    DisplayMetrics displayMetrics = new DisplayMetrics();\r\n    WindowManager windowManager =\r\n        (WindowManager) getApplication().getSystemService(Context.WINDOW_SERVICE);\r\n    windowManager.getDefaultDisplay().getRealMetrics(displayMetrics);\r\n    return displayMetrics;\r\n  }\r\n\r\n  @TargetApi(19)\r\n  private static int getSystemUiVisibility() {\r\n    int flags = View.SYSTEM_UI_FLAG_HIDE_NAVIGATION | View.SYSTEM_UI_FLAG_FULLSCREEN;\r\n    if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.KITKAT) {\r\n      flags |= View.SYSTEM_UI_FLAG_IMMERSIVE_STICKY;\r\n    }\r\n    return flags;\r\n  }\r\n\r\n  @TargetApi(21)\r\n  private void startScreenCapture() {\r\n    MediaProjectionManager mediaProjectionManager =\r\n        (MediaProjectionManager) getApplication().getSystemService(\r\n            Context.MEDIA_PROJECTION_SERVICE);\r\n    startActivityForResult(\r\n        mediaProjectionManager.createScreenCaptureIntent(), CAPTURE_PERMISSION_REQUEST_CODE);\r\n  }\r\n\r\n  @Override\r\n  public void onActivityResult(int requestCode, int resultCode, Intent data) {\r\n    if (requestCode != CAPTURE_PERMISSION_REQUEST_CODE)\r\n      return;\r\n    mediaProjectionPermissionResultCode = resultCode;\r\n    mediaProjectionPermissionResultData = data;\r\n    startCall();\r\n  }\r\n\r\n  private boolean useCamera2() {\r\n    return Camera2Enumerator.isSupported(this) && getIntent().getBooleanExtra(EXTRA_CAMERA2, true);\r\n  }\r\n\r\n  private boolean captureToTexture() {\r\n    return getIntent().getBooleanExtra(EXTRA_CAPTURETOTEXTURE_ENABLED, false);\r\n  }\r\n\r\n  private @Nullable VideoCapturer createCameraCapturer(CameraEnumerator enumerator) {\r\n    final String[] deviceNames = enumerator.getDeviceNames();\r\n\r\n    // First, try to find front facing camera\r\n    Logging.d(TAG, \"Looking for front facing cameras.\");\r\n    for (String deviceName : deviceNames) {\r\n      if (enumerator.isFrontFacing(deviceName)) {\r\n        Logging.d(TAG, \"Creating front facing camera capturer.\");\r\n        VideoCapturer videoCapturer = enumerator.createCapturer(deviceName, null);\r\n\r\n        if (videoCapturer != null) {\r\n          return videoCapturer;\r\n        }\r\n      }\r\n    }\r\n\r\n    // Front facing camera not found, try something else\r\n    Logging.d(TAG, \"Looking for other cameras.\");\r\n    for (String deviceName : deviceNames) {\r\n      if (!enumerator.isFrontFacing(deviceName)) {\r\n        Logging.d(TAG, \"Creating other camera capturer.\");\r\n        VideoCapturer videoCapturer = enumerator.createCapturer(deviceName, null);\r\n\r\n        if (videoCapturer != null) {\r\n          return videoCapturer;\r\n        }\r\n      }\r\n    }\r\n\r\n    return null;\r\n  }\r\n\r\n  @TargetApi(21)\r\n  private @Nullable VideoCapturer createScreenCapturer() {\r\n    if (mediaProjectionPermissionResultCode != Activity.RESULT_OK) {\r\n      reportError(\"User didn't give permission to capture the screen.\");\r\n      return null;\r\n    }\r\n    return new ScreenCapturerAndroid(\r\n        mediaProjectionPermissionResultData, new MediaProjection.Callback() {\r\n      @Override\r\n      public void onStop() {\r\n        reportError(\"User revoked permission to capture the screen.\");\r\n      }\r\n    });\r\n  }\r\n\r\n  // Activity interfaces\r\n  @Override\r\n  public void onStop() {\r\n    super.onStop();\r\n    activityRunning = false;\r\n    // Don't stop the video when using screencapture to allow user to show other apps to the remote\r\n    // end.\r\n    if (peerConnectionClient != null && !screencaptureEnabled) {\r\n      peerConnectionClient.stopVideoSource();\r\n    }\r\n    if (cpuMonitor != null) {\r\n      cpuMonitor.pause();\r\n    }\r\n  }\r\n\r\n  @Override\r\n  public void onStart() {\r\n    super.onStart();\r\n    activityRunning = true;\r\n    // Video is not paused for screencapture. See onPause.\r\n    if (peerConnectionClient != null && !screencaptureEnabled) {\r\n      peerConnectionClient.startVideoSource();\r\n    }\r\n    if (cpuMonitor != null) {\r\n      cpuMonitor.resume();\r\n    }\r\n  }\r\n\r\n  @Override\r\n  protected void onDestroy() {\r\n    Thread.setDefaultUncaughtExceptionHandler(null);\r\n    disconnect();\r\n    if (logToast != null) {\r\n      logToast.cancel();\r\n    }\r\n    activityRunning = false;\r\n    super.onDestroy();\r\n  }\r\n\r\n  // CallFragment.OnCallEvents interface implementation.\r\n  @Override\r\n  public void onCallHangUp() {\r\n    disconnect();\r\n  }\r\n\r\n  @Override\r\n  public void onCameraSwitch() {\r\n    if (peerConnectionClient != null) {\r\n      peerConnectionClient.switchCamera();\r\n    }\r\n  }\r\n\r\n  @Override\r\n  public void onVideoScalingSwitch(ScalingType scalingType) {\r\n    fullscreenRenderer.setScalingType(scalingType);\r\n  }\r\n\r\n  @Override\r\n  public void onCaptureFormatChange(int width, int height, int framerate) {\r\n    if (peerConnectionClient != null) {\r\n      peerConnectionClient.changeCaptureFormat(width, height, framerate);\r\n    }\r\n  }\r\n\r\n  @Override\r\n  public boolean onToggleMic() {\r\n    if (peerConnectionClient != null) {\r\n      micEnabled = !micEnabled;\r\n      peerConnectionClient.setAudioEnabled(micEnabled);\r\n    }\r\n    return micEnabled;\r\n  }\r\n\r\n  // Helper functions.\r\n  private void toggleCallControlFragmentVisibility() {\r\n    if (!iceConnected || !callFragment.isAdded()) {\r\n      return;\r\n    }\r\n    // Show/hide call control fragment\r\n    callControlFragmentVisible = !callControlFragmentVisible;\r\n    FragmentTransaction ft = getFragmentManager().beginTransaction();\r\n    if (callControlFragmentVisible) {\r\n      ft.show(callFragment);\r\n      ft.show(hudFragment);\r\n    } else {\r\n      ft.hide(callFragment);\r\n      ft.hide(hudFragment);\r\n    }\r\n    ft.setTransition(FragmentTransaction.TRANSIT_FRAGMENT_FADE);\r\n    ft.commit();\r\n  }\r\n\r\n  private void startCall() {\r\n    if (appRtcClient == null) {\r\n      Log.e(TAG, \"AppRTC client is not allocated for a call.\");\r\n      return;\r\n    }\r\n    callStartedTimeMs = System.currentTimeMillis();\r\n\r\n    // Start room connection.\r\n    logAndToast(getString(org.appspot.apprtc.R.string.connecting_to, roomConnectionParameters.roomUrl));\r\n    appRtcClient.connectToRoom(roomConnectionParameters);\r\n\r\n    // Create and audio manager that will take care of audio routing,\r\n    // audio modes, audio device enumeration etc.\r\n    audioManager = AppRTCAudioManager.create(getApplicationContext());\r\n    // Store existing audio settings and change audio mode to\r\n    // MODE_IN_COMMUNICATION for best possible VoIP performance.\r\n    Log.d(TAG, \"Starting the audio manager...\");\r\n    audioManager.start(new AudioManagerEvents() {\r\n      // This method will be called each time the number of available audio\r\n      // devices has changed.\r\n      @Override\r\n      public void onAudioDeviceChanged(\r\n          AudioDevice audioDevice, Set<AudioDevice> availableAudioDevices) {\r\n        onAudioManagerDevicesChanged(audioDevice, availableAudioDevices);\r\n      }\r\n    });\r\n  }\r\n\r\n  // Should be called from UI thread\r\n  private void callConnected() {\r\n    final long delta = System.currentTimeMillis() - callStartedTimeMs;\r\n    Log.i(TAG, \"Call connected: delay=\" + delta + \"ms\");\r\n    if (peerConnectionClient == null || isError) {\r\n      Log.w(TAG, \"Call is connected in closed or error state\");\r\n      return;\r\n    }\r\n    // Enable statistics callback.\r\n    peerConnectionClient.enableStatsEvents(true, STAT_CALLBACK_PERIOD);\r\n    setSwappedFeeds(false /* isSwappedFeeds */);\r\n  }\r\n\r\n  // This method is called when the audio manager reports audio device change,\r\n  // e.g. from wired headset to speakerphone.\r\n  private void onAudioManagerDevicesChanged(\r\n      final AudioDevice device, final Set<AudioDevice> availableDevices) {\r\n    Log.d(TAG, \"onAudioManagerDevicesChanged: \" + availableDevices + \", \"\r\n            + \"selected: \" + device);\r\n    // TODO(henrika): add callback handler.\r\n  }\r\n\r\n  // Disconnect from remote resources, dispose of local resources, and exit.\r\n  private void disconnect() {\r\n    activityRunning = false;\r\n    remoteProxyRenderer.setTarget(null);\r\n    localProxyVideoSink.setTarget(null);\r\n    if (appRtcClient != null) {\r\n      appRtcClient.disconnectFromRoom();\r\n      appRtcClient = null;\r\n    }\r\n    if (pipRenderer != null) {\r\n      pipRenderer.release();\r\n      pipRenderer = null;\r\n    }\r\n    if (videoFileRenderer != null) {\r\n      videoFileRenderer.release();\r\n      videoFileRenderer = null;\r\n    }\r\n    if (fullscreenRenderer != null) {\r\n      fullscreenRenderer.release();\r\n      fullscreenRenderer = null;\r\n    }\r\n    if (peerConnectionClient != null) {\r\n      peerConnectionClient.close();\r\n      peerConnectionClient = null;\r\n    }\r\n    if (audioManager != null) {\r\n      audioManager.stop();\r\n      audioManager = null;\r\n    }\r\n    if (iceConnected && !isError) {\r\n      setResult(RESULT_OK);\r\n    } else {\r\n      setResult(RESULT_CANCELED);\r\n    }\r\n    finish();\r\n  }\r\n\r\n  private void disconnectWithErrorMessage(final String errorMessage) {\r\n    if (commandLineRun || !activityRunning) {\r\n      Log.e(TAG, \"Critical error: \" + errorMessage);\r\n      disconnect();\r\n    } else {\r\n      new AlertDialog.Builder(this)\r\n          .setTitle(getText(org.appspot.apprtc.R.string.channel_error_title))\r\n          .setMessage(errorMessage)\r\n          .setCancelable(false)\r\n          .setNeutralButton(org.appspot.apprtc.R.string.ok,\r\n              new DialogInterface.OnClickListener() {\r\n                @Override\r\n                public void onClick(DialogInterface dialog, int id) {\r\n                  dialog.cancel();\r\n                  disconnect();\r\n                }\r\n              })\r\n          .create()\r\n          .show();\r\n    }\r\n  }\r\n\r\n  // Log |msg| and Toast about it.\r\n  private void logAndToast(String msg) {\r\n    Log.d(TAG, msg);\r\n    if (logToast != null) {\r\n      logToast.cancel();\r\n    }\r\n    logToast = Toast.makeText(this, msg, Toast.LENGTH_SHORT);\r\n    logToast.show();\r\n  }\r\n\r\n  private void reportError(final String description) {\r\n    runOnUiThread(new Runnable() {\r\n      @Override\r\n      public void run() {\r\n        if (!isError) {\r\n          isError = true;\r\n          disconnectWithErrorMessage(description);\r\n        }\r\n      }\r\n    });\r\n  }\r\n\r\n  private @Nullable VideoCapturer createVideoCapturer() {\r\n    final VideoCapturer videoCapturer;\r\n    String videoFileAsCamera = getIntent().getStringExtra(EXTRA_VIDEO_FILE_AS_CAMERA);\r\n    if (videoFileAsCamera != null) {\r\n      try {\r\n        videoCapturer = new FileVideoCapturer(videoFileAsCamera);\r\n      } catch (IOException e) {\r\n        reportError(\"Failed to open video file for emulated camera\");\r\n        return null;\r\n      }\r\n    } else if (screencaptureEnabled) {\r\n      return createScreenCapturer();\r\n    } else if (useCamera2()) {\r\n      if (!captureToTexture()) {\r\n        reportError(getString(org.appspot.apprtc.R.string.camera2_texture_only_error));\r\n        return null;\r\n      }\r\n\r\n      Logging.d(TAG, \"Creating capturer using camera2 API.\");\r\n      videoCapturer = createCameraCapturer(new Camera2Enumerator(this));\r\n    } else {\r\n      Logging.d(TAG, \"Creating capturer using camera1 API.\");\r\n      videoCapturer = createCameraCapturer(new Camera1Enumerator(captureToTexture()));\r\n    }\r\n    if (videoCapturer == null) {\r\n      reportError(\"Failed to open camera\");\r\n      return null;\r\n    }\r\n    return videoCapturer;\r\n  }\r\n\r\n  private void setSwappedFeeds(boolean isSwappedFeeds) {\r\n    Logging.d(TAG, \"setSwappedFeeds: \" + isSwappedFeeds);\r\n    this.isSwappedFeeds = isSwappedFeeds;\r\n    localProxyVideoSink.setTarget(isSwappedFeeds ? fullscreenRenderer : pipRenderer);\r\n    remoteProxyRenderer.setTarget(isSwappedFeeds ? pipRenderer : fullscreenRenderer);\r\n    fullscreenRenderer.setMirror(isSwappedFeeds);\r\n    pipRenderer.setMirror(!isSwappedFeeds);\r\n  }\r\n\r\n  // -----Implementation of AppRTCClient.AppRTCSignalingEvents ---------------\r\n  // All callbacks are invoked from websocket signaling looper thread and\r\n  // are routed to UI thread.\r\n  private void onConnectedToRoomInternal(final SignalingParameters params) {\r\n    final long delta = System.currentTimeMillis() - callStartedTimeMs;\r\n\r\n    signalingParameters = params;\r\n    logAndToast(\"Creating peer connection, delay=\" + delta + \"ms\");\r\n    VideoCapturer videoCapturer = null;\r\n    if (peerConnectionParameters.videoCallEnabled) {\r\n      videoCapturer = createVideoCapturer();\r\n    }\r\n    peerConnectionClient.createPeerConnection(\r\n        localProxyVideoSink, remoteSinks, videoCapturer, signalingParameters);\r\n\r\n    if (signalingParameters.initiator) {\r\n      logAndToast(\"Creating OFFER...\");\r\n      // Create offer. Offer SDP will be sent to answering client in\r\n      // PeerConnectionEvents.onLocalDescription event.\r\n      peerConnectionClient.createOffer();\r\n    } else {\r\n      if (params.offerSdp != null) {\r\n        peerConnectionClient.setRemoteDescription(params.offerSdp);\r\n        logAndToast(\"Creating ANSWER...\");\r\n        // Create answer. Answer SDP will be sent to offering client in\r\n        // PeerConnectionEvents.onLocalDescription event.\r\n        peerConnectionClient.createAnswer();\r\n      }\r\n      if (params.iceCandidates != null) {\r\n        // Add remote ICE candidates from room.\r\n        for (IceCandidate iceCandidate : params.iceCandidates) {\r\n          peerConnectionClient.addRemoteIceCandidate(iceCandidate);\r\n        }\r\n      }\r\n    }\r\n  }\r\n\r\n  @Override\r\n  public void onConnectedToRoom(final SignalingParameters params) {\r\n    runOnUiThread(new Runnable() {\r\n      @Override\r\n      public void run() {\r\n        onConnectedToRoomInternal(params);\r\n      }\r\n    });\r\n  }\r\n\r\n  @Override\r\n  public void onRemoteDescription(final SessionDescription sdp) {\r\n    final long delta = System.currentTimeMillis() - callStartedTimeMs;\r\n    runOnUiThread(new Runnable() {\r\n      @Override\r\n      public void run() {\r\n        if (peerConnectionClient == null) {\r\n          Log.e(TAG, \"Received remote SDP for non-initilized peer connection.\");\r\n          return;\r\n        }\r\n        logAndToast(\"Received remote \" + sdp.type + \", delay=\" + delta + \"ms\");\r\n        peerConnectionClient.setRemoteDescription(sdp);\r\n        if (!signalingParameters.initiator) {\r\n          logAndToast(\"Creating ANSWER...\");\r\n          // Create answer. Answer SDP will be sent to offering client in\r\n          // PeerConnectionEvents.onLocalDescription event.\r\n          peerConnectionClient.createAnswer();\r\n        }\r\n      }\r\n    });\r\n  }\r\n\r\n  @Override\r\n  public void onRemoteIceCandidate(final IceCandidate candidate) {\r\n    runOnUiThread(new Runnable() {\r\n      @Override\r\n      public void run() {\r\n        if (peerConnectionClient == null) {\r\n          Log.e(TAG, \"Received ICE candidate for a non-initialized peer connection.\");\r\n          return;\r\n        }\r\n        peerConnectionClient.addRemoteIceCandidate(candidate);\r\n      }\r\n    });\r\n  }\r\n\r\n  @Override\r\n  public void onRemoteIceCandidatesRemoved(final IceCandidate[] candidates) {\r\n    runOnUiThread(new Runnable() {\r\n      @Override\r\n      public void run() {\r\n        if (peerConnectionClient == null) {\r\n          Log.e(TAG, \"Received ICE candidate removals for a non-initialized peer connection.\");\r\n          return;\r\n        }\r\n        peerConnectionClient.removeRemoteIceCandidates(candidates);\r\n      }\r\n    });\r\n  }\r\n\r\n  @Override\r\n  public void onChannelClose() {\r\n    runOnUiThread(new Runnable() {\r\n      @Override\r\n      public void run() {\r\n        logAndToast(\"Remote end hung up; dropping PeerConnection\");\r\n        disconnect();\r\n      }\r\n    });\r\n  }\r\n\r\n  @Override\r\n  public void onChannelError(final String description) {\r\n    reportError(description);\r\n  }\r\n\r\n  // -----Implementation of PeerConnectionClient.PeerConnectionEvents.---------\r\n  // Send local peer connection SDP and ICE candidates to remote party.\r\n  // All callbacks are invoked from peer connection client looper thread and\r\n  // are routed to UI thread.\r\n  @Override\r\n  public void onLocalDescription(final SessionDescription sdp) {\r\n    final long delta = System.currentTimeMillis() - callStartedTimeMs;\r\n    runOnUiThread(new Runnable() {\r\n      @Override\r\n      public void run() {\r\n        if (appRtcClient != null) {\r\n          logAndToast(\"Sending \" + sdp.type + \", delay=\" + delta + \"ms\");\r\n          if (signalingParameters.initiator) {\r\n            appRtcClient.sendOfferSdp(sdp);\r\n          } else {\r\n            appRtcClient.sendAnswerSdp(sdp);\r\n          }\r\n        }\r\n        if (peerConnectionParameters.videoMaxBitrate > 0) {\r\n          Log.d(TAG, \"Set video maximum bitrate: \" + peerConnectionParameters.videoMaxBitrate);\r\n          peerConnectionClient.setVideoMaxBitrate(peerConnectionParameters.videoMaxBitrate);\r\n        }\r\n      }\r\n    });\r\n  }\r\n\r\n  @Override\r\n  public void onIceCandidate(final IceCandidate candidate) {\r\n    runOnUiThread(new Runnable() {\r\n      @Override\r\n      public void run() {\r\n        if (appRtcClient != null) {\r\n          appRtcClient.sendLocalIceCandidate(candidate);\r\n        }\r\n      }\r\n    });\r\n  }\r\n\r\n  @Override\r\n  public void onIceCandidatesRemoved(final IceCandidate[] candidates) {\r\n    runOnUiThread(new Runnable() {\r\n      @Override\r\n      public void run() {\r\n        if (appRtcClient != null) {\r\n          appRtcClient.sendLocalIceCandidateRemovals(candidates);\r\n        }\r\n      }\r\n    });\r\n  }\r\n\r\n  @Override\r\n  public void onIceConnected() {\r\n    final long delta = System.currentTimeMillis() - callStartedTimeMs;\r\n    runOnUiThread(new Runnable() {\r\n      @Override\r\n      public void run() {\r\n        logAndToast(\"ICE connected, delay=\" + delta + \"ms\");\r\n        iceConnected = true;\r\n        callConnected();\r\n      }\r\n    });\r\n  }\r\n\r\n  @Override\r\n  public void onIceDisconnected() {\r\n    runOnUiThread(new Runnable() {\r\n      @Override\r\n      public void run() {\r\n        logAndToast(\"ICE disconnected\");\r\n        iceConnected = false;\r\n        disconnect();\r\n      }\r\n    });\r\n  }\r\n\r\n  @Override\r\n  public void onPeerConnectionClosed() {}\r\n\r\n  @Override\r\n  public void onPeerConnectionStatsReady(final StatsReport[] reports) {\r\n    runOnUiThread(new Runnable() {\r\n      @Override\r\n      public void run() {\r\n        if (!isError && iceConnected) {\r\n          hudFragment.updateEncoderStatistics(reports);\r\n        }\r\n      }\r\n    });\r\n  }\r\n\r\n  @Override\r\n  public void onPeerConnectionError(final String description) {\r\n    reportError(description);\r\n  }\r\n}\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/src/main/java/com/example/webrtc/android/CallActivity.java	(revision bf540945d88389d00f5acde8206c98ded8cdb2e7)
+++ app/src/main/java/com/example/webrtc/android/CallActivity.java	(date 1606285046345)
@@ -18,6 +18,10 @@
 import android.content.DialogInterface;
 import android.content.Intent;
 import android.content.pm.PackageManager;
+import android.content.res.AssetFileDescriptor;
+import android.graphics.Bitmap;
+import android.graphics.Color;
+import android.graphics.Matrix;
 import android.media.projection.MediaProjection;
 import android.media.projection.MediaProjectionManager;
 import android.net.Uri;
@@ -30,12 +34,19 @@
 import android.view.Window;
 import android.view.WindowManager;
 import android.view.WindowManager.LayoutParams;
+import android.widget.ImageView;
 import android.widget.Toast;
+
+import java.io.FileInputStream;
 import java.io.IOException;
 import java.lang.RuntimeException;
+import java.nio.ByteBuffer;
+import java.nio.MappedByteBuffer;
+import java.nio.channels.FileChannel;
 import java.util.ArrayList;
 import java.util.List;
 import java.util.Set;
+
 import javax.annotation.Nullable;
 
 import org.appspot.apprtc.AppRTCAudioManager;
@@ -51,6 +62,7 @@
 import org.appspot.apprtc.PeerConnectionClient.PeerConnectionParameters;
 import org.appspot.apprtc.UnhandledExceptionHandler;
 import org.appspot.apprtc.WebSocketRTCClient;
+import org.tensorflow.lite.Interpreter;
 import org.webrtc.Camera1Enumerator;
 import org.webrtc.Camera2Enumerator;
 import org.webrtc.CameraEnumerator;
@@ -69,893 +81,1040 @@
 import org.webrtc.VideoFrame;
 import org.webrtc.VideoSink;
 
+import static java.lang.Thread.sleep;
+
 /**
  * Activity for peer connection call setup, call waiting
  * and call view.
  */
 public class CallActivity extends Activity implements AppRTCClient.SignalingEvents,
-                                                      PeerConnectionClient.PeerConnectionEvents,
-                                                      CallFragment.OnCallEvents {
-  private static final String TAG = "CallRTCClient";
+        PeerConnectionClient.PeerConnectionEvents,
+        CallFragment.OnCallEvents {
+    private static final String TAG = "CallRTCClient";
 
-  public static final String EXTRA_ROOMID = "org.appspot.apprtc.ROOMID";
-  public static final String EXTRA_URLPARAMETERS = "org.appspot.apprtc.URLPARAMETERS";
-  public static final String EXTRA_LOOPBACK = "org.appspot.apprtc.LOOPBACK";
-  public static final String EXTRA_VIDEO_CALL = "org.appspot.apprtc.VIDEO_CALL";
-  public static final String EXTRA_SCREENCAPTURE = "org.appspot.apprtc.SCREENCAPTURE";
-  public static final String EXTRA_CAMERA2 = "org.appspot.apprtc.CAMERA2";
-  public static final String EXTRA_VIDEO_WIDTH = "org.appspot.apprtc.VIDEO_WIDTH";
-  public static final String EXTRA_VIDEO_HEIGHT = "org.appspot.apprtc.VIDEO_HEIGHT";
-  public static final String EXTRA_VIDEO_FPS = "org.appspot.apprtc.VIDEO_FPS";
-  public static final String EXTRA_VIDEO_CAPTUREQUALITYSLIDER_ENABLED =
-      "org.appsopt.apprtc.VIDEO_CAPTUREQUALITYSLIDER";
-  public static final String EXTRA_VIDEO_BITRATE = "org.appspot.apprtc.VIDEO_BITRATE";
-  public static final String EXTRA_VIDEOCODEC = "org.appspot.apprtc.VIDEOCODEC";
-  public static final String EXTRA_HWCODEC_ENABLED = "org.appspot.apprtc.HWCODEC";
-  public static final String EXTRA_CAPTURETOTEXTURE_ENABLED = "org.appspot.apprtc.CAPTURETOTEXTURE";
-  public static final String EXTRA_FLEXFEC_ENABLED = "org.appspot.apprtc.FLEXFEC";
-  public static final String EXTRA_AUDIO_BITRATE = "org.appspot.apprtc.AUDIO_BITRATE";
-  public static final String EXTRA_AUDIOCODEC = "org.appspot.apprtc.AUDIOCODEC";
-  public static final String EXTRA_NOAUDIOPROCESSING_ENABLED =
-      "org.appspot.apprtc.NOAUDIOPROCESSING";
-  public static final String EXTRA_AECDUMP_ENABLED = "org.appspot.apprtc.AECDUMP";
-  public static final String EXTRA_SAVE_INPUT_AUDIO_TO_FILE_ENABLED =
-      "org.appspot.apprtc.SAVE_INPUT_AUDIO_TO_FILE";
-  public static final String EXTRA_OPENSLES_ENABLED = "org.appspot.apprtc.OPENSLES";
-  public static final String EXTRA_DISABLE_BUILT_IN_AEC = "org.appspot.apprtc.DISABLE_BUILT_IN_AEC";
-  public static final String EXTRA_DISABLE_BUILT_IN_AGC = "org.appspot.apprtc.DISABLE_BUILT_IN_AGC";
-  public static final String EXTRA_DISABLE_BUILT_IN_NS = "org.appspot.apprtc.DISABLE_BUILT_IN_NS";
-  public static final String EXTRA_DISABLE_WEBRTC_AGC_AND_HPF =
-      "org.appspot.apprtc.DISABLE_WEBRTC_GAIN_CONTROL";
-  public static final String EXTRA_DISPLAY_HUD = "org.appspot.apprtc.DISPLAY_HUD";
-  public static final String EXTRA_TRACING = "org.appspot.apprtc.TRACING";
-  public static final String EXTRA_CMDLINE = "org.appspot.apprtc.CMDLINE";
-  public static final String EXTRA_RUNTIME = "org.appspot.apprtc.RUNTIME";
-  public static final String EXTRA_VIDEO_FILE_AS_CAMERA = "org.appspot.apprtc.VIDEO_FILE_AS_CAMERA";
-  public static final String EXTRA_SAVE_REMOTE_VIDEO_TO_FILE =
-      "org.appspot.apprtc.SAVE_REMOTE_VIDEO_TO_FILE";
-  public static final String EXTRA_SAVE_REMOTE_VIDEO_TO_FILE_WIDTH =
-      "org.appspot.apprtc.SAVE_REMOTE_VIDEO_TO_FILE_WIDTH";
-  public static final String EXTRA_SAVE_REMOTE_VIDEO_TO_FILE_HEIGHT =
-      "org.appspot.apprtc.SAVE_REMOTE_VIDEO_TO_FILE_HEIGHT";
-  public static final String EXTRA_USE_VALUES_FROM_INTENT =
-      "org.appspot.apprtc.USE_VALUES_FROM_INTENT";
-  public static final String EXTRA_DATA_CHANNEL_ENABLED = "org.appspot.apprtc.DATA_CHANNEL_ENABLED";
-  public static final String EXTRA_ORDERED = "org.appspot.apprtc.ORDERED";
-  public static final String EXTRA_MAX_RETRANSMITS_MS = "org.appspot.apprtc.MAX_RETRANSMITS_MS";
-  public static final String EXTRA_MAX_RETRANSMITS = "org.appspot.apprtc.MAX_RETRANSMITS";
-  public static final String EXTRA_PROTOCOL = "org.appspot.apprtc.PROTOCOL";
-  public static final String EXTRA_NEGOTIATED = "org.appspot.apprtc.NEGOTIATED";
-  public static final String EXTRA_ID = "org.appspot.apprtc.ID";
-  public static final String EXTRA_ENABLE_RTCEVENTLOG = "org.appspot.apprtc.ENABLE_RTCEVENTLOG";
-  public static final String EXTRA_USE_LEGACY_AUDIO_DEVICE =
-      "org.appspot.apprtc.USE_LEGACY_AUDIO_DEVICE";
+    public static final String EXTRA_ROOMID = "org.appspot.apprtc.ROOMID";
+    public static final String EXTRA_URLPARAMETERS = "org.appspot.apprtc.URLPARAMETERS";
+    public static final String EXTRA_LOOPBACK = "org.appspot.apprtc.LOOPBACK";
+    public static final String EXTRA_VIDEO_CALL = "org.appspot.apprtc.VIDEO_CALL";
+    public static final String EXTRA_SCREENCAPTURE = "org.appspot.apprtc.SCREENCAPTURE";
+    public static final String EXTRA_CAMERA2 = "org.appspot.apprtc.CAMERA2";
+    public static final String EXTRA_VIDEO_WIDTH = "org.appspot.apprtc.VIDEO_WIDTH";
+    public static final String EXTRA_VIDEO_HEIGHT = "org.appspot.apprtc.VIDEO_HEIGHT";
+    public static final String EXTRA_VIDEO_FPS = "org.appspot.apprtc.VIDEO_FPS";
+    public static final String EXTRA_VIDEO_CAPTUREQUALITYSLIDER_ENABLED =
+            "org.appsopt.apprtc.VIDEO_CAPTUREQUALITYSLIDER";
+    public static final String EXTRA_VIDEO_BITRATE = "org.appspot.apprtc.VIDEO_BITRATE";
+    public static final String EXTRA_VIDEOCODEC = "org.appspot.apprtc.VIDEOCODEC";
+    public static final String EXTRA_HWCODEC_ENABLED = "org.appspot.apprtc.HWCODEC";
+    public static final String EXTRA_CAPTURETOTEXTURE_ENABLED = "org.appspot.apprtc.CAPTURETOTEXTURE";
+    public static final String EXTRA_FLEXFEC_ENABLED = "org.appspot.apprtc.FLEXFEC";
+    public static final String EXTRA_AUDIO_BITRATE = "org.appspot.apprtc.AUDIO_BITRATE";
+    public static final String EXTRA_AUDIOCODEC = "org.appspot.apprtc.AUDIOCODEC";
+    public static final String EXTRA_NOAUDIOPROCESSING_ENABLED =
+            "org.appspot.apprtc.NOAUDIOPROCESSING";
+    public static final String EXTRA_AECDUMP_ENABLED = "org.appspot.apprtc.AECDUMP";
+    public static final String EXTRA_SAVE_INPUT_AUDIO_TO_FILE_ENABLED =
+            "org.appspot.apprtc.SAVE_INPUT_AUDIO_TO_FILE";
+    public static final String EXTRA_OPENSLES_ENABLED = "org.appspot.apprtc.OPENSLES";
+    public static final String EXTRA_DISABLE_BUILT_IN_AEC = "org.appspot.apprtc.DISABLE_BUILT_IN_AEC";
+    public static final String EXTRA_DISABLE_BUILT_IN_AGC = "org.appspot.apprtc.DISABLE_BUILT_IN_AGC";
+    public static final String EXTRA_DISABLE_BUILT_IN_NS = "org.appspot.apprtc.DISABLE_BUILT_IN_NS";
+    public static final String EXTRA_DISABLE_WEBRTC_AGC_AND_HPF =
+            "org.appspot.apprtc.DISABLE_WEBRTC_GAIN_CONTROL";
+    public static final String EXTRA_DISPLAY_HUD = "org.appspot.apprtc.DISPLAY_HUD";
+    public static final String EXTRA_TRACING = "org.appspot.apprtc.TRACING";
+    public static final String EXTRA_CMDLINE = "org.appspot.apprtc.CMDLINE";
+    public static final String EXTRA_RUNTIME = "org.appspot.apprtc.RUNTIME";
+    public static final String EXTRA_VIDEO_FILE_AS_CAMERA = "org.appspot.apprtc.VIDEO_FILE_AS_CAMERA";
+    public static final String EXTRA_SAVE_REMOTE_VIDEO_TO_FILE =
+            "org.appspot.apprtc.SAVE_REMOTE_VIDEO_TO_FILE";
+    public static final String EXTRA_SAVE_REMOTE_VIDEO_TO_FILE_WIDTH =
+            "org.appspot.apprtc.SAVE_REMOTE_VIDEO_TO_FILE_WIDTH";
+    public static final String EXTRA_SAVE_REMOTE_VIDEO_TO_FILE_HEIGHT =
+            "org.appspot.apprtc.SAVE_REMOTE_VIDEO_TO_FILE_HEIGHT";
+    public static final String EXTRA_USE_VALUES_FROM_INTENT =
+            "org.appspot.apprtc.USE_VALUES_FROM_INTENT";
+    public static final String EXTRA_DATA_CHANNEL_ENABLED = "org.appspot.apprtc.DATA_CHANNEL_ENABLED";
+    public static final String EXTRA_ORDERED = "org.appspot.apprtc.ORDERED";
+    public static final String EXTRA_MAX_RETRANSMITS_MS = "org.appspot.apprtc.MAX_RETRANSMITS_MS";
+    public static final String EXTRA_MAX_RETRANSMITS = "org.appspot.apprtc.MAX_RETRANSMITS";
+    public static final String EXTRA_PROTOCOL = "org.appspot.apprtc.PROTOCOL";
+    public static final String EXTRA_NEGOTIATED = "org.appspot.apprtc.NEGOTIATED";
+    public static final String EXTRA_ID = "org.appspot.apprtc.ID";
+    public static final String EXTRA_ENABLE_RTCEVENTLOG = "org.appspot.apprtc.ENABLE_RTCEVENTLOG";
+    public static final String EXTRA_USE_LEGACY_AUDIO_DEVICE =
+            "org.appspot.apprtc.USE_LEGACY_AUDIO_DEVICE";
 
-  private static final int CAPTURE_PERMISSION_REQUEST_CODE = 1;
+    private static final int CAPTURE_PERMISSION_REQUEST_CODE = 1;
 
-  // List of mandatory application permissions.
-  private static final String[] MANDATORY_PERMISSIONS = {"android.permission.MODIFY_AUDIO_SETTINGS",
-      "android.permission.RECORD_AUDIO", "android.permission.INTERNET"};
+    // List of mandatory application permissions.
+    private static final String[] MANDATORY_PERMISSIONS = {"android.permission.MODIFY_AUDIO_SETTINGS",
+            "android.permission.RECORD_AUDIO", "android.permission.INTERNET"};
 
-  // Peer connection statistics callback period in ms.
-  private static final int STAT_CALLBACK_PERIOD = 1000;
+    // Peer connection statistics callback period in ms.
+    private static final int STAT_CALLBACK_PERIOD = 1000;
+    //-------------------------------
+    static Interpreter tflite1;
+    public static int count1 = 0;
+    public static int index1 = 0;
+    public static int[] arr1 = new int[3];      //0(up) 1(down)
+    public static boolean up1 = true;
+    public static boolean down1 = false;
+    private static boolean game_end1 = false;
+
 
-  private static class ProxyVideoSink implements VideoSink {
-    private VideoSink target;
+    private static class ProxyVideoSink implements VideoSink {
+        private VideoSink target;
 
-    @Override
-    synchronized public void onFrame(VideoFrame frame) {
-      if (target == null) {
-        Logging.d(TAG, "Dropping frame in proxy because target is null.");
-        return;
-      }
+        // 여기다!!!!!!!!!!!
+        @Override
+        synchronized public void onFrame(VideoFrame frame) {
+            if (target == null) {
+                Logging.d(TAG, "Dropping frame in proxy because target is null.");
+                return;
+            }
 
-      target.onFrame(frame);
-    }
+            frame.getBuffer().toI420().getDataY();
+            ByteBuffer y = frame.getBuffer().toI420().getDataY();
+            ByteBuffer u = frame.getBuffer().toI420().getDataY();
+            ByteBuffer v = frame.getBuffer().toI420().getDataY();
+            final int[] rgb = convert(y, u, v, frame.getBuffer().getWidth(), frame.getBuffer().getHeight());
+
+            Bitmap bmp = Bitmap.createBitmap(rgb, frame.getBuffer().getWidth(), frame.getBuffer().getHeight(), Bitmap.Config.ARGB_8888);
+            bmp = Bitmap.createScaledBitmap(bmp, 224, 224, false);
+
+            Matrix rotateMatrix = new Matrix();
+            rotateMatrix.postRotate(90);
+
+            bmp = Bitmap.createBitmap(bmp, 0, 0,
+                    bmp.getWidth(), bmp.getHeight(), rotateMatrix, false);
+
+            //모델 적용을 위해
+            float[][][][] inputs = new float[1][224][224][3];       //1 * width * height * RGB
+            float[][] outputs = new float[1][2];
+            for (int x = 0; x < 224; x++) {
+                for (int k = 0; k < 224; k++) {
+                    int pixel = bmp.getPixel(x, k);
+                    inputs[0][k][x][0] = (Color.red(pixel)) / 255.0f;
+                    inputs[0][k][x][1] = (Color.green(pixel)) / 255.0f;
+                    inputs[0][k][x][2] = (Color.blue(pixel)) / 255.0f;
+                }
+            }
+
+            tflite1.run(inputs, outputs);
+
+            //서있을때
+            if (outputs[0][0] > outputs[0][1]) {
+                System.out.println("UP!!!!");
+                //tv_result.setText("up");
+                //determine(0);
+            }
+            //앉아있을때
+            else {
+                System.out.println("DOWN!!!!");
+                //tv_result.setText("down");
+                //determine(1);
+            }
+
+            target.onFrame(frame);
+        }
 
-    synchronized public void setTarget(VideoSink target) {
-      this.target = target;
-    }
-  }
+        synchronized public void setTarget(VideoSink target) {
+            this.target = target;
+        }
+    }
 
-  private final ProxyVideoSink remoteProxyRenderer = new ProxyVideoSink();
-  private final ProxyVideoSink localProxyVideoSink = new ProxyVideoSink();
-  @Nullable
-  private PeerConnectionClient peerConnectionClient = null;
-  @Nullable
-  private AppRTCClient appRtcClient;
-  @Nullable
-  private SignalingParameters signalingParameters;
-  @Nullable
-  private AppRTCAudioManager audioManager = null;
-  @Nullable
-  private SurfaceViewRenderer pipRenderer;
-  @Nullable
-  private SurfaceViewRenderer fullscreenRenderer;
-  @Nullable
-  private VideoFileRenderer videoFileRenderer;
-  private final List<VideoSink> remoteSinks = new ArrayList<>();
-  private Toast logToast;
-  private boolean commandLineRun;
-  private boolean activityRunning;
-  private RoomConnectionParameters roomConnectionParameters;
-  @Nullable
-  private PeerConnectionParameters peerConnectionParameters;
-  private boolean iceConnected;
-  private boolean isError;
-  private boolean callControlFragmentVisible = true;
-  private long callStartedTimeMs = 0;
-  private boolean micEnabled = true;
-  private boolean screencaptureEnabled = false;
-  private static Intent mediaProjectionPermissionResultData;
-  private static int mediaProjectionPermissionResultCode;
-  // True if local view is in the fullscreen renderer.
-  private boolean isSwappedFeeds;
+
+    private MappedByteBuffer loadModelFile1(Activity activity, String modelPath) throws IOException {
+        AssetFileDescriptor fileDescriptor = activity.getAssets().openFd(modelPath);
+        FileInputStream inputStream = new FileInputStream(fileDescriptor.getFileDescriptor());
+        FileChannel fileChannel = inputStream.getChannel();
+        long startOffset = fileDescriptor.getStartOffset();
+        long declaredLength = fileDescriptor.getDeclaredLength();
+        return fileChannel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength);
+    }
+
+    //모델 로드 국룰
+    private Interpreter getTfliteInterpreter(String modelPath) {
+        try {
+            return new Interpreter(loadModelFile1(CallActivity.this, modelPath));
+        } catch (Exception e) {
+            e.printStackTrace();
+        }
+        return null;
+    }
+
+    //판단 (up,down) 카운팅
+    public static void determine(int n) {
+        if (index1 == 0 || index1 == 1) {
+            arr1[index1] = n;
+            index1++;
+        }
+        //index가 2이면 마지막꺼만 비어있는 상태
+        else {
+            //우선 넣어주고
+            arr1[index1] = n;
+            //판단
+            if (arr1[0] == arr1[1] && arr1[1] == arr1[2]) {
+                //down이 true인 상태에서 up인상태이면 count++
+                if (arr1[0] == 0) {
+                    if (down1) {
+                        down1 = false;
+                        count1++;
+                        System.out.println(count1);
+                        //tv_count = findViewById(R.id.tv_count);
+                        //tv_count.setText(Integer.toString(count));
+
+                        //10개 채웠으면 game_end!
+                        if (count1 >= 3) game_end1 = true;
+                    }
+                }
+                //down
+                else {
+                    down1 = true;
+                }
+            }
+            //앞에껄 지우고 옮겨줌
+            arr1[0] = arr1[1];
+            arr1[1] = arr1[2];
+            arr1[2] = -1;
+        }
+
+    }
+
+    //rgb추출
+    public static int[] convert(ByteBuffer y, ByteBuffer u, ByteBuffer v, int width, int height) {
+        final int frameSize = width * height;
+        int rgb[] = new int[width * height];
+        for (int j = 0, yp = 0; j < frameSize; j++, yp++) {
+            int y_value = y.get(j);
+            int u_value = u.get(j);
+            int v_value = v.get(j);
+
+            int y1192 = 1192 * y_value;
+            int r = (y1192 + 1634 * v_value);
+            int g = (y1192 - 833 * v_value - 400 * u_value);
+            int b = (y1192 + 2066 * u_value);
+
+            if (r < 0) r = 0;
+            else if (r > 262143) r = 262143;
+            if (g < 0) g = 0;
+            else if (g > 262143) g = 262143;
+            if (b < 0) b = 0;
+            else if (b > 262143) b = 262143;
+
+            rgb[yp] = 0xff000000 | ((r << 6) & 0xff0000) | ((g >> 2) &
+                    0xff00) | ((b >> 10) & 0xff);
+        }
+        return rgb;
+    }
+
+
+    private final ProxyVideoSink remoteProxyRenderer = new ProxyVideoSink();
+    private final ProxyVideoSink localProxyVideoSink = new ProxyVideoSink();
+    @Nullable
+    private PeerConnectionClient peerConnectionClient = null;
+    @Nullable
+    private AppRTCClient appRtcClient;
+    @Nullable
+    private SignalingParameters signalingParameters;
+    @Nullable
+    private AppRTCAudioManager audioManager = null;
+    @Nullable
+    private SurfaceViewRenderer pipRenderer;
+    @Nullable
+    private SurfaceViewRenderer fullscreenRenderer;
+    @Nullable
+    private VideoFileRenderer videoFileRenderer;
+    private final List<VideoSink> remoteSinks = new ArrayList<>();
+    private Toast logToast;
+    private boolean commandLineRun;
+    private boolean activityRunning;
+    private RoomConnectionParameters roomConnectionParameters;
+    @Nullable
+    private PeerConnectionParameters peerConnectionParameters;
+    private boolean iceConnected;
+    private boolean isError;
+    private boolean callControlFragmentVisible = true;
+    private long callStartedTimeMs = 0;
+    private boolean micEnabled = true;
+    private boolean screencaptureEnabled = false;
+    private static Intent mediaProjectionPermissionResultData;
+    private static int mediaProjectionPermissionResultCode;
+    // True if local view is in the fullscreen renderer.
+    private boolean isSwappedFeeds;
 
-  // Controls
-  private CallFragment callFragment;
-  private HudFragment hudFragment;
-  private CpuMonitor cpuMonitor;
+    // Controls
+    private CallFragment callFragment;
+    private HudFragment hudFragment;
+    private CpuMonitor cpuMonitor;
+    static ImageView iv_my;
+
 
-  @Override
-  // TODO(bugs.webrtc.org/8580): LayoutParams.FLAG_TURN_SCREEN_ON and
-  // LayoutParams.FLAG_SHOW_WHEN_LOCKED are deprecated.
-  @SuppressWarnings("deprecation")
-  public void onCreate(Bundle savedInstanceState) {
-    super.onCreate(savedInstanceState);
-    Thread.setDefaultUncaughtExceptionHandler(new UnhandledExceptionHandler(this));
+    @Override
+    // TODO(bugs.webrtc.org/8580): LayoutParams.FLAG_TURN_SCREEN_ON and
+    // LayoutParams.FLAG_SHOW_WHEN_LOCKED are deprecated.
+    @SuppressWarnings("deprecation")
+    public void onCreate(Bundle savedInstanceState) {
+        super.onCreate(savedInstanceState);
+        Thread.setDefaultUncaughtExceptionHandler(new UnhandledExceptionHandler(this));
 
-    // Set window styles for fullscreen-window size. Needs to be done before
-    // adding content.
-    requestWindowFeature(Window.FEATURE_NO_TITLE);
-    getWindow().addFlags(LayoutParams.FLAG_FULLSCREEN | LayoutParams.FLAG_KEEP_SCREEN_ON
-        | LayoutParams.FLAG_SHOW_WHEN_LOCKED | LayoutParams.FLAG_TURN_SCREEN_ON);
-    getWindow().getDecorView().setSystemUiVisibility(getSystemUiVisibility());
-    setContentView(R.layout.activity_call);
+        // Set window styles for fullscreen-window size. Needs to be done before
+        // adding content.
+        requestWindowFeature(Window.FEATURE_NO_TITLE);
+        getWindow().addFlags(LayoutParams.FLAG_FULLSCREEN | LayoutParams.FLAG_KEEP_SCREEN_ON
+                | LayoutParams.FLAG_SHOW_WHEN_LOCKED | LayoutParams.FLAG_TURN_SCREEN_ON);
+        getWindow().getDecorView().setSystemUiVisibility(getSystemUiVisibility());
+        setContentView(R.layout.activity_call);
 
-    iceConnected = false;
-    signalingParameters = null;
-
-    // Create UI controls.
-    pipRenderer = findViewById(R.id.pip_video_view);
-    fullscreenRenderer = findViewById(R.id.fullscreen_video_view);
-    callFragment = new CallFragment();
-    hudFragment = new HudFragment();
+        iceConnected = false;
+        signalingParameters = null;
+        // Create UI controls.
+        pipRenderer = findViewById(R.id.pip_video_view);
+        fullscreenRenderer = findViewById(R.id.fullscreen_video_view);
+        callFragment = new CallFragment();
+        hudFragment = new HudFragment();
+        tflite1 = getTfliteInterpreter("model.tflite");
+
 
-    // Show/hide call control fragment on view click.
-    View.OnClickListener listener = new View.OnClickListener() {
-      @Override
-      public void onClick(View view) {
-        toggleCallControlFragmentVisibility();
-      }
-    };
+        // Show/hide call control fragment on view click.
+        View.OnClickListener listener = new View.OnClickListener() {
+            @Override
+            public void onClick(View view) {
+                toggleCallControlFragmentVisibility();
+            }
+        };
 
-    // Swap feeds on pip view click.
-    pipRenderer.setOnClickListener(new View.OnClickListener() {
-      @Override
-      public void onClick(View view) {
-        setSwappedFeeds(!isSwappedFeeds);
-      }
-    });
+        // Swap feeds on pip view click.
+        pipRenderer.setOnClickListener(new View.OnClickListener() {
+            @Override
+            public void onClick(View view) {
+                setSwappedFeeds(!isSwappedFeeds);
+            }
+        });
 
-    fullscreenRenderer.setOnClickListener(listener);
-    remoteSinks.add(remoteProxyRenderer);
+        fullscreenRenderer.setOnClickListener(listener);
+        remoteSinks.add(remoteProxyRenderer);
 
-    final Intent intent = getIntent();
-    final EglBase eglBase = EglBase.create();
+        final Intent intent = getIntent();
+        final EglBase eglBase = EglBase.create();
 
-    // Create video renderers.
-    pipRenderer.init(eglBase.getEglBaseContext(), null);
-    pipRenderer.setScalingType(ScalingType.SCALE_ASPECT_FIT);
-    String saveRemoteVideoToFile = intent.getStringExtra(EXTRA_SAVE_REMOTE_VIDEO_TO_FILE);
+        // Create video renderers.
+        pipRenderer.init(eglBase.getEglBaseContext(), null);
+        pipRenderer.setScalingType(ScalingType.SCALE_ASPECT_FIT);
+        String saveRemoteVideoToFile = intent.getStringExtra(EXTRA_SAVE_REMOTE_VIDEO_TO_FILE);
 
-    // When saveRemoteVideoToFile is set we save the video from the remote to a file.
-    if (saveRemoteVideoToFile != null) {
-      int videoOutWidth = intent.getIntExtra(EXTRA_SAVE_REMOTE_VIDEO_TO_FILE_WIDTH, 0);
-      int videoOutHeight = intent.getIntExtra(EXTRA_SAVE_REMOTE_VIDEO_TO_FILE_HEIGHT, 0);
-      try {
-        videoFileRenderer = new VideoFileRenderer(
-            saveRemoteVideoToFile, videoOutWidth, videoOutHeight, eglBase.getEglBaseContext());
-        remoteSinks.add(videoFileRenderer);
-      } catch (IOException e) {
-        throw new RuntimeException(
-            "Failed to open video file for output: " + saveRemoteVideoToFile, e);
-      }
-    }
-    fullscreenRenderer.init(eglBase.getEglBaseContext(), null);
-    fullscreenRenderer.setScalingType(ScalingType.SCALE_ASPECT_FILL);
+        // When saveRemoteVideoToFile is set we save the video from the remote to a file.
+        if (saveRemoteVideoToFile != null) {
+            int videoOutWidth = intent.getIntExtra(EXTRA_SAVE_REMOTE_VIDEO_TO_FILE_WIDTH, 0);
+            int videoOutHeight = intent.getIntExtra(EXTRA_SAVE_REMOTE_VIDEO_TO_FILE_HEIGHT, 0);
+            try {
+                videoFileRenderer = new VideoFileRenderer(
+                        saveRemoteVideoToFile, videoOutWidth, videoOutHeight, eglBase.getEglBaseContext());
+                remoteSinks.add(videoFileRenderer);
+            } catch (IOException e) {
+                throw new RuntimeException(
+                        "Failed to open video file for output: " + saveRemoteVideoToFile, e);
+            }
+        }
+        fullscreenRenderer.init(eglBase.getEglBaseContext(), null);
+        fullscreenRenderer.setScalingType(ScalingType.SCALE_ASPECT_FILL);
 
-    pipRenderer.setZOrderMediaOverlay(true);
-    pipRenderer.setEnableHardwareScaler(true /* enabled */);
-    fullscreenRenderer.setEnableHardwareScaler(false /* enabled */);
-    // Start with local feed in fullscreen and swap it to the pip when the call is connected.
-    setSwappedFeeds(true /* isSwappedFeeds */);
+        pipRenderer.setZOrderMediaOverlay(true);
+        pipRenderer.setEnableHardwareScaler(true /* enabled */);
+        fullscreenRenderer.setEnableHardwareScaler(false /* enabled */);
+        // Start with local feed in fullscreen and swap it to the pip when the call is connected.
+        setSwappedFeeds(true /* isSwappedFeeds */);
 
-    // Check for mandatory permissions.
-    for (String permission : MANDATORY_PERMISSIONS) {
-      if (checkCallingOrSelfPermission(permission) != PackageManager.PERMISSION_GRANTED) {
-        logAndToast("Permission " + permission + " is not granted");
-        setResult(RESULT_CANCELED);
-        finish();
-        return;
-      }
-    }
+        // Check for mandatory permissions.
+        for (String permission : MANDATORY_PERMISSIONS) {
+            if (checkCallingOrSelfPermission(permission) != PackageManager.PERMISSION_GRANTED) {
+                logAndToast("Permission " + permission + " is not granted");
+                setResult(RESULT_CANCELED);
+                finish();
+                return;
+            }
+        }
 
-    Uri roomUri = intent.getData();
-    if (roomUri == null) {
-      logAndToast(getString(org.appspot.apprtc.R.string.missing_url));
-      Log.e(TAG, "Didn't get any URL in intent!");
-      setResult(RESULT_CANCELED);
-      finish();
-      return;
-    }
+        Uri roomUri = intent.getData();
+        if (roomUri == null) {
+            logAndToast(getString(org.appspot.apprtc.R.string.missing_url));
+            Log.e(TAG, "Didn't get any URL in intent!");
+            setResult(RESULT_CANCELED);
+            finish();
+            return;
+        }
 
-    // Get Intent parameters.
-    String roomId = intent.getStringExtra(EXTRA_ROOMID);
-    Log.d(TAG, "Room ID: " + roomId);
-    if (roomId == null || roomId.length() == 0) {
-      logAndToast(getString(org.appspot.apprtc.R.string.missing_url));
-      Log.e(TAG, "Incorrect room ID in intent!");
-      setResult(RESULT_CANCELED);
-      finish();
-      return;
-    }
+        // Get Intent parameters.
+        String roomId = intent.getStringExtra(EXTRA_ROOMID);
+        Log.d(TAG, "Room ID: " + roomId);
+        if (roomId == null || roomId.length() == 0) {
+            logAndToast(getString(org.appspot.apprtc.R.string.missing_url));
+            Log.e(TAG, "Incorrect room ID in intent!");
+            setResult(RESULT_CANCELED);
+            finish();
+            return;
+        }
 
-    boolean loopback = intent.getBooleanExtra(EXTRA_LOOPBACK, false);
-    boolean tracing = intent.getBooleanExtra(EXTRA_TRACING, false);
+        boolean loopback = intent.getBooleanExtra(EXTRA_LOOPBACK, false);
+        boolean tracing = intent.getBooleanExtra(EXTRA_TRACING, false);
 
-    int videoWidth = intent.getIntExtra(EXTRA_VIDEO_WIDTH, 0);
-    int videoHeight = intent.getIntExtra(EXTRA_VIDEO_HEIGHT, 0);
+        int videoWidth = intent.getIntExtra(EXTRA_VIDEO_WIDTH, 0);
+        int videoHeight = intent.getIntExtra(EXTRA_VIDEO_HEIGHT, 0);
 
-    screencaptureEnabled = intent.getBooleanExtra(EXTRA_SCREENCAPTURE, false);
-    // If capturing format is not specified for screencapture, use screen resolution.
-    if (screencaptureEnabled && videoWidth == 0 && videoHeight == 0) {
-      DisplayMetrics displayMetrics = getDisplayMetrics();
-      videoWidth = displayMetrics.widthPixels;
-      videoHeight = displayMetrics.heightPixels;
-    }
-    DataChannelParameters dataChannelParameters = null;
-    if (intent.getBooleanExtra(EXTRA_DATA_CHANNEL_ENABLED, false)) {
-      dataChannelParameters = new DataChannelParameters(intent.getBooleanExtra(EXTRA_ORDERED, true),
-          intent.getIntExtra(EXTRA_MAX_RETRANSMITS_MS, -1),
-          intent.getIntExtra(EXTRA_MAX_RETRANSMITS, -1), intent.getStringExtra(EXTRA_PROTOCOL),
-          intent.getBooleanExtra(EXTRA_NEGOTIATED, false), intent.getIntExtra(EXTRA_ID, -1));
-    }
-    peerConnectionParameters =
-        new PeerConnectionParameters(intent.getBooleanExtra(EXTRA_VIDEO_CALL, true), loopback,
-            tracing, videoWidth, videoHeight, intent.getIntExtra(EXTRA_VIDEO_FPS, 0),
-            intent.getIntExtra(EXTRA_VIDEO_BITRATE, 0), intent.getStringExtra(EXTRA_VIDEOCODEC),
-            intent.getBooleanExtra(EXTRA_HWCODEC_ENABLED, true),
-            intent.getBooleanExtra(EXTRA_FLEXFEC_ENABLED, false),
-            intent.getIntExtra(EXTRA_AUDIO_BITRATE, 0), intent.getStringExtra(EXTRA_AUDIOCODEC),
-            intent.getBooleanExtra(EXTRA_NOAUDIOPROCESSING_ENABLED, false),
-            intent.getBooleanExtra(EXTRA_AECDUMP_ENABLED, false),
-            intent.getBooleanExtra(EXTRA_SAVE_INPUT_AUDIO_TO_FILE_ENABLED, false),
-            intent.getBooleanExtra(EXTRA_OPENSLES_ENABLED, false),
-            intent.getBooleanExtra(EXTRA_DISABLE_BUILT_IN_AEC, false),
-            intent.getBooleanExtra(EXTRA_DISABLE_BUILT_IN_AGC, false),
-            intent.getBooleanExtra(EXTRA_DISABLE_BUILT_IN_NS, false),
-            intent.getBooleanExtra(EXTRA_DISABLE_WEBRTC_AGC_AND_HPF, false),
-            intent.getBooleanExtra(EXTRA_ENABLE_RTCEVENTLOG, false),
-            intent.getBooleanExtra(EXTRA_USE_LEGACY_AUDIO_DEVICE, false), dataChannelParameters);
-    commandLineRun = intent.getBooleanExtra(EXTRA_CMDLINE, false);
-    int runTimeMs = intent.getIntExtra(EXTRA_RUNTIME, 0);
+        screencaptureEnabled = intent.getBooleanExtra(EXTRA_SCREENCAPTURE, false);
+        // If capturing format is not specified for screencapture, use screen resolution.
+        if (screencaptureEnabled && videoWidth == 0 && videoHeight == 0) {
+            DisplayMetrics displayMetrics = getDisplayMetrics();
+            videoWidth = displayMetrics.widthPixels;
+            videoHeight = displayMetrics.heightPixels;
+        }
+        DataChannelParameters dataChannelParameters = null;
+        if (intent.getBooleanExtra(EXTRA_DATA_CHANNEL_ENABLED, false)) {
+            dataChannelParameters = new DataChannelParameters(intent.getBooleanExtra(EXTRA_ORDERED, true),
+                    intent.getIntExtra(EXTRA_MAX_RETRANSMITS_MS, -1),
+                    intent.getIntExtra(EXTRA_MAX_RETRANSMITS, -1), intent.getStringExtra(EXTRA_PROTOCOL),
+                    intent.getBooleanExtra(EXTRA_NEGOTIATED, false), intent.getIntExtra(EXTRA_ID, -1));
+        }
+        peerConnectionParameters =
+                new PeerConnectionParameters(intent.getBooleanExtra(EXTRA_VIDEO_CALL, true), loopback,
+                        tracing, videoWidth, videoHeight, intent.getIntExtra(EXTRA_VIDEO_FPS, 0),
+                        intent.getIntExtra(EXTRA_VIDEO_BITRATE, 0), intent.getStringExtra(EXTRA_VIDEOCODEC),
+                        intent.getBooleanExtra(EXTRA_HWCODEC_ENABLED, true),
+                        intent.getBooleanExtra(EXTRA_FLEXFEC_ENABLED, false),
+                        intent.getIntExtra(EXTRA_AUDIO_BITRATE, 0), intent.getStringExtra(EXTRA_AUDIOCODEC),
+                        intent.getBooleanExtra(EXTRA_NOAUDIOPROCESSING_ENABLED, false),
+                        intent.getBooleanExtra(EXTRA_AECDUMP_ENABLED, false),
+                        intent.getBooleanExtra(EXTRA_SAVE_INPUT_AUDIO_TO_FILE_ENABLED, false),
+                        intent.getBooleanExtra(EXTRA_OPENSLES_ENABLED, false),
+                        intent.getBooleanExtra(EXTRA_DISABLE_BUILT_IN_AEC, false),
+                        intent.getBooleanExtra(EXTRA_DISABLE_BUILT_IN_AGC, false),
+                        intent.getBooleanExtra(EXTRA_DISABLE_BUILT_IN_NS, false),
+                        intent.getBooleanExtra(EXTRA_DISABLE_WEBRTC_AGC_AND_HPF, false),
+                        intent.getBooleanExtra(EXTRA_ENABLE_RTCEVENTLOG, false),
+                        intent.getBooleanExtra(EXTRA_USE_LEGACY_AUDIO_DEVICE, false), dataChannelParameters);
+        commandLineRun = intent.getBooleanExtra(EXTRA_CMDLINE, false);
+        int runTimeMs = intent.getIntExtra(EXTRA_RUNTIME, 0);
 
-    Log.d(TAG, "VIDEO_FILE: '" + intent.getStringExtra(EXTRA_VIDEO_FILE_AS_CAMERA) + "'");
+        Log.d(TAG, "VIDEO_FILE: '" + intent.getStringExtra(EXTRA_VIDEO_FILE_AS_CAMERA) + "'");
 
-    // Create connection client. Use DirectRTCClient if room name is an IP otherwise use the
-    // standard WebSocketRTCClient.
-    if (loopback || !DirectRTCClient.IP_PATTERN.matcher(roomId).matches()) {
-      appRtcClient = new WebSocketRTCClient(this);
-    } else {
-      Log.i(TAG, "Using DirectRTCClient because room name looks like an IP.");
-      appRtcClient = new DirectRTCClient(this);
-    }
-    // Create connection parameters.
-    String urlParameters = intent.getStringExtra(EXTRA_URLPARAMETERS);
-    roomConnectionParameters =
-        new RoomConnectionParameters(roomUri.toString(), roomId, loopback, urlParameters);
+        // Create connection client. Use DirectRTCClient if room name is an IP otherwise use the
+        // standard WebSocketRTCClient.
+        if (loopback || !DirectRTCClient.IP_PATTERN.matcher(roomId).matches()) {
+            appRtcClient = new WebSocketRTCClient(this);
+        } else {
+            Log.i(TAG, "Using DirectRTCClient because room name looks like an IP.");
+            appRtcClient = new DirectRTCClient(this);
+        }
+        // Create connection parameters.
+        String urlParameters = intent.getStringExtra(EXTRA_URLPARAMETERS);
+        roomConnectionParameters =
+                new RoomConnectionParameters(roomUri.toString(), roomId, loopback, urlParameters);
 
-    // Create CPU monitor
-    if (CpuMonitor.isSupported()) {
-      cpuMonitor = new CpuMonitor(this);
-      hudFragment.setCpuMonitor(cpuMonitor);
-    }
+        // Create CPU monitor
+        if (CpuMonitor.isSupported()) {
+            cpuMonitor = new CpuMonitor(this);
+            hudFragment.setCpuMonitor(cpuMonitor);
+        }
 
-    // Send intent arguments to fragments.
-    callFragment.setArguments(intent.getExtras());
-    hudFragment.setArguments(intent.getExtras());
-    // Activate call and HUD fragments and start the call.
-    FragmentTransaction ft = getFragmentManager().beginTransaction();
-    ft.add(R.id.call_fragment_container, callFragment);
-    ft.add(R.id.hud_fragment_container, hudFragment);
-    ft.commit();
+        // Send intent arguments to fragments.
+        callFragment.setArguments(intent.getExtras());
+        hudFragment.setArguments(intent.getExtras());
+        // Activate call and HUD fragments and start the call.
+        FragmentTransaction ft = getFragmentManager().beginTransaction();
+        ft.add(R.id.call_fragment_container, callFragment);
+        ft.add(R.id.hud_fragment_container, hudFragment);
+        ft.commit();
 
-    // For command line execution run connection for <runTimeMs> and exit.
-    if (commandLineRun && runTimeMs > 0) {
-      (new Handler()).postDelayed(new Runnable() {
-        @Override
-        public void run() {
-          disconnect();
-        }
-      }, runTimeMs);
-    }
+        // For command line execution run connection for <runTimeMs> and exit.
+        if (commandLineRun && runTimeMs > 0) {
+            (new Handler()).postDelayed(new Runnable() {
+                @Override
+                public void run() {
+                    disconnect();
+                }
+            }, runTimeMs);
+        }
 
-    // Create peer connection client.
-    peerConnectionClient = new PeerConnectionClient(
-        getApplicationContext(), eglBase, peerConnectionParameters, CallActivity.this);
-    PeerConnectionFactory.Options options = new PeerConnectionFactory.Options();
-    if (loopback) {
-      options.networkIgnoreMask = 0;
-    }
-    peerConnectionClient.createPeerConnectionFactory(options);
+        // Create peer connection client.
+        peerConnectionClient = new PeerConnectionClient(
+                getApplicationContext(), eglBase, peerConnectionParameters, CallActivity.this);
+        PeerConnectionFactory.Options options = new PeerConnectionFactory.Options();
+        if (loopback) {
+            options.networkIgnoreMask = 0;
+        }
+        peerConnectionClient.createPeerConnectionFactory(options);
 
-    if (screencaptureEnabled) {
-      startScreenCapture();
-    } else {
-      startCall();
-    }
-  }
+        if (screencaptureEnabled) {
+            startScreenCapture();
+        } else {
+            startCall();
+        }
+    }
 
-  @TargetApi(17)
-  private DisplayMetrics getDisplayMetrics() {
-    DisplayMetrics displayMetrics = new DisplayMetrics();
-    WindowManager windowManager =
-        (WindowManager) getApplication().getSystemService(Context.WINDOW_SERVICE);
-    windowManager.getDefaultDisplay().getRealMetrics(displayMetrics);
-    return displayMetrics;
-  }
+    @TargetApi(17)
+    private DisplayMetrics getDisplayMetrics() {
+        DisplayMetrics displayMetrics = new DisplayMetrics();
+        WindowManager windowManager =
+                (WindowManager) getApplication().getSystemService(Context.WINDOW_SERVICE);
+        windowManager.getDefaultDisplay().getRealMetrics(displayMetrics);
+        return displayMetrics;
+    }
 
-  @TargetApi(19)
-  private static int getSystemUiVisibility() {
-    int flags = View.SYSTEM_UI_FLAG_HIDE_NAVIGATION | View.SYSTEM_UI_FLAG_FULLSCREEN;
-    if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.KITKAT) {
-      flags |= View.SYSTEM_UI_FLAG_IMMERSIVE_STICKY;
-    }
-    return flags;
-  }
+    @TargetApi(19)
+    private static int getSystemUiVisibility() {
+        int flags = View.SYSTEM_UI_FLAG_HIDE_NAVIGATION | View.SYSTEM_UI_FLAG_FULLSCREEN;
+        if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.KITKAT) {
+            flags |= View.SYSTEM_UI_FLAG_IMMERSIVE_STICKY;
+        }
+        return flags;
+    }
 
-  @TargetApi(21)
-  private void startScreenCapture() {
-    MediaProjectionManager mediaProjectionManager =
-        (MediaProjectionManager) getApplication().getSystemService(
-            Context.MEDIA_PROJECTION_SERVICE);
-    startActivityForResult(
-        mediaProjectionManager.createScreenCaptureIntent(), CAPTURE_PERMISSION_REQUEST_CODE);
-  }
+    @TargetApi(21)
+    private void startScreenCapture() {
+        MediaProjectionManager mediaProjectionManager =
+                (MediaProjectionManager) getApplication().getSystemService(
+                        Context.MEDIA_PROJECTION_SERVICE);
+        startActivityForResult(
+                mediaProjectionManager.createScreenCaptureIntent(), CAPTURE_PERMISSION_REQUEST_CODE);
+    }
 
-  @Override
-  public void onActivityResult(int requestCode, int resultCode, Intent data) {
-    if (requestCode != CAPTURE_PERMISSION_REQUEST_CODE)
-      return;
-    mediaProjectionPermissionResultCode = resultCode;
-    mediaProjectionPermissionResultData = data;
-    startCall();
-  }
+    @Override
+    public void onActivityResult(int requestCode, int resultCode, Intent data) {
+        if (requestCode != CAPTURE_PERMISSION_REQUEST_CODE)
+            return;
+        mediaProjectionPermissionResultCode = resultCode;
+        mediaProjectionPermissionResultData = data;
+        startCall();
+    }
 
-  private boolean useCamera2() {
-    return Camera2Enumerator.isSupported(this) && getIntent().getBooleanExtra(EXTRA_CAMERA2, true);
-  }
+    private boolean useCamera2() {
+        return Camera2Enumerator.isSupported(this) && getIntent().getBooleanExtra(EXTRA_CAMERA2, true);
+    }
 
-  private boolean captureToTexture() {
-    return getIntent().getBooleanExtra(EXTRA_CAPTURETOTEXTURE_ENABLED, false);
-  }
+    private boolean captureToTexture() {
+        return getIntent().getBooleanExtra(EXTRA_CAPTURETOTEXTURE_ENABLED, false);
+    }
 
-  private @Nullable VideoCapturer createCameraCapturer(CameraEnumerator enumerator) {
-    final String[] deviceNames = enumerator.getDeviceNames();
+    private @Nullable
+    VideoCapturer createCameraCapturer(CameraEnumerator enumerator) {
+        final String[] deviceNames = enumerator.getDeviceNames();
 
-    // First, try to find front facing camera
-    Logging.d(TAG, "Looking for front facing cameras.");
-    for (String deviceName : deviceNames) {
-      if (enumerator.isFrontFacing(deviceName)) {
-        Logging.d(TAG, "Creating front facing camera capturer.");
-        VideoCapturer videoCapturer = enumerator.createCapturer(deviceName, null);
+        // First, try to find front facing camera
+        Logging.d(TAG, "Looking for front facing cameras.");
+        for (String deviceName : deviceNames) {
+            if (enumerator.isFrontFacing(deviceName)) {
+                Logging.d(TAG, "Creating front facing camera capturer.");
+                VideoCapturer videoCapturer = enumerator.createCapturer(deviceName, null);
 
-        if (videoCapturer != null) {
-          return videoCapturer;
-        }
-      }
-    }
+                if (videoCapturer != null) {
+                    return videoCapturer;
+                }
+            }
+        }
 
-    // Front facing camera not found, try something else
-    Logging.d(TAG, "Looking for other cameras.");
-    for (String deviceName : deviceNames) {
-      if (!enumerator.isFrontFacing(deviceName)) {
-        Logging.d(TAG, "Creating other camera capturer.");
-        VideoCapturer videoCapturer = enumerator.createCapturer(deviceName, null);
+        // Front facing camera not found, try something else
+        Logging.d(TAG, "Looking for other cameras.");
+        for (String deviceName : deviceNames) {
+            if (!enumerator.isFrontFacing(deviceName)) {
+                Logging.d(TAG, "Creating other camera capturer.");
+                VideoCapturer videoCapturer = enumerator.createCapturer(deviceName, null);
 
-        if (videoCapturer != null) {
-          return videoCapturer;
-        }
-      }
-    }
+                if (videoCapturer != null) {
+                    return videoCapturer;
+                }
+            }
+        }
 
-    return null;
-  }
+        return null;
+    }
 
-  @TargetApi(21)
-  private @Nullable VideoCapturer createScreenCapturer() {
-    if (mediaProjectionPermissionResultCode != Activity.RESULT_OK) {
-      reportError("User didn't give permission to capture the screen.");
-      return null;
-    }
-    return new ScreenCapturerAndroid(
-        mediaProjectionPermissionResultData, new MediaProjection.Callback() {
-      @Override
-      public void onStop() {
-        reportError("User revoked permission to capture the screen.");
-      }
-    });
-  }
+    @TargetApi(21)
+    private @Nullable
+    VideoCapturer createScreenCapturer() {
+        if (mediaProjectionPermissionResultCode != Activity.RESULT_OK) {
+            reportError("User didn't give permission to capture the screen.");
+            return null;
+        }
+        return new ScreenCapturerAndroid(
+                mediaProjectionPermissionResultData, new MediaProjection.Callback() {
+            @Override
+            public void onStop() {
+                reportError("User revoked permission to capture the screen.");
+            }
+        });
+    }
 
-  // Activity interfaces
-  @Override
-  public void onStop() {
-    super.onStop();
-    activityRunning = false;
-    // Don't stop the video when using screencapture to allow user to show other apps to the remote
-    // end.
-    if (peerConnectionClient != null && !screencaptureEnabled) {
-      peerConnectionClient.stopVideoSource();
-    }
-    if (cpuMonitor != null) {
-      cpuMonitor.pause();
-    }
-  }
+    // Activity interfaces
+    @Override
+    public void onStop() {
+        super.onStop();
+        activityRunning = false;
+        // Don't stop the video when using screencapture to allow user to show other apps to the remote
+        // end.
+        if (peerConnectionClient != null && !screencaptureEnabled) {
+            peerConnectionClient.stopVideoSource();
+        }
+        if (cpuMonitor != null) {
+            cpuMonitor.pause();
+        }
+    }
 
-  @Override
-  public void onStart() {
-    super.onStart();
-    activityRunning = true;
-    // Video is not paused for screencapture. See onPause.
-    if (peerConnectionClient != null && !screencaptureEnabled) {
-      peerConnectionClient.startVideoSource();
-    }
-    if (cpuMonitor != null) {
-      cpuMonitor.resume();
-    }
-  }
+    @Override
+    public void onStart() {
+        super.onStart();
+        activityRunning = true;
+        // Video is not paused for screencapture. See onPause.
+        if (peerConnectionClient != null && !screencaptureEnabled) {
+            peerConnectionClient.startVideoSource();
+        }
+        if (cpuMonitor != null) {
+            cpuMonitor.resume();
+        }
+    }
 
-  @Override
-  protected void onDestroy() {
-    Thread.setDefaultUncaughtExceptionHandler(null);
-    disconnect();
-    if (logToast != null) {
-      logToast.cancel();
-    }
-    activityRunning = false;
-    super.onDestroy();
-  }
+    @Override
+    protected void onDestroy() {
+        Thread.setDefaultUncaughtExceptionHandler(null);
+        disconnect();
+        if (logToast != null) {
+            logToast.cancel();
+        }
+        activityRunning = false;
+        super.onDestroy();
+    }
 
-  // CallFragment.OnCallEvents interface implementation.
-  @Override
-  public void onCallHangUp() {
-    disconnect();
-  }
+    // CallFragment.OnCallEvents interface implementation.
+    @Override
+    public void onCallHangUp() {
+        disconnect();
+    }
 
-  @Override
-  public void onCameraSwitch() {
-    if (peerConnectionClient != null) {
-      peerConnectionClient.switchCamera();
-    }
-  }
+    @Override
+    public void onCameraSwitch() {
+        if (peerConnectionClient != null) {
+            peerConnectionClient.switchCamera();
+        }
+    }
 
-  @Override
-  public void onVideoScalingSwitch(ScalingType scalingType) {
-    fullscreenRenderer.setScalingType(scalingType);
-  }
+    @Override
+    public void onVideoScalingSwitch(ScalingType scalingType) {
+        fullscreenRenderer.setScalingType(scalingType);
+    }
 
-  @Override
-  public void onCaptureFormatChange(int width, int height, int framerate) {
-    if (peerConnectionClient != null) {
-      peerConnectionClient.changeCaptureFormat(width, height, framerate);
-    }
-  }
+    @Override
+    public void onCaptureFormatChange(int width, int height, int framerate) {
+        if (peerConnectionClient != null) {
+            peerConnectionClient.changeCaptureFormat(width, height, framerate);
+        }
+    }
 
-  @Override
-  public boolean onToggleMic() {
-    if (peerConnectionClient != null) {
-      micEnabled = !micEnabled;
-      peerConnectionClient.setAudioEnabled(micEnabled);
-    }
-    return micEnabled;
-  }
+    @Override
+    public boolean onToggleMic() {
+        if (peerConnectionClient != null) {
+            micEnabled = !micEnabled;
+            peerConnectionClient.setAudioEnabled(micEnabled);
+        }
+        return micEnabled;
+    }
 
-  // Helper functions.
-  private void toggleCallControlFragmentVisibility() {
-    if (!iceConnected || !callFragment.isAdded()) {
-      return;
-    }
-    // Show/hide call control fragment
-    callControlFragmentVisible = !callControlFragmentVisible;
-    FragmentTransaction ft = getFragmentManager().beginTransaction();
-    if (callControlFragmentVisible) {
-      ft.show(callFragment);
-      ft.show(hudFragment);
-    } else {
-      ft.hide(callFragment);
-      ft.hide(hudFragment);
-    }
-    ft.setTransition(FragmentTransaction.TRANSIT_FRAGMENT_FADE);
-    ft.commit();
-  }
+    // Helper functions.
+    private void toggleCallControlFragmentVisibility() {
+        if (!iceConnected || !callFragment.isAdded()) {
+            return;
+        }
+        // Show/hide call control fragment
+        callControlFragmentVisible = !callControlFragmentVisible;
+        FragmentTransaction ft = getFragmentManager().beginTransaction();
+        if (callControlFragmentVisible) {
+            ft.show(callFragment);
+            ft.show(hudFragment);
+        } else {
+            ft.hide(callFragment);
+            ft.hide(hudFragment);
+        }
+        ft.setTransition(FragmentTransaction.TRANSIT_FRAGMENT_FADE);
+        ft.commit();
+    }
 
-  private void startCall() {
-    if (appRtcClient == null) {
-      Log.e(TAG, "AppRTC client is not allocated for a call.");
-      return;
-    }
-    callStartedTimeMs = System.currentTimeMillis();
+    private void startCall() {
+        if (appRtcClient == null) {
+            Log.e(TAG, "AppRTC client is not allocated for a call.");
+            return;
+        }
+        callStartedTimeMs = System.currentTimeMillis();
 
-    // Start room connection.
-    logAndToast(getString(org.appspot.apprtc.R.string.connecting_to, roomConnectionParameters.roomUrl));
-    appRtcClient.connectToRoom(roomConnectionParameters);
+        // Start room connection.
+        logAndToast(getString(org.appspot.apprtc.R.string.connecting_to, roomConnectionParameters.roomUrl));
+        appRtcClient.connectToRoom(roomConnectionParameters);
 
-    // Create and audio manager that will take care of audio routing,
-    // audio modes, audio device enumeration etc.
-    audioManager = AppRTCAudioManager.create(getApplicationContext());
-    // Store existing audio settings and change audio mode to
-    // MODE_IN_COMMUNICATION for best possible VoIP performance.
-    Log.d(TAG, "Starting the audio manager...");
-    audioManager.start(new AudioManagerEvents() {
-      // This method will be called each time the number of available audio
-      // devices has changed.
-      @Override
-      public void onAudioDeviceChanged(
-          AudioDevice audioDevice, Set<AudioDevice> availableAudioDevices) {
-        onAudioManagerDevicesChanged(audioDevice, availableAudioDevices);
-      }
-    });
-  }
+        // Create and audio manager that will take care of audio routing,
+        // audio modes, audio device enumeration etc.
+        audioManager = AppRTCAudioManager.create(getApplicationContext());
+        // Store existing audio settings and change audio mode to
+        // MODE_IN_COMMUNICATION for best possible VoIP performance.
+        Log.d(TAG, "Starting the audio manager...");
+        audioManager.start(new AudioManagerEvents() {
+            // This method will be called each time the number of available audio
+            // devices has changed.
+            @Override
+            public void onAudioDeviceChanged(
+                    AudioDevice audioDevice, Set<AudioDevice> availableAudioDevices) {
+                onAudioManagerDevicesChanged(audioDevice, availableAudioDevices);
+            }
+        });
+    }
 
-  // Should be called from UI thread
-  private void callConnected() {
-    final long delta = System.currentTimeMillis() - callStartedTimeMs;
-    Log.i(TAG, "Call connected: delay=" + delta + "ms");
-    if (peerConnectionClient == null || isError) {
-      Log.w(TAG, "Call is connected in closed or error state");
-      return;
-    }
-    // Enable statistics callback.
-    peerConnectionClient.enableStatsEvents(true, STAT_CALLBACK_PERIOD);
-    setSwappedFeeds(false /* isSwappedFeeds */);
-  }
+    // Should be called from UI thread
+    private void callConnected() {
+        final long delta = System.currentTimeMillis() - callStartedTimeMs;
+        Log.i(TAG, "Call connected: delay=" + delta + "ms");
+        if (peerConnectionClient == null || isError) {
+            Log.w(TAG, "Call is connected in closed or error state");
+            return;
+        }
+        // Enable statistics callback.
+        peerConnectionClient.enableStatsEvents(true, STAT_CALLBACK_PERIOD);
+        setSwappedFeeds(false /* isSwappedFeeds */);
+    }
 
-  // This method is called when the audio manager reports audio device change,
-  // e.g. from wired headset to speakerphone.
-  private void onAudioManagerDevicesChanged(
-      final AudioDevice device, final Set<AudioDevice> availableDevices) {
-    Log.d(TAG, "onAudioManagerDevicesChanged: " + availableDevices + ", "
-            + "selected: " + device);
-    // TODO(henrika): add callback handler.
-  }
+    // This method is called when the audio manager reports audio device change,
+    // e.g. from wired headset to speakerphone.
+    private void onAudioManagerDevicesChanged(
+            final AudioDevice device, final Set<AudioDevice> availableDevices) {
+        Log.d(TAG, "onAudioManagerDevicesChanged: " + availableDevices + ", "
+                + "selected: " + device);
+        // TODO(henrika): add callback handler.
+    }
 
-  // Disconnect from remote resources, dispose of local resources, and exit.
-  private void disconnect() {
-    activityRunning = false;
-    remoteProxyRenderer.setTarget(null);
-    localProxyVideoSink.setTarget(null);
-    if (appRtcClient != null) {
-      appRtcClient.disconnectFromRoom();
-      appRtcClient = null;
-    }
-    if (pipRenderer != null) {
-      pipRenderer.release();
-      pipRenderer = null;
-    }
-    if (videoFileRenderer != null) {
-      videoFileRenderer.release();
-      videoFileRenderer = null;
-    }
-    if (fullscreenRenderer != null) {
-      fullscreenRenderer.release();
-      fullscreenRenderer = null;
-    }
-    if (peerConnectionClient != null) {
-      peerConnectionClient.close();
-      peerConnectionClient = null;
-    }
-    if (audioManager != null) {
-      audioManager.stop();
-      audioManager = null;
-    }
-    if (iceConnected && !isError) {
-      setResult(RESULT_OK);
-    } else {
-      setResult(RESULT_CANCELED);
-    }
-    finish();
-  }
+    // Disconnect from remote resources, dispose of local resources, and exit.
+    private void disconnect() {
+        activityRunning = false;
+        remoteProxyRenderer.setTarget(null);
+        localProxyVideoSink.setTarget(null);
+        if (appRtcClient != null) {
+            appRtcClient.disconnectFromRoom();
+            appRtcClient = null;
+        }
+        if (pipRenderer != null) {
+            pipRenderer.release();
+            pipRenderer = null;
+        }
+        if (videoFileRenderer != null) {
+            videoFileRenderer.release();
+            videoFileRenderer = null;
+        }
+        if (fullscreenRenderer != null) {
+            fullscreenRenderer.release();
+            fullscreenRenderer = null;
+        }
+        if (peerConnectionClient != null) {
+            peerConnectionClient.close();
+            peerConnectionClient = null;
+        }
+        if (audioManager != null) {
+            audioManager.stop();
+            audioManager = null;
+        }
+        if (iceConnected && !isError) {
+            setResult(RESULT_OK);
+        } else {
+            setResult(RESULT_CANCELED);
+        }
+        finish();
+    }
 
-  private void disconnectWithErrorMessage(final String errorMessage) {
-    if (commandLineRun || !activityRunning) {
-      Log.e(TAG, "Critical error: " + errorMessage);
-      disconnect();
-    } else {
-      new AlertDialog.Builder(this)
-          .setTitle(getText(org.appspot.apprtc.R.string.channel_error_title))
-          .setMessage(errorMessage)
-          .setCancelable(false)
-          .setNeutralButton(org.appspot.apprtc.R.string.ok,
-              new DialogInterface.OnClickListener() {
-                @Override
-                public void onClick(DialogInterface dialog, int id) {
-                  dialog.cancel();
-                  disconnect();
-                }
-              })
-          .create()
-          .show();
-    }
-  }
+    private void disconnectWithErrorMessage(final String errorMessage) {
+        if (commandLineRun || !activityRunning) {
+            Log.e(TAG, "Critical error: " + errorMessage);
+            disconnect();
+        } else {
+            new AlertDialog.Builder(this)
+                    .setTitle(getText(org.appspot.apprtc.R.string.channel_error_title))
+                    .setMessage(errorMessage)
+                    .setCancelable(false)
+                    .setNeutralButton(org.appspot.apprtc.R.string.ok,
+                            new DialogInterface.OnClickListener() {
+                                @Override
+                                public void onClick(DialogInterface dialog, int id) {
+                                    dialog.cancel();
+                                    disconnect();
+                                }
+                            })
+                    .create()
+                    .show();
+        }
+    }
 
-  // Log |msg| and Toast about it.
-  private void logAndToast(String msg) {
-    Log.d(TAG, msg);
-    if (logToast != null) {
-      logToast.cancel();
-    }
-    logToast = Toast.makeText(this, msg, Toast.LENGTH_SHORT);
-    logToast.show();
-  }
+    // Log |msg| and Toast about it.
+    private void logAndToast(String msg) {
+        Log.d(TAG, msg);
+        if (logToast != null) {
+            logToast.cancel();
+        }
+        logToast = Toast.makeText(this, msg, Toast.LENGTH_SHORT);
+        logToast.show();
+    }
 
-  private void reportError(final String description) {
-    runOnUiThread(new Runnable() {
-      @Override
-      public void run() {
-        if (!isError) {
-          isError = true;
-          disconnectWithErrorMessage(description);
-        }
-      }
-    });
-  }
+    private void reportError(final String description) {
+        runOnUiThread(new Runnable() {
+            @Override
+            public void run() {
+                if (!isError) {
+                    isError = true;
+                    disconnectWithErrorMessage(description);
+                }
+            }
+        });
+    }
 
-  private @Nullable VideoCapturer createVideoCapturer() {
-    final VideoCapturer videoCapturer;
-    String videoFileAsCamera = getIntent().getStringExtra(EXTRA_VIDEO_FILE_AS_CAMERA);
-    if (videoFileAsCamera != null) {
-      try {
-        videoCapturer = new FileVideoCapturer(videoFileAsCamera);
-      } catch (IOException e) {
-        reportError("Failed to open video file for emulated camera");
-        return null;
-      }
-    } else if (screencaptureEnabled) {
-      return createScreenCapturer();
-    } else if (useCamera2()) {
-      if (!captureToTexture()) {
-        reportError(getString(org.appspot.apprtc.R.string.camera2_texture_only_error));
-        return null;
-      }
+    private @Nullable
+    VideoCapturer createVideoCapturer() {
+        final VideoCapturer videoCapturer;
+        String videoFileAsCamera = getIntent().getStringExtra(EXTRA_VIDEO_FILE_AS_CAMERA);
+        if (videoFileAsCamera != null) {
+            try {
+                videoCapturer = new FileVideoCapturer(videoFileAsCamera);
+            } catch (IOException e) {
+                reportError("Failed to open video file for emulated camera");
+                return null;
+            }
+        } else if (screencaptureEnabled) {
+            return createScreenCapturer();
+        } else if (useCamera2()) {
+            if (!captureToTexture()) {
+                reportError(getString(org.appspot.apprtc.R.string.camera2_texture_only_error));
+                return null;
+            }
 
-      Logging.d(TAG, "Creating capturer using camera2 API.");
-      videoCapturer = createCameraCapturer(new Camera2Enumerator(this));
-    } else {
-      Logging.d(TAG, "Creating capturer using camera1 API.");
-      videoCapturer = createCameraCapturer(new Camera1Enumerator(captureToTexture()));
-    }
-    if (videoCapturer == null) {
-      reportError("Failed to open camera");
-      return null;
-    }
-    return videoCapturer;
-  }
+            Logging.d(TAG, "Creating capturer using camera2 API.");
+            videoCapturer = createCameraCapturer(new Camera2Enumerator(this));
+        } else {
+            Logging.d(TAG, "Creating capturer using camera1 API.");
+            videoCapturer = createCameraCapturer(new Camera1Enumerator(captureToTexture()));
+        }
+        if (videoCapturer == null) {
+            reportError("Failed to open camera");
+            return null;
+        }
+        return videoCapturer;
+    }
 
-  private void setSwappedFeeds(boolean isSwappedFeeds) {
-    Logging.d(TAG, "setSwappedFeeds: " + isSwappedFeeds);
-    this.isSwappedFeeds = isSwappedFeeds;
-    localProxyVideoSink.setTarget(isSwappedFeeds ? fullscreenRenderer : pipRenderer);
-    remoteProxyRenderer.setTarget(isSwappedFeeds ? pipRenderer : fullscreenRenderer);
-    fullscreenRenderer.setMirror(isSwappedFeeds);
-    pipRenderer.setMirror(!isSwappedFeeds);
-  }
+    private void setSwappedFeeds(boolean isSwappedFeeds) {
+        Logging.d(TAG, "setSwappedFeeds: " + isSwappedFeeds);
+        this.isSwappedFeeds = isSwappedFeeds;
+        localProxyVideoSink.setTarget(isSwappedFeeds ? fullscreenRenderer : pipRenderer);
+        remoteProxyRenderer.setTarget(isSwappedFeeds ? pipRenderer : fullscreenRenderer);
+        fullscreenRenderer.setMirror(isSwappedFeeds);
+        pipRenderer.setMirror(!isSwappedFeeds);
+    }
 
-  // -----Implementation of AppRTCClient.AppRTCSignalingEvents ---------------
-  // All callbacks are invoked from websocket signaling looper thread and
-  // are routed to UI thread.
-  private void onConnectedToRoomInternal(final SignalingParameters params) {
-    final long delta = System.currentTimeMillis() - callStartedTimeMs;
+    // -----Implementation of AppRTCClient.AppRTCSignalingEvents ---------------
+    // All callbacks are invoked from websocket signaling looper thread and
+    // are routed to UI thread.
+    private void onConnectedToRoomInternal(final SignalingParameters params) {
+        final long delta = System.currentTimeMillis() - callStartedTimeMs;
 
-    signalingParameters = params;
-    logAndToast("Creating peer connection, delay=" + delta + "ms");
-    VideoCapturer videoCapturer = null;
-    if (peerConnectionParameters.videoCallEnabled) {
-      videoCapturer = createVideoCapturer();
-    }
-    peerConnectionClient.createPeerConnection(
-        localProxyVideoSink, remoteSinks, videoCapturer, signalingParameters);
+        signalingParameters = params;
+        logAndToast("Creating peer connection, delay=" + delta + "ms");
+        VideoCapturer videoCapturer = null;
+        if (peerConnectionParameters.videoCallEnabled) {
+            videoCapturer = createVideoCapturer();
+        }
+        peerConnectionClient.createPeerConnection(
+                localProxyVideoSink, remoteSinks, videoCapturer, signalingParameters);
 
-    if (signalingParameters.initiator) {
-      logAndToast("Creating OFFER...");
-      // Create offer. Offer SDP will be sent to answering client in
-      // PeerConnectionEvents.onLocalDescription event.
-      peerConnectionClient.createOffer();
-    } else {
-      if (params.offerSdp != null) {
-        peerConnectionClient.setRemoteDescription(params.offerSdp);
-        logAndToast("Creating ANSWER...");
-        // Create answer. Answer SDP will be sent to offering client in
-        // PeerConnectionEvents.onLocalDescription event.
-        peerConnectionClient.createAnswer();
-      }
-      if (params.iceCandidates != null) {
-        // Add remote ICE candidates from room.
-        for (IceCandidate iceCandidate : params.iceCandidates) {
-          peerConnectionClient.addRemoteIceCandidate(iceCandidate);
-        }
-      }
-    }
-  }
+        if (signalingParameters.initiator) {
+            logAndToast("Creating OFFER...");
+            // Create offer. Offer SDP will be sent to answering client in
+            // PeerConnectionEvents.onLocalDescription event.
+            peerConnectionClient.createOffer();
+        } else {
+            if (params.offerSdp != null) {
+                peerConnectionClient.setRemoteDescription(params.offerSdp);
+                logAndToast("Creating ANSWER...");
+                // Create answer. Answer SDP will be sent to offering client in
+                // PeerConnectionEvents.onLocalDescription event.
+                peerConnectionClient.createAnswer();
+            }
+            if (params.iceCandidates != null) {
+                // Add remote ICE candidates from room.
+                for (IceCandidate iceCandidate : params.iceCandidates) {
+                    peerConnectionClient.addRemoteIceCandidate(iceCandidate);
+                }
+            }
+        }
+    }
 
-  @Override
-  public void onConnectedToRoom(final SignalingParameters params) {
-    runOnUiThread(new Runnable() {
-      @Override
-      public void run() {
-        onConnectedToRoomInternal(params);
-      }
-    });
-  }
+    @Override
+    public void onConnectedToRoom(final SignalingParameters params) {
+        runOnUiThread(new Runnable() {
+            @Override
+            public void run() {
+                onConnectedToRoomInternal(params);
+            }
+        });
+    }
 
-  @Override
-  public void onRemoteDescription(final SessionDescription sdp) {
-    final long delta = System.currentTimeMillis() - callStartedTimeMs;
-    runOnUiThread(new Runnable() {
-      @Override
-      public void run() {
-        if (peerConnectionClient == null) {
-          Log.e(TAG, "Received remote SDP for non-initilized peer connection.");
-          return;
-        }
-        logAndToast("Received remote " + sdp.type + ", delay=" + delta + "ms");
-        peerConnectionClient.setRemoteDescription(sdp);
-        if (!signalingParameters.initiator) {
-          logAndToast("Creating ANSWER...");
-          // Create answer. Answer SDP will be sent to offering client in
-          // PeerConnectionEvents.onLocalDescription event.
-          peerConnectionClient.createAnswer();
-        }
-      }
-    });
-  }
+    @Override
+    public void onRemoteDescription(final SessionDescription sdp) {
+        final long delta = System.currentTimeMillis() - callStartedTimeMs;
+        runOnUiThread(new Runnable() {
+            @Override
+            public void run() {
+                if (peerConnectionClient == null) {
+                    Log.e(TAG, "Received remote SDP for non-initilized peer connection.");
+                    return;
+                }
+                logAndToast("Received remote " + sdp.type + ", delay=" + delta + "ms");
+                peerConnectionClient.setRemoteDescription(sdp);
+                if (!signalingParameters.initiator) {
+                    logAndToast("Creating ANSWER...");
+                    // Create answer. Answer SDP will be sent to offering client in
+                    // PeerConnectionEvents.onLocalDescription event.
+                    peerConnectionClient.createAnswer();
+                }
+            }
+        });
+    }
 
-  @Override
-  public void onRemoteIceCandidate(final IceCandidate candidate) {
-    runOnUiThread(new Runnable() {
-      @Override
-      public void run() {
-        if (peerConnectionClient == null) {
-          Log.e(TAG, "Received ICE candidate for a non-initialized peer connection.");
-          return;
-        }
-        peerConnectionClient.addRemoteIceCandidate(candidate);
-      }
-    });
-  }
+    @Override
+    public void onRemoteIceCandidate(final IceCandidate candidate) {
+        runOnUiThread(new Runnable() {
+            @Override
+            public void run() {
+                if (peerConnectionClient == null) {
+                    Log.e(TAG, "Received ICE candidate for a non-initialized peer connection.");
+                    return;
+                }
+                peerConnectionClient.addRemoteIceCandidate(candidate);
+            }
+        });
+    }
 
-  @Override
-  public void onRemoteIceCandidatesRemoved(final IceCandidate[] candidates) {
-    runOnUiThread(new Runnable() {
-      @Override
-      public void run() {
-        if (peerConnectionClient == null) {
-          Log.e(TAG, "Received ICE candidate removals for a non-initialized peer connection.");
-          return;
-        }
-        peerConnectionClient.removeRemoteIceCandidates(candidates);
-      }
-    });
-  }
+    @Override
+    public void onRemoteIceCandidatesRemoved(final IceCandidate[] candidates) {
+        runOnUiThread(new Runnable() {
+            @Override
+            public void run() {
+                if (peerConnectionClient == null) {
+                    Log.e(TAG, "Received ICE candidate removals for a non-initialized peer connection.");
+                    return;
+                }
+                peerConnectionClient.removeRemoteIceCandidates(candidates);
+            }
+        });
+    }
 
-  @Override
-  public void onChannelClose() {
-    runOnUiThread(new Runnable() {
-      @Override
-      public void run() {
-        logAndToast("Remote end hung up; dropping PeerConnection");
-        disconnect();
-      }
-    });
-  }
+    @Override
+    public void onChannelClose() {
+        runOnUiThread(new Runnable() {
+            @Override
+            public void run() {
+                logAndToast("Remote end hung up; dropping PeerConnection");
+                disconnect();
+            }
+        });
+    }
 
-  @Override
-  public void onChannelError(final String description) {
-    reportError(description);
-  }
+    @Override
+    public void onChannelError(final String description) {
+        reportError(description);
+    }
 
-  // -----Implementation of PeerConnectionClient.PeerConnectionEvents.---------
-  // Send local peer connection SDP and ICE candidates to remote party.
-  // All callbacks are invoked from peer connection client looper thread and
-  // are routed to UI thread.
-  @Override
-  public void onLocalDescription(final SessionDescription sdp) {
-    final long delta = System.currentTimeMillis() - callStartedTimeMs;
-    runOnUiThread(new Runnable() {
-      @Override
-      public void run() {
-        if (appRtcClient != null) {
-          logAndToast("Sending " + sdp.type + ", delay=" + delta + "ms");
-          if (signalingParameters.initiator) {
-            appRtcClient.sendOfferSdp(sdp);
-          } else {
-            appRtcClient.sendAnswerSdp(sdp);
-          }
-        }
-        if (peerConnectionParameters.videoMaxBitrate > 0) {
-          Log.d(TAG, "Set video maximum bitrate: " + peerConnectionParameters.videoMaxBitrate);
-          peerConnectionClient.setVideoMaxBitrate(peerConnectionParameters.videoMaxBitrate);
-        }
-      }
-    });
-  }
+    // -----Implementation of PeerConnectionClient.PeerConnectionEvents.---------
+    // Send local peer connection SDP and ICE candidates to remote party.
+    // All callbacks are invoked from peer connection client looper thread and
+    // are routed to UI thread.
+    @Override
+    public void onLocalDescription(final SessionDescription sdp) {
+        final long delta = System.currentTimeMillis() - callStartedTimeMs;
+        runOnUiThread(new Runnable() {
+            @Override
+            public void run() {
+                if (appRtcClient != null) {
+                    logAndToast("Sending " + sdp.type + ", delay=" + delta + "ms");
+                    if (signalingParameters.initiator) {
+                        appRtcClient.sendOfferSdp(sdp);
+                    } else {
+                        appRtcClient.sendAnswerSdp(sdp);
+                    }
+                }
+                if (peerConnectionParameters.videoMaxBitrate > 0) {
+                    Log.d(TAG, "Set video maximum bitrate: " + peerConnectionParameters.videoMaxBitrate);
+                    peerConnectionClient.setVideoMaxBitrate(peerConnectionParameters.videoMaxBitrate);
+                }
+            }
+        });
+    }
 
-  @Override
-  public void onIceCandidate(final IceCandidate candidate) {
-    runOnUiThread(new Runnable() {
-      @Override
-      public void run() {
-        if (appRtcClient != null) {
-          appRtcClient.sendLocalIceCandidate(candidate);
-        }
-      }
-    });
-  }
+    @Override
+    public void onIceCandidate(final IceCandidate candidate) {
+        runOnUiThread(new Runnable() {
+            @Override
+            public void run() {
+                if (appRtcClient != null) {
+                    appRtcClient.sendLocalIceCandidate(candidate);
+                }
+            }
+        });
+    }
 
-  @Override
-  public void onIceCandidatesRemoved(final IceCandidate[] candidates) {
-    runOnUiThread(new Runnable() {
-      @Override
-      public void run() {
-        if (appRtcClient != null) {
-          appRtcClient.sendLocalIceCandidateRemovals(candidates);
-        }
-      }
-    });
-  }
+    @Override
+    public void onIceCandidatesRemoved(final IceCandidate[] candidates) {
+        runOnUiThread(new Runnable() {
+            @Override
+            public void run() {
+                if (appRtcClient != null) {
+                    appRtcClient.sendLocalIceCandidateRemovals(candidates);
+                }
+            }
+        });
+    }
 
-  @Override
-  public void onIceConnected() {
-    final long delta = System.currentTimeMillis() - callStartedTimeMs;
-    runOnUiThread(new Runnable() {
-      @Override
-      public void run() {
-        logAndToast("ICE connected, delay=" + delta + "ms");
-        iceConnected = true;
-        callConnected();
-      }
-    });
-  }
+    @Override
+    public void onIceConnected() {
+        final long delta = System.currentTimeMillis() - callStartedTimeMs;
+        runOnUiThread(new Runnable() {
+            @Override
+            public void run() {
+                logAndToast("ICE connected, delay=" + delta + "ms");
+                iceConnected = true;
+                callConnected();
+            }
+        });
+    }
 
-  @Override
-  public void onIceDisconnected() {
-    runOnUiThread(new Runnable() {
-      @Override
-      public void run() {
-        logAndToast("ICE disconnected");
-        iceConnected = false;
-        disconnect();
-      }
-    });
-  }
+    @Override
+    public void onIceDisconnected() {
+        runOnUiThread(new Runnable() {
+            @Override
+            public void run() {
+                logAndToast("ICE disconnected");
+                iceConnected = false;
+                disconnect();
+            }
+        });
+    }
 
-  @Override
-  public void onPeerConnectionClosed() {}
+    @Override
+    public void onPeerConnectionClosed() {
+    }
 
-  @Override
-  public void onPeerConnectionStatsReady(final StatsReport[] reports) {
-    runOnUiThread(new Runnable() {
-      @Override
-      public void run() {
-        if (!isError && iceConnected) {
-          hudFragment.updateEncoderStatistics(reports);
-        }
-      }
-    });
-  }
+    @Override
+    public void onPeerConnectionStatsReady(final StatsReport[] reports) {
+        runOnUiThread(new Runnable() {
+            @Override
+            public void run() {
+                if (!isError && iceConnected) {
+                    hudFragment.updateEncoderStatistics(reports);
+                }
+            }
+        });
+    }
 
-  @Override
-  public void onPeerConnectionError(final String description) {
-    reportError(description);
-  }
+    @Override
+    public void onPeerConnectionError(final String description) {
+        reportError(description);
+    }
 }
Index: app/src/main/java/com/example/webrtc/android/solo_speed_play.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>package com.example.webrtc.android;\r\n\r\nimport androidx.annotation.NonNull;\r\nimport androidx.appcompat.app.AppCompatActivity;\r\nimport androidx.core.app.ActivityCompat;\r\nimport androidx.core.content.ContextCompat;\r\n\r\nimport android.Manifest;\r\nimport android.app.Activity;\r\nimport android.content.Intent;\r\nimport android.content.pm.PackageManager;\r\nimport android.content.res.AssetFileDescriptor;\r\nimport android.graphics.Bitmap;\r\nimport android.graphics.Color;\r\nimport android.graphics.Matrix;\r\nimport android.hardware.Camera;\r\nimport android.os.Build;\r\nimport android.os.Bundle;\r\nimport android.os.CountDownTimer;\r\nimport android.os.Handler;\r\nimport android.os.Message;\r\nimport android.os.SystemClock;\r\nimport android.preference.PreferenceManager;\r\nimport android.view.SurfaceHolder;\r\nimport android.view.Window;\r\nimport android.view.WindowManager;\r\nimport android.widget.Button;\r\nimport android.widget.TextView;\r\nimport android.widget.Toast;\r\n\r\nimport com.google.firebase.database.DataSnapshot;\r\nimport com.google.firebase.database.DatabaseError;\r\nimport com.google.firebase.database.DatabaseReference;\r\nimport com.google.firebase.database.FirebaseDatabase;\r\nimport com.google.firebase.database.ValueEventListener;\r\n\r\nimport org.tensorflow.lite.Interpreter;\r\n\r\nimport java.io.FileInputStream;\r\nimport java.io.IOException;\r\nimport java.nio.MappedByteBuffer;\r\nimport java.nio.channels.FileChannel;\r\nimport java.util.Iterator;\r\n\r\npublic class solo_speed_play extends AppCompatActivity implements Camera.PreviewCallback {\r\n\r\n    //카운트를 위해(시간)\r\n    public TextView tv_timer;\r\n    private CountDownTimer countDownTimer;\r\n    private long start_time, now_time, overTime;\r\n    private boolean game_end = false;\r\n    private boolean game_start = false;\r\n\r\n    //DB접근을 위해\r\n    DatabaseReference DB_speed;\r\n    DatabaseReference DB_total;\r\n    String email = \"\";\r\n\r\n    //카메라를 위해\r\n    private static CameraPreview surfaceView;\r\n    private SurfaceHolder holder;\r\n    private static Button camera_preview_button;\r\n    private static Camera mCamera;\r\n    private int RESULT_PERMISSIONS = 100;\r\n    public static solo_speed_play getInstance;\r\n    //모델 판단을 위해\r\n    Interpreter tflite;\r\n    public TextView tv_result;\r\n    public TextView tv_count;\r\n    public int count = 0;\r\n    public int[] arr = new int[3];      //0(up) 1(down)\r\n    public int index = 0;\r\n    public boolean up = true;\r\n    public boolean down = false;\r\n\r\n    @Override\r\n    protected void onCreate(Bundle savedInstanceState) {\r\n        super.onCreate(savedInstanceState);\r\n        //setContentView(R.layout.activity_solo_speed_play);\r\n\r\n        //이메일을 알고있어야 db연동\r\n        Intent intent = getIntent();\r\n        email = intent.getStringExtra(\"Email\");        //구글이메일\r\n\r\n        // 카메라 프리뷰를  전체화면으로 보여주기 위해 셋팅한다.\r\n        supportRequestWindowFeature(Window.FEATURE_NO_TITLE);\r\n        getWindow().setFlags(WindowManager.LayoutParams.FLAG_FULLSCREEN,\r\n                WindowManager.LayoutParams.FLAG_FULLSCREEN);\r\n\r\n        //모델 로드\r\n        tflite = getTfliteInterpreter(\"model.tflite\");\r\n\r\n\r\n        // 안드로이드 6.0 이상 버전에서는 CAMERA 권한 허가를 요청한다.\r\n        requestPermissionCamera();\r\n\r\n        //카운트 시작 (준비시간 5초)\r\n        tv_timer = findViewById(R.id.tv_timer);\r\n        countDownTimer();\r\n        countDownTimer.start();\r\n\r\n    }\r\n\r\n    //카운트를 위해\r\n    public void countDownTimer() {\r\n        countDownTimer = new CountDownTimer(1000, 1000) {\r\n            @Override\r\n            public void onTick(long l) {\r\n                //0초면 토스트 메세지 띄운다\r\n                if (l / 1000 == 0) {\r\n                    Toast.makeText(getApplicationContext(), \"Start!\", Toast.LENGTH_SHORT).show();\r\n                } else tv_timer.setText(Long.toString(l / 1000));\r\n            }\r\n\r\n            @Override\r\n            public void onFinish() {\r\n                //0.0부터 타이머가 시작해야하므로\r\n                start_time = SystemClock.elapsedRealtime();\r\n                game_start = true;\r\n                handler.sendEmptyMessage(0);\r\n            }\r\n        };\r\n    }\r\n\r\n    //카운터 계산부분\r\n    private String getTime() {\r\n        //게임이 종료되지 않았다면\r\n        //경과된 시간 체크\r\n        now_time = SystemClock.elapsedRealtime();\r\n        //시스템이 부팅된 이후의 시간?\r\n        overTime = now_time - start_time;\r\n\r\n        long m = overTime / 1000 / 60;\r\n        long s = (overTime / 1000) % 60;\r\n\r\n        long ms = overTime % 1000;\r\n\r\n        //3분 넘어가면 게임종료\r\n        if (m >= 3) game_end = true;\r\n\r\n        String recTime = String.format(\"%d:%02d:%03d\", m, s, ms);\r\n\r\n        return recTime;\r\n    }\r\n\r\n    //handler (카운터)\r\n    Handler handler = new Handler() {\r\n        @Override\r\n        public void handleMessage(@NonNull Message msg) {\r\n\r\n            tv_timer.setText(getTime());\r\n\r\n            if (!game_end) handler.sendEmptyMessage(0);\r\n\r\n        }\r\n    };\r\n\r\n    //판단 (up,down) 카운팅\r\n    public void determine(int n) {\r\n        if (index == 0 || index == 1) {\r\n            arr[index] = n;\r\n            index++;\r\n        }\r\n        //index가 2이면 마지막꺼만 비어있는 상태\r\n        else {\r\n            //우선 넣어주고\r\n            arr[index] = n;\r\n            //판단\r\n            if (arr[0] == arr[1] && arr[1] == arr[2]) {\r\n                //down이 true인 상태에서 up인상태이면 count++\r\n                if (arr[0] == 0) {\r\n                    if (down) {\r\n                        down = false;\r\n                        count++;\r\n                        tv_count = findViewById(R.id.tv_count);\r\n                        tv_count.setText(Integer.toString(count));\r\n\r\n                        //10개 채웠으면 game_end!\r\n                        if (count >= 3) game_end = true;\r\n                    }\r\n                }\r\n                //down\r\n                else {\r\n                    down = true;\r\n                }\r\n            }\r\n            //앞에껄 지우고 옮겨줌\r\n            arr[0] = arr[1];\r\n            arr[1] = arr[2];\r\n            arr[2] = -1;\r\n        }\r\n\r\n    }\r\n    //total_count 와 speed_time update\r\n    public void updateRecord() {\r\n        //String[] s = {\"/speed_time\", \"/total_count\"};\r\n        //speed_time\r\n        DB_speed = FirebaseDatabase.getInstance().getReference(\"/users/\" + email + \"/speed_time\");         //해당 아이디 값들 조회\r\n        DB_speed.addListenerForSingleValueEvent(new ValueEventListener() {\r\n            @Override\r\n            public void onDataChange(@NonNull DataSnapshot snapshot) {\r\n                //만약 더빠르다면 update\r\n                long result = (long) snapshot.getValue();\r\n                if (result > overTime) {\r\n                    DB_speed.setValue(overTime);\r\n                }\r\n            }\r\n            @Override\r\n            public void onCancelled(@NonNull DatabaseError error) {\r\n\r\n            }\r\n        });\r\n        //total_count\r\n        DB_total = FirebaseDatabase.getInstance().getReference(\"/users/\" + email + \"/total_count\");         //해당 아이디 값들 조회\r\n        DB_total.addListenerForSingleValueEvent(new ValueEventListener() {\r\n            @Override\r\n            public void onDataChange(@NonNull DataSnapshot snapshot) {\r\n                System.out.println(snapshot.getValue()+\"!!!!!!!!!!!!!!!!!!!!!!\");\r\n                long result = (long) snapshot.getValue();\r\n                result += count;\r\n                DB_total.setValue(result);\r\n            }\r\n            @Override\r\n            public void onCancelled(@NonNull DatabaseError error) {\r\n\r\n            }\r\n        });\r\n    }\r\n\r\n    //Frame마다\r\n    @Override\r\n    public void onPreviewFrame(byte[] bytes, Camera camera) {\r\n        //결과값 출력을 위해\r\n        tv_result = findViewById(R.id.tv_result);\r\n        tv_count = findViewById(R.id.tv_count);\r\n        //게임이 끝나면\r\n        if (game_end) {\r\n            updateRecord();                 //db의 total_count 와 speed_time update\r\n            Toast.makeText(getApplicationContext(), \"game end!\", Toast.LENGTH_SHORT).show();\r\n            surfaceView.surfaceDestroyed(holder);       //preview 종료\r\n            solo_speed_play.this.finish();      //액티비티 종료\r\n        }\r\n        //게임 끝이 아니고 게임이 시작됐다면(게임중이라면)\r\n        else if (game_start && !(mCamera == null)) {\r\n            Camera.Parameters params= mCamera.getParameters();\r\n\r\n            int w = params.getPreviewSize().width;\r\n            int h = params.getPreviewSize().height;\r\n\r\n            final int[] rgb = decodeYUV420SP(bytes, w, h);\r\n            Bitmap bmp = Bitmap.createBitmap(rgb, w, h, Bitmap.Config.ARGB_8888);\r\n            bmp = Bitmap.createScaledBitmap(bmp, 224, 224, false);\r\n\r\n            Matrix rotateMatrix = new Matrix();\r\n            rotateMatrix.postRotate(90);\r\n\r\n            bmp = Bitmap.createBitmap(bmp, 0, 0,\r\n                    bmp.getWidth(), bmp.getHeight(), rotateMatrix, false);\r\n\r\n            //모델 적용을 위해\r\n            float[][][][] inputs = new float[1][224][224][3];       //1 * width * height * RGB\r\n            float[][] outputs = new float[1][2];\r\n            for (int x = 0; x < 224; x++) {\r\n                for (int y = 0; y < 224; y++) {\r\n                    int pixel = bmp.getPixel(x, y);\r\n                    inputs[0][y][x][0] = (Color.red(pixel)) / 255.0f;\r\n                    inputs[0][y][x][1] = (Color.green(pixel)) / 255.0f;\r\n                    inputs[0][y][x][2] = (Color.blue(pixel)) / 255.0f;\r\n                }\r\n            }\r\n            tflite.run(inputs, outputs);\r\n\r\n            //서있을때\r\n            if (outputs[0][0] > outputs[0][1]) {\r\n                tv_result.setText(\"up\");\r\n                determine(0);\r\n            }\r\n            //앉아있을때\r\n            else {\r\n                tv_result.setText(\"down\");\r\n                determine(1);\r\n            }\r\n        }\r\n    }\r\n\r\n\r\n    //bytes에서 rgb정보 추출\r\n    public int[] decodeYUV420SP(byte[] yuv420sp, int width, int height) {\r\n        final int frameSize = width * height;\r\n\r\n        int rgb[] = new int[width * height];\r\n        for (int j = 0, yp = 0; j < height; j++) {\r\n            int uvp = frameSize + (j >> 1) * width, u = 0, v = 0;\r\n            for (int i = 0; i < width; i++, yp++) {\r\n                int y = (0xff & ((int) yuv420sp[yp])) - 16;\r\n                if (y < 0) y = 0;\r\n                if ((i & 1) == 0) {\r\n                    v = (0xff & yuv420sp[uvp++]) - 128;\r\n                    u = (0xff & yuv420sp[uvp++]) - 128;\r\n                }\r\n\r\n                int y1192 = 1192 * y;\r\n                int r = (y1192 + 1634 * v);\r\n                int g = (y1192 - 833 * v - 400 * u);\r\n                int b = (y1192 + 2066 * u);\r\n\r\n                if (r < 0) r = 0;\r\n                else if (r > 262143) r = 262143;\r\n                if (g < 0) g = 0;\r\n                else if (g > 262143) g = 262143;\r\n                if (b < 0) b = 0;\r\n                else if (b > 262143) b = 262143;\r\n\r\n                rgb[yp] = 0xff000000 | ((r << 6) & 0xff0000) | ((g >> 2) &\r\n                        0xff00) | ((b >> 10) & 0xff);\r\n\r\n            }\r\n        }\r\n        return rgb;\r\n    }\r\n\r\n    //카메라 부분\r\n    public static Camera getCamera() {\r\n        return mCamera;\r\n    }\r\n\r\n    private void setInit() {\r\n        getInstance = this;\r\n\r\n\r\n\r\n        // 카메라 객체를 R.layout.activity_main의 레이아웃에 선언한 SurfaceView에서 먼저 정의해야 함으로 setContentView 보다 먼저 정의한다.\r\n        mCamera = Camera.open();\r\n\r\n        setContentView(R.layout.activity_solo_speed_play);\r\n\r\n        // SurfaceView를 상속받은 레이아웃을 정의한다.\r\n        surfaceView = (CameraPreview) findViewById(R.id.preview);\r\n        //리스너 설정\r\n        mCamera.setPreviewCallback(this::onPreviewFrame);\r\n        // SurfaceView 정의 - holder와 Callback을 정의한다.\r\n        holder = surfaceView.getHolder();\r\n        holder.addCallback(surfaceView);\r\n        holder.setType(SurfaceHolder.SURFACE_TYPE_PUSH_BUFFERS);\r\n    }\r\n\r\n    //허가\r\n    private boolean requestPermissionCamera() {\r\n        int sdkVersion = Build.VERSION.SDK_INT;\r\n        if (sdkVersion >= Build.VERSION_CODES.M) {\r\n\r\n            if (ContextCompat.checkSelfPermission(this, Manifest.permission.CAMERA) != PackageManager.PERMISSION_GRANTED) {\r\n\r\n                ActivityCompat.requestPermissions(solo_speed_play.this,\r\n                        new String[]{Manifest.permission.CAMERA},\r\n                        RESULT_PERMISSIONS);\r\n\r\n            } else {\r\n                setInit();\r\n            }\r\n        } else {  // version 6 이하일때\r\n            setInit();\r\n            return true;\r\n        }\r\n\r\n        return true;\r\n    }\r\n\r\n    @Override\r\n    public void onRequestPermissionsResult(int requestCode,\r\n                                           String permissions[], int[] grantResults) {\r\n\r\n        if (RESULT_PERMISSIONS == requestCode) {\r\n\r\n            if (grantResults.length > 0\r\n                    && grantResults[0] == PackageManager.PERMISSION_GRANTED) {\r\n                // 권한 허가시\r\n                setInit();\r\n            } else {\r\n                // 권한 거부시\r\n            }\r\n            return;\r\n        }\r\n\r\n    }\r\n\r\n\r\n    //모델 로드 국룰\r\n    private Interpreter getTfliteInterpreter(String modelPath) {\r\n        try {\r\n            return new Interpreter(loadModelFile(solo_speed_play.this, modelPath));\r\n        } catch (Exception e) {\r\n            e.printStackTrace();\r\n        }\r\n        return null;\r\n    }\r\n\r\n    private MappedByteBuffer loadModelFile(Activity activity, String modelPath) throws IOException {\r\n        AssetFileDescriptor fileDescriptor = activity.getAssets().openFd(modelPath);\r\n        FileInputStream inputStream = new FileInputStream(fileDescriptor.getFileDescriptor());\r\n        FileChannel fileChannel = inputStream.getChannel();\r\n        long startOffset = fileDescriptor.getStartOffset();\r\n        long declaredLength = fileDescriptor.getDeclaredLength();\r\n        return fileChannel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength);\r\n    }\r\n}
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/src/main/java/com/example/webrtc/android/solo_speed_play.java	(revision bf540945d88389d00f5acde8206c98ded8cdb2e7)
+++ app/src/main/java/com/example/webrtc/android/solo_speed_play.java	(date 1606204729876)
@@ -191,6 +191,8 @@
         }
 
     }
+
+
     //total_count 와 speed_time update
     public void updateRecord() {
         //String[] s = {"/speed_time", "/total_count"};
@@ -327,10 +329,9 @@
     private void setInit() {
         getInstance = this;
 
-
-
+        int cameraID = Camera.CameraInfo.CAMERA_FACING_FRONT;
         // 카메라 객체를 R.layout.activity_main의 레이아웃에 선언한 SurfaceView에서 먼저 정의해야 함으로 setContentView 보다 먼저 정의한다.
-        mCamera = Camera.open();
+        mCamera = Camera.open(cameraID);
 
         setContentView(R.layout.activity_solo_speed_play);
 
Index: app/src/main/res/layout/activity_call.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+><?xml version=\"1.0\" encoding=\"utf-8\"?>\r\n\r\n<!-- tools:ignore is needed because lint thinks this can be replaced with a merge. Replacing this\r\n     with a merge causes the fullscreen SurfaceView not to be centered. -->\r\n<FrameLayout\r\n    xmlns:android=\"http://schemas.android.com/apk/res/android\"\r\n    xmlns:tools=\"http://schemas.android.com/tools\"\r\n    android:layout_width=\"match_parent\"\r\n    android:layout_height=\"match_parent\"\r\n    tools:ignore=\"MergeRootFrame\">\r\n\r\n    <org.webrtc.SurfaceViewRenderer\r\n        android:id=\"@+id/fullscreen_video_view\"\r\n        android:layout_width=\"wrap_content\"\r\n        android:layout_height=\"wrap_content\"\r\n        android:layout_gravity=\"center\" />\r\n\r\n    <org.webrtc.SurfaceViewRenderer\r\n        android:id=\"@+id/pip_video_view\"\r\n        android:layout_height=\"144dp\"\r\n        android:layout_width=\"wrap_content\"\r\n        android:layout_gravity=\"bottom|end\"\r\n        android:layout_margin=\"16dp\"/>\r\n\r\n    <FrameLayout\r\n        android:id=\"@+id/call_fragment_container\"\r\n        android:layout_width=\"match_parent\"\r\n        android:layout_height=\"match_parent\" />\r\n    <FrameLayout\r\n        android:id=\"@+id/hud_fragment_container\"\r\n        android:layout_width=\"match_parent\"\r\n        android:layout_height=\"match_parent\" />\r\n\r\n</FrameLayout>\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/src/main/res/layout/activity_call.xml	(revision bf540945d88389d00f5acde8206c98ded8cdb2e7)
+++ app/src/main/res/layout/activity_call.xml	(date 1606210882164)
@@ -4,15 +4,24 @@
      with a merge causes the fullscreen SurfaceView not to be centered. -->
 <FrameLayout
     xmlns:android="http://schemas.android.com/apk/res/android"
+    xmlns:app="http://schemas.android.com/apk/res-auto"
     xmlns:tools="http://schemas.android.com/tools"
     android:layout_width="match_parent"
     android:layout_height="match_parent"
     tools:ignore="MergeRootFrame">
 
+    <TextView
+        android:id="@+id/tv_count"
+        android:layout_width="wrap_content"
+        android:layout_height="wrap_content"
+        android:text="체크용"
+        android:textColor="#FFFFFF"
+        android:textSize="50sp" />
+
     <org.webrtc.SurfaceViewRenderer
         android:id="@+id/fullscreen_video_view"
         android:layout_width="wrap_content"
-        android:layout_height="wrap_content"
+        android:layout_height="565dp"
         android:layout_gravity="center" />
 
     <org.webrtc.SurfaceViewRenderer
Index: app/src/main/java/com/example/webrtc/android/Main.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>package com.example.webrtc.android;\r\n\r\nimport androidx.appcompat.app.AppCompatActivity;\r\nimport androidx.core.app.ActivityCompat;\r\nimport androidx.core.content.ContextCompat;\r\n\r\nimport android.Manifest;\r\nimport android.content.Intent;\r\nimport android.content.pm.PackageManager;\r\nimport android.os.Build;\r\nimport android.os.Bundle;\r\nimport android.view.View;\r\nimport android.widget.Button;\r\nimport android.widget.ImageView;\r\nimport android.widget.LinearLayout;\r\nimport android.widget.TextView;\r\n\r\nimport java.util.HashMap;\r\nimport java.util.Map;\r\n\r\npublic class Main extends AppCompatActivity {\r\n\r\n    private LinearLayout my_page;\r\n    private TextView quest_name1;\r\n    private TextView quest_name2;\r\n    private TextView quest_name3;\r\n    private ImageView reroll1;\r\n    private ImageView reroll2;\r\n    private ImageView reroll3;\r\n    private int questcnt;\r\n    Map<Integer,String> questSet = new HashMap<>();\r\n    Main.quest[] today_quest = new Main.quest[3];\r\n\r\n    //카메라 권한을 위해\r\n    private int RESULT_PERMISSIONS = 100;\r\n\r\n    @Override\r\n    protected void onCreate(Bundle savedInstanceState) {\r\n        super.onCreate(savedInstanceState);\r\n        setContentView(R.layout.activity_main);\r\n        Main.quest q = new Main.quest(\"\",0,true);\r\n        q.setTodayQuest();\r\n\r\n        // 안드로이드 6.0 이상 버전에서는 CAMERA 권한 허가를 요청한다.\r\n        requestPermissionCamera();\r\n\r\n        Intent intent = getIntent();\r\n\r\n        final String nickName = intent.getStringExtra(\"name\");        //loginactivity로부터 닉네임 전달받음\r\n        final String photoUrl = intent.getStringExtra(\"photoUrl\");        //loginactivity로부터 프로필사진 Url전달받음\r\n        final String email = intent.getStringExtra(\"Email\");        //구글이메일\r\n\r\n        LinearLayout Quest = findViewById(R.id.Quest);\r\n        LinearLayout questlist = findViewById(R.id.questlist);\r\n        LinearLayout main_linear = findViewById(R.id.main_linear);\r\n\r\n        Quest.setOnClickListener(view -> { // 퀘스트 누르면 위로 오버랩되게 처리\r\n            questlist.setVisibility(View.VISIBLE);\r\n            main_linear.setVisibility(View.INVISIBLE);\r\n        });\r\n        questlist.setOnClickListener(view -> {\r\n            questlist.setVisibility(View.INVISIBLE);\r\n            main_linear.setVisibility(View.VISIBLE);\r\n        });\r\n\r\n        reroll1 = findViewById(R.id.reroll1);\r\n        reroll2 = findViewById(R.id.reroll2);\r\n        reroll3 = findViewById(R.id.reroll3);\r\n        reroll1.setOnClickListener(view -> reroll(reroll1));\r\n        reroll2.setOnClickListener(view -> reroll(reroll2));\r\n        reroll3.setOnClickListener(view -> reroll(reroll3));\r\n\r\n        LinearLayout friendlist = findViewById(R.id.Friendlist); // 친구목록으로\r\n        friendlist.setOnClickListener(view -> {\r\n            Intent intent12 = new Intent(getApplicationContext(), Friend_list.class);\r\n            intent12.putExtra(\"Email\" , email);\r\n            startActivity(intent12);\r\n        });\r\n\r\n        my_page = findViewById(R.id.My_page); // 마이페이지로\r\n        my_page.setOnClickListener(view -> {\r\n            Intent intent1 = new Intent(getApplicationContext(), Mypage.class);\r\n            intent1.putExtra(\"name\" , nickName);\r\n            intent1.putExtra(\"photoUrl\",photoUrl);\r\n            intent1.putExtra(\"Email\",email);\r\n            startActivity(intent1);\r\n\r\n        });\r\n\r\n        LinearLayout solo = findViewById(R.id.Solo);\r\n        LinearLayout random = findViewById(R.id.Random);\r\n\r\n        //솔로 플레이 버튼이 눌렸을때 (모드 선택화면)\r\n        solo.setOnClickListener(view -> {\r\n            Intent intent14 = new Intent(getApplicationContext(), Solo_selection.class);\r\n            intent14.putExtra(\"Email\" , email);       //우선 id만 넘겨준다 가정\r\n            startActivity(intent14);\r\n        });\r\n        //랜덤(협력)\r\n        random.setOnClickListener(view -> {\r\n            Intent intent13 = new Intent(getApplicationContext(), ConnectActivity.class);\r\n            //intent13.putExtra(\"Email\" , email);       //우선 id만 넘겨준다 가정\r\n            startActivity(intent13);\r\n        });\r\n    }\r\n\r\n    public class quest{\r\n        String name;\r\n        int num;\r\n        Boolean clear;\r\n\r\n        quest (){\r\n            this.name=\"\";\r\n            this.num=-1;\r\n            this.clear=false;\r\n        }\r\n\r\n        quest (String q, int n, Boolean c){\r\n            this.name=q;\r\n            this.num=n;\r\n            this.clear=c;\r\n        }\r\n\r\n        void setTodayQuest(){ // 퀘스트 랜덤하게 선정\r\n            setQuest();\r\n            int ran = (int)(Math.random()*9);\r\n            for(int i=0;i<3;i++){\r\n                if(ran>=8) ran=0;\r\n                else if(ran<=0) ran=0;\r\n                today_quest[i]= new Main.quest(questSet.get(ran),ran+1,false);\r\n                questSet.remove(ran);\r\n                ran++;\r\n            }\r\n            questcnt=ran;\r\n            quest_name1 = findViewById(R.id.quest_name1);\r\n            quest_name1.setText(today_quest[0].name);\r\n            quest_name2 = findViewById(R.id.quest_name2);\r\n            quest_name2.setText(today_quest[1].name);\r\n            quest_name3 = findViewById(R.id.quest_name3);\r\n            quest_name3.setText(today_quest[2].name);\r\n        }\r\n    };\r\n\r\n    public void setQuest(){\r\n        questSet.put(1,\"스쿼트 55회\");\r\n        questSet.put(2,\"친선전 1회\");\r\n        questSet.put(3,\"1대1 3회\");\r\n        questSet.put(4,\"1대1 승리\");\r\n        questSet.put(5,\"스쿼트 100회\");\r\n        questSet.put(6,\"친구추가\\n1회\");\r\n        questSet.put(7,\"혼자하기\\n3회\");\r\n        questSet.put(8,\"랭커 영상\\n1회 관전\");\r\n        questSet.put(0,\"친선전 승리\");\r\n    }\r\n\r\n    public void reroll(ImageView imageView){ // 리롤하면 버튼 사라지고 퀘스트 교체\r\n        imageView.setOnClickListener(view -> {\r\n            if(imageView == findViewById(R.id.reroll1)) {\r\n                if(questcnt>=8) questcnt=0;\r\n                quest_name1.setText(questSet.get(questcnt));\r\n                reroll1.setVisibility(View.INVISIBLE);\r\n                questcnt++;\r\n            }\r\n            else if(imageView == findViewById(R.id.reroll2)) {\r\n                if(questcnt>=8) questcnt=0;\r\n                quest_name2.setText(questSet.get(questcnt));\r\n                reroll2.setVisibility(View.INVISIBLE);\r\n                questcnt++;\r\n            }\r\n            else {\r\n                if(questcnt>=8) questcnt=0;\r\n                quest_name3.setText(questSet.get(questcnt));\r\n                reroll3.setVisibility(View.INVISIBLE);\r\n                questcnt++;\r\n            }\r\n        });\r\n    }\r\n\r\n    //카메라라\r\n    private boolean requestPermissionCamera() {\r\n        int sdkVersion = Build.VERSION.SDK_INT;\r\n        if(sdkVersion >= Build.VERSION_CODES.M) {\r\n\r\n            if (ContextCompat.checkSelfPermission(this, Manifest.permission.CAMERA) != PackageManager.PERMISSION_GRANTED) {\r\n\r\n                ActivityCompat.requestPermissions(Main.this,\r\n                        new String[]{Manifest.permission.CAMERA},\r\n                        RESULT_PERMISSIONS);\r\n\r\n            }\r\n//            else {\r\n//                setInit();\r\n//            }\r\n        }\r\n//        else{  // version 6 이하일때\r\n//            setInit();\r\n//            return true;\r\n//        }\r\n\r\n        return true;\r\n    }\r\n    @Override\r\n    public void onRequestPermissionsResult(int requestCode,\r\n                                           String permissions[], int[] grantResults) {\r\n\r\n        if (RESULT_PERMISSIONS == requestCode) {\r\n\r\n            if (grantResults.length > 0\r\n                    && grantResults[0] == PackageManager.PERMISSION_GRANTED) {\r\n                // 권한 허가시\r\n                //setInit();\r\n            } else {\r\n                // 권한 거부시\r\n            }\r\n            return;\r\n        }\r\n\r\n    }\r\n}
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/src/main/java/com/example/webrtc/android/Main.java	(revision bf540945d88389d00f5acde8206c98ded8cdb2e7)
+++ app/src/main/java/com/example/webrtc/android/Main.java	(date 1606203974413)
@@ -199,6 +199,7 @@
 
         return true;
     }
+
     @Override
     public void onRequestPermissionsResult(int requestCode,
                                            String permissions[], int[] grantResults) {
Index: app/src/main/java/com/example/webrtc/android/CameraPreview.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>package com.example.webrtc.android;\r\n\r\nimport android.content.Context;\r\nimport android.content.res.Configuration;\r\nimport android.hardware.Camera;\r\nimport android.util.AttributeSet;\r\nimport android.view.SurfaceHolder;\r\nimport android.view.SurfaceView;\r\n\r\nimport java.io.IOException;\r\nimport java.util.List;\r\n\r\npublic class CameraPreview extends SurfaceView implements SurfaceHolder.Callback {\r\n    private SurfaceHolder mHolder;\r\n    private Camera mCamera;\r\n    public List<Camera.Size> listPreviewSizes;\r\n    private Camera.Size previewSize;\r\n    private Context context;\r\n\r\n    //content를 파싱해서 맞는 카메라를 켜줌\r\n    public String parsing(String s){\r\n        String result = \"\";\r\n\r\n        for(int i=0;i<s.length();i++){\r\n            if(s.charAt(i) == '@'){\r\n                break;\r\n            }\r\n            else result+=s.charAt(i);\r\n        }\r\n        return result;\r\n    }\r\n    // SurfaceView 생성자\r\n    public CameraPreview(Context context, AttributeSet attrs) {\r\n        super(context, attrs);\r\n        this.context = context;\r\n\r\n        String s = context.toString();\r\n        String field = parsing(s);\r\n\r\n        if(field.equals(\"com.example.webrtc.android.solo_speed_play\")) mCamera = solo_speed_play.getCamera();\r\n        //if(field.equals(\"com.example.squatchallenge.team_play\")) mCamera = team_play.getCamera();\r\n        //mCamera = solo_speed_play.getCamera();\r\n\r\n        if(mCamera == null){\r\n            mCamera = Camera.open();\r\n        }\r\n        listPreviewSizes = mCamera.getParameters().getSupportedPreviewSizes();\r\n    }\r\n\r\n    //  SurfaceView 생성시 호출\r\n    @Override\r\n    public void surfaceCreated(SurfaceHolder surfaceHolder) {\r\n\r\n        try {\r\n            // 카메라 객체를 사용할 수 있게 연결한다.\r\n            if(mCamera  == null){\r\n                mCamera  = Camera.open();\r\n            }\r\n            // 카메라 설정\r\n            Camera.Parameters parameters = mCamera .getParameters();\r\n\r\n            // 카메라의 회전이 가로/세로일때 화면을 설정한다.\r\n            if (getResources().getConfiguration().orientation != Configuration.ORIENTATION_LANDSCAPE) {\r\n                parameters.set(\"orientation\", \"portrait\");\r\n                mCamera.setDisplayOrientation(90);\r\n                parameters.setRotation(90);\r\n            } else {\r\n                parameters.set(\"orientation\", \"landscape\");\r\n                mCamera.setDisplayOrientation(0);\r\n                parameters.setRotation(0);\r\n            }\r\n            mCamera.setParameters(parameters);\r\n            mCamera.setPreviewDisplay(surfaceHolder);\r\n            // 카메라 미리보기를 시작한다.\r\n            mCamera.startPreview();\r\n\r\n            // 자동포커스 설정\r\n            mCamera.autoFocus(new Camera.AutoFocusCallback() {\r\n                public void onAutoFocus(boolean success, Camera camera) {\r\n                    if (success) {\r\n\r\n                    }\r\n                }\r\n            });\r\n        } catch (IOException e) {\r\n        }\r\n    }\r\n    // SurfaceView 의 크기가 바뀌면 호출\r\n    @Override\r\n    public void surfaceChanged(SurfaceHolder surfaceHolder, int i, int w, int h) {\r\n\r\n    }\r\n    @Override\r\n    public void surfaceDestroyed(SurfaceHolder surfaceHolder) {\r\n        if(mCamera != null){\r\n            // 카메라 미리보기를 종료한다.\r\n            mCamera.stopPreview();\r\n            mCamera.setPreviewCallback(null);\r\n            mCamera.release();\r\n            mCamera = null;\r\n        }\r\n    }\r\n\r\n}\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- app/src/main/java/com/example/webrtc/android/CameraPreview.java	(revision bf540945d88389d00f5acde8206c98ded8cdb2e7)
+++ app/src/main/java/com/example/webrtc/android/CameraPreview.java	(date 1605933737172)
@@ -42,7 +42,7 @@
         //mCamera = solo_speed_play.getCamera();
 
         if(mCamera == null){
-            mCamera = Camera.open();
+            mCamera = Camera.open(-1);
         }
         listPreviewSizes = mCamera.getParameters().getSupportedPreviewSizes();
     }
Index: webrtc/src/main/java/org/appspot/apprtc/PeerConnectionClient.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>/*\r\n *  Copyright 2014 The WebRTC Project Authors. All rights reserved.\r\n *\r\n *  Use of this source code is governed by a BSD-style license\r\n *  that can be found in the LICENSE file in the root of the source\r\n *  tree. An additional intellectual property rights grant can be found\r\n *  in the file PATENTS.  All contributing project authors may\r\n *  be found in the AUTHORS file in the root of the source tree.\r\n */\r\n\r\npackage org.appspot.apprtc;\r\n\r\nimport android.content.Context;\r\nimport android.os.Environment;\r\nimport android.os.ParcelFileDescriptor;\r\nimport android.preference.PreferenceManager;\r\nimport android.util.Log;\r\nimport java.io.File;\r\nimport java.io.IOException;\r\nimport java.nio.ByteBuffer;\r\nimport java.nio.charset.Charset;\r\nimport java.text.DateFormat;\r\nimport java.text.SimpleDateFormat;\r\nimport java.util.ArrayList;\r\nimport java.util.Arrays;\r\nimport java.util.Collections;\r\nimport java.util.Date;\r\nimport java.util.Iterator;\r\nimport java.util.List;\r\nimport java.util.Locale;\r\nimport java.util.Timer;\r\nimport java.util.TimerTask;\r\nimport java.util.concurrent.ExecutorService;\r\nimport java.util.concurrent.Executors;\r\nimport java.util.regex.Matcher;\r\nimport java.util.regex.Pattern;\r\nimport javax.annotation.Nullable;\r\nimport org.appspot.apprtc.AppRTCClient.SignalingParameters;\r\nimport org.appspot.apprtc.RecordedAudioToFileController;\r\nimport org.webrtc.AudioSource;\r\nimport org.webrtc.AudioTrack;\r\nimport org.webrtc.CameraVideoCapturer;\r\nimport org.webrtc.DataChannel;\r\nimport org.webrtc.DefaultVideoDecoderFactory;\r\nimport org.webrtc.DefaultVideoEncoderFactory;\r\nimport org.webrtc.EglBase;\r\nimport org.webrtc.IceCandidate;\r\nimport org.webrtc.Logging;\r\nimport org.webrtc.MediaConstraints;\r\nimport org.webrtc.MediaStream;\r\nimport org.webrtc.MediaStreamTrack;\r\nimport org.webrtc.MediaStreamTrack.MediaType;\r\nimport org.webrtc.PeerConnection;\r\nimport org.webrtc.PeerConnection.IceConnectionState;\r\nimport org.webrtc.PeerConnectionFactory;\r\nimport org.webrtc.RtpParameters;\r\nimport org.webrtc.RtpReceiver;\r\nimport org.webrtc.RtpSender;\r\nimport org.webrtc.RtpTransceiver;\r\nimport org.webrtc.SdpObserver;\r\nimport org.webrtc.SessionDescription;\r\nimport org.webrtc.SoftwareVideoDecoderFactory;\r\nimport org.webrtc.SoftwareVideoEncoderFactory;\r\nimport org.webrtc.StatsObserver;\r\nimport org.webrtc.StatsReport;\r\nimport org.webrtc.SurfaceTextureHelper;\r\nimport org.webrtc.VideoCapturer;\r\nimport org.webrtc.VideoDecoderFactory;\r\nimport org.webrtc.VideoEncoderFactory;\r\nimport org.webrtc.VideoSink;\r\nimport org.webrtc.VideoSource;\r\nimport org.webrtc.VideoTrack;\r\nimport org.webrtc.audio.AudioDeviceModule;\r\nimport org.webrtc.audio.JavaAudioDeviceModule;\r\nimport org.webrtc.audio.JavaAudioDeviceModule.AudioRecordErrorCallback;\r\nimport org.webrtc.audio.JavaAudioDeviceModule.AudioTrackErrorCallback;\r\nimport org.webrtc.audio.LegacyAudioDeviceModule;\r\nimport org.webrtc.voiceengine.WebRtcAudioManager;\r\nimport org.webrtc.voiceengine.WebRtcAudioRecord;\r\nimport org.webrtc.voiceengine.WebRtcAudioRecord.AudioRecordStartErrorCode;\r\nimport org.webrtc.voiceengine.WebRtcAudioRecord.WebRtcAudioRecordErrorCallback;\r\nimport org.webrtc.voiceengine.WebRtcAudioTrack;\r\nimport org.webrtc.voiceengine.WebRtcAudioTrack.AudioTrackStartErrorCode;\r\nimport org.webrtc.voiceengine.WebRtcAudioUtils;\r\n\r\n/**\r\n * Peer connection client implementation.\r\n *\r\n * <p>All public methods are routed to local looper thread.\r\n * All PeerConnectionEvents callbacks are invoked from the same looper thread.\r\n * This class is a singleton.\r\n */\r\npublic class PeerConnectionClient {\r\n  public static final String VIDEO_TRACK_ID = \"ARDAMSv0\";\r\n  public static final String AUDIO_TRACK_ID = \"ARDAMSa0\";\r\n  public static final String VIDEO_TRACK_TYPE = \"video\";\r\n  private static final String TAG = \"PCRTCClient\";\r\n  private static final String VIDEO_CODEC_VP8 = \"VP8\";\r\n  private static final String VIDEO_CODEC_VP9 = \"VP9\";\r\n  private static final String VIDEO_CODEC_H264 = \"H264\";\r\n  private static final String VIDEO_CODEC_H264_BASELINE = \"H264 Baseline\";\r\n  private static final String VIDEO_CODEC_H264_HIGH = \"H264 High\";\r\n  private static final String AUDIO_CODEC_OPUS = \"opus\";\r\n  private static final String AUDIO_CODEC_ISAC = \"ISAC\";\r\n  private static final String VIDEO_CODEC_PARAM_START_BITRATE = \"x-google-start-bitrate\";\r\n  private static final String VIDEO_FLEXFEC_FIELDTRIAL =\r\n      \"WebRTC-FlexFEC-03-Advertised/Enabled/WebRTC-FlexFEC-03/Enabled/\";\r\n  private static final String VIDEO_VP8_INTEL_HW_ENCODER_FIELDTRIAL = \"WebRTC-IntelVP8/Enabled/\";\r\n  private static final String DISABLE_WEBRTC_AGC_FIELDTRIAL =\r\n      \"WebRTC-Audio-MinimizeResamplingOnMobile/Enabled/\";\r\n  private static final String AUDIO_CODEC_PARAM_BITRATE = \"maxaveragebitrate\";\r\n  private static final String AUDIO_ECHO_CANCELLATION_CONSTRAINT = \"googEchoCancellation\";\r\n  private static final String AUDIO_AUTO_GAIN_CONTROL_CONSTRAINT = \"googAutoGainControl\";\r\n  private static final String AUDIO_HIGH_PASS_FILTER_CONSTRAINT = \"googHighpassFilter\";\r\n  private static final String AUDIO_NOISE_SUPPRESSION_CONSTRAINT = \"googNoiseSuppression\";\r\n  private static final String DTLS_SRTP_KEY_AGREEMENT_CONSTRAINT = \"DtlsSrtpKeyAgreement\";\r\n  private static final int HD_VIDEO_WIDTH = 1280;\r\n  private static final int HD_VIDEO_HEIGHT = 720;\r\n  private static final int BPS_IN_KBPS = 1000;\r\n  private static final String RTCEVENTLOG_OUTPUT_DIR_NAME = \"rtc_event_log\";\r\n\r\n  // Executor thread is started once in private ctor and is used for all\r\n  // peer connection API calls to ensure new peer connection factory is\r\n  // created on the same thread as previously destroyed factory.\r\n  private static final ExecutorService executor = Executors.newSingleThreadExecutor();\r\n\r\n  private final PCObserver pcObserver = new PCObserver();\r\n  private final SDPObserver sdpObserver = new SDPObserver();\r\n  private final Timer statsTimer = new Timer();\r\n  private final EglBase rootEglBase;\r\n  private final Context appContext;\r\n  private final PeerConnectionParameters peerConnectionParameters;\r\n  private final PeerConnectionEvents events;\r\n\r\n  @Nullable\r\n  private PeerConnectionFactory factory;\r\n  @Nullable\r\n  private PeerConnection peerConnection;\r\n  @Nullable\r\n  private AudioSource audioSource;\r\n  @Nullable private SurfaceTextureHelper surfaceTextureHelper;\r\n  @Nullable private VideoSource videoSource;\r\n  private boolean preferIsac;\r\n  private boolean videoCapturerStopped;\r\n  private boolean isError;\r\n  @Nullable\r\n  private VideoSink localRender;\r\n  @Nullable private List<VideoSink> remoteSinks;\r\n  private SignalingParameters signalingParameters;\r\n  private int videoWidth;\r\n  private int videoHeight;\r\n  private int videoFps;\r\n  private MediaConstraints audioConstraints;\r\n  private MediaConstraints sdpMediaConstraints;\r\n  // Queued remote ICE candidates are consumed only after both local and\r\n  // remote descriptions are set. Similarly local ICE candidates are sent to\r\n  // remote peer after both local and remote description are set.\r\n  @Nullable\r\n  private List<IceCandidate> queuedRemoteCandidates;\r\n  private boolean isInitiator;\r\n  @Nullable\r\n  private SessionDescription localSdp; // either offer or answer SDP\r\n  @Nullable\r\n  private VideoCapturer videoCapturer;\r\n  // enableVideo is set to true if video should be rendered and sent.\r\n  private boolean renderVideo = true;\r\n  @Nullable\r\n  private VideoTrack localVideoTrack;\r\n  @Nullable\r\n  private VideoTrack remoteVideoTrack;\r\n  @Nullable\r\n  private RtpSender localVideoSender;\r\n  // enableAudio is set to true if audio should be sent.\r\n  private boolean enableAudio = true;\r\n  @Nullable\r\n  private AudioTrack localAudioTrack;\r\n  @Nullable\r\n  private DataChannel dataChannel;\r\n  private final boolean dataChannelEnabled;\r\n  // Enable RtcEventLog.\r\n  @Nullable\r\n  private RtcEventLog rtcEventLog;\r\n  // Implements the WebRtcAudioRecordSamplesReadyCallback interface and writes\r\n  // recorded audio samples to an output file.\r\n  @Nullable\r\n  private RecordedAudioToFileController saveRecordedAudioToFile = null;\r\n\r\n  /**\r\n   * Peer connection parameters.\r\n   */\r\n  public static class DataChannelParameters {\r\n    public final boolean ordered;\r\n    public final int maxRetransmitTimeMs;\r\n    public final int maxRetransmits;\r\n    public final String protocol;\r\n    public final boolean negotiated;\r\n    public final int id;\r\n\r\n    public DataChannelParameters(boolean ordered, int maxRetransmitTimeMs, int maxRetransmits,\r\n        String protocol, boolean negotiated, int id) {\r\n      this.ordered = ordered;\r\n      this.maxRetransmitTimeMs = maxRetransmitTimeMs;\r\n      this.maxRetransmits = maxRetransmits;\r\n      this.protocol = protocol;\r\n      this.negotiated = negotiated;\r\n      this.id = id;\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Peer connection parameters.\r\n   */\r\n  public static class PeerConnectionParameters {\r\n    public final boolean videoCallEnabled;\r\n    public final boolean loopback;\r\n    public final boolean tracing;\r\n    public final int videoWidth;\r\n    public final int videoHeight;\r\n    public final int videoFps;\r\n    public final int videoMaxBitrate;\r\n    public final String videoCodec;\r\n    public final boolean videoCodecHwAcceleration;\r\n    public final boolean videoFlexfecEnabled;\r\n    public final int audioStartBitrate;\r\n    public final String audioCodec;\r\n    public final boolean noAudioProcessing;\r\n    public final boolean aecDump;\r\n    public final boolean saveInputAudioToFile;\r\n    public final boolean useOpenSLES;\r\n    public final boolean disableBuiltInAEC;\r\n    public final boolean disableBuiltInAGC;\r\n    public final boolean disableBuiltInNS;\r\n    public final boolean disableWebRtcAGCAndHPF;\r\n    public final boolean enableRtcEventLog;\r\n    public final boolean useLegacyAudioDevice;\r\n    private final DataChannelParameters dataChannelParameters;\r\n\r\n    public PeerConnectionParameters(boolean videoCallEnabled, boolean loopback, boolean tracing,\r\n        int videoWidth, int videoHeight, int videoFps, int videoMaxBitrate, String videoCodec,\r\n        boolean videoCodecHwAcceleration, boolean videoFlexfecEnabled, int audioStartBitrate,\r\n        String audioCodec, boolean noAudioProcessing, boolean aecDump, boolean saveInputAudioToFile,\r\n        boolean useOpenSLES, boolean disableBuiltInAEC, boolean disableBuiltInAGC,\r\n        boolean disableBuiltInNS, boolean disableWebRtcAGCAndHPF, boolean enableRtcEventLog,\r\n        boolean useLegacyAudioDevice, DataChannelParameters dataChannelParameters) {\r\n      this.videoCallEnabled = videoCallEnabled;\r\n      this.loopback = loopback;\r\n      this.tracing = tracing;\r\n      this.videoWidth = videoWidth;\r\n      this.videoHeight = videoHeight;\r\n      this.videoFps = videoFps;\r\n      this.videoMaxBitrate = videoMaxBitrate;\r\n      this.videoCodec = videoCodec;\r\n      this.videoFlexfecEnabled = videoFlexfecEnabled;\r\n      this.videoCodecHwAcceleration = videoCodecHwAcceleration;\r\n      this.audioStartBitrate = audioStartBitrate;\r\n      this.audioCodec = audioCodec;\r\n      this.noAudioProcessing = noAudioProcessing;\r\n      this.aecDump = aecDump;\r\n      this.saveInputAudioToFile = saveInputAudioToFile;\r\n      this.useOpenSLES = useOpenSLES;\r\n      this.disableBuiltInAEC = disableBuiltInAEC;\r\n      this.disableBuiltInAGC = disableBuiltInAGC;\r\n      this.disableBuiltInNS = disableBuiltInNS;\r\n      this.disableWebRtcAGCAndHPF = disableWebRtcAGCAndHPF;\r\n      this.enableRtcEventLog = enableRtcEventLog;\r\n      this.useLegacyAudioDevice = useLegacyAudioDevice;\r\n      this.dataChannelParameters = dataChannelParameters;\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Peer connection events.\r\n   */\r\n  public interface PeerConnectionEvents {\r\n    /**\r\n     * Callback fired once local SDP is created and set.\r\n     */\r\n    void onLocalDescription(final SessionDescription sdp);\r\n\r\n    /**\r\n     * Callback fired once local Ice candidate is generated.\r\n     */\r\n    void onIceCandidate(final IceCandidate candidate);\r\n\r\n    /**\r\n     * Callback fired once local ICE candidates are removed.\r\n     */\r\n    void onIceCandidatesRemoved(final IceCandidate[] candidates);\r\n\r\n    /**\r\n     * Callback fired once connection is established (IceConnectionState is\r\n     * CONNECTED).\r\n     */\r\n    void onIceConnected();\r\n\r\n    /**\r\n     * Callback fired once connection is closed (IceConnectionState is\r\n     * DISCONNECTED).\r\n     */\r\n    void onIceDisconnected();\r\n\r\n    /**\r\n     * Callback fired once peer connection is closed.\r\n     */\r\n    void onPeerConnectionClosed();\r\n\r\n    /**\r\n     * Callback fired once peer connection statistics is ready.\r\n     */\r\n    void onPeerConnectionStatsReady(final StatsReport[] reports);\r\n\r\n    /**\r\n     * Callback fired once peer connection error happened.\r\n     */\r\n    void onPeerConnectionError(final String description);\r\n  }\r\n\r\n  /**\r\n   * Create a PeerConnectionClient with the specified parameters. PeerConnectionClient takes\r\n   * ownership of |eglBase|.\r\n   */\r\n  public PeerConnectionClient(Context appContext, EglBase eglBase,\r\n      PeerConnectionParameters peerConnectionParameters, PeerConnectionEvents events) {\r\n    this.rootEglBase = eglBase;\r\n    this.appContext = appContext;\r\n    this.events = events;\r\n    this.peerConnectionParameters = peerConnectionParameters;\r\n    this.dataChannelEnabled = peerConnectionParameters.dataChannelParameters != null;\r\n\r\n    Log.d(TAG, \"Preferred video codec: \" + getSdpVideoCodecName(peerConnectionParameters));\r\n\r\n    final String fieldTrials = getFieldTrials(peerConnectionParameters);\r\n    executor.execute(() -> {\r\n      Log.d(TAG, \"Initialize WebRTC. Field trials: \" + fieldTrials);\r\n      PeerConnectionFactory.initialize(\r\n          PeerConnectionFactory.InitializationOptions.builder(appContext)\r\n              .setFieldTrials(fieldTrials)\r\n              .setEnableInternalTracer(true)\r\n              .createInitializationOptions());\r\n    });\r\n  }\r\n\r\n  /**\r\n   * This function should only be called once.\r\n   */\r\n  public void createPeerConnectionFactory(PeerConnectionFactory.Options options) {\r\n    if (factory != null) {\r\n      throw new IllegalStateException(\"PeerConnectionFactory has already been constructed\");\r\n    }\r\n    executor.execute(() -> createPeerConnectionFactoryInternal(options));\r\n  }\r\n\r\n  public void createPeerConnection(final VideoSink localRender, final VideoSink remoteSink,\r\n      final VideoCapturer videoCapturer, final SignalingParameters signalingParameters) {\r\n    if (peerConnectionParameters.videoCallEnabled && videoCapturer == null) {\r\n      Log.w(TAG, \"Video call enabled but no video capturer provided.\");\r\n    }\r\n    createPeerConnection(\r\n        localRender, Collections.singletonList(remoteSink), videoCapturer, signalingParameters);\r\n  }\r\n\r\n  public void createPeerConnection(final VideoSink localRender, final List<VideoSink> remoteSinks,\r\n      final VideoCapturer videoCapturer, final SignalingParameters signalingParameters) {\r\n    if (peerConnectionParameters == null) {\r\n      Log.e(TAG, \"Creating peer connection without initializing factory.\");\r\n      return;\r\n    }\r\n    this.localRender = localRender;\r\n    this.remoteSinks = remoteSinks;\r\n    this.videoCapturer = videoCapturer;\r\n    this.signalingParameters = signalingParameters;\r\n    executor.execute(() -> {\r\n      try {\r\n        createMediaConstraintsInternal();\r\n        createPeerConnectionInternal();\r\n        maybeCreateAndStartRtcEventLog();\r\n      } catch (Exception e) {\r\n        reportError(\"Failed to create peer connection: \" + e.getMessage());\r\n        throw e;\r\n      }\r\n    });\r\n  }\r\n\r\n  public void close() {\r\n    executor.execute(this ::closeInternal);\r\n  }\r\n\r\n  private boolean isVideoCallEnabled() {\r\n    return peerConnectionParameters.videoCallEnabled && videoCapturer != null;\r\n  }\r\n\r\n  private void createPeerConnectionFactoryInternal(PeerConnectionFactory.Options options) {\r\n    isError = false;\r\n\r\n    if (peerConnectionParameters.tracing) {\r\n      PeerConnectionFactory.startInternalTracingCapture(\r\n          Environment.getExternalStorageDirectory().getAbsolutePath() + File.separator\r\n          + \"webrtc-trace.txt\");\r\n    }\r\n\r\n    // Check if ISAC is used by default.\r\n    preferIsac = peerConnectionParameters.audioCodec != null\r\n        && peerConnectionParameters.audioCodec.equals(AUDIO_CODEC_ISAC);\r\n\r\n    // It is possible to save a copy in raw PCM format on a file by checking\r\n    // the \"Save input audio to file\" checkbox in the Settings UI. A callback\r\n    // interface is set when this flag is enabled. As a result, a copy of recorded\r\n    // audio samples are provided to this client directly from the native audio\r\n    // layer in Java.\r\n    if (peerConnectionParameters.saveInputAudioToFile) {\r\n      if (!peerConnectionParameters.useOpenSLES) {\r\n        Log.d(TAG, \"Enable recording of microphone input audio to file\");\r\n        saveRecordedAudioToFile = new RecordedAudioToFileController(executor);\r\n      } else {\r\n        // TODO(henrika): ensure that the UI reflects that if OpenSL ES is selected,\r\n        // then the \"Save inut audio to file\" option shall be grayed out.\r\n        Log.e(TAG, \"Recording of input audio is not supported for OpenSL ES\");\r\n      }\r\n    }\r\n\r\n    final AudioDeviceModule adm = peerConnectionParameters.useLegacyAudioDevice\r\n        ? createLegacyAudioDevice()\r\n        : createJavaAudioDevice();\r\n\r\n    // Create peer connection factory.\r\n    if (options != null) {\r\n      Log.d(TAG, \"Factory networkIgnoreMask option: \" + options.networkIgnoreMask);\r\n    }\r\n    final boolean enableH264HighProfile =\r\n        VIDEO_CODEC_H264_HIGH.equals(peerConnectionParameters.videoCodec);\r\n    final VideoEncoderFactory encoderFactory;\r\n    final VideoDecoderFactory decoderFactory;\r\n\r\n    if (peerConnectionParameters.videoCodecHwAcceleration) {\r\n      encoderFactory = new DefaultVideoEncoderFactory(\r\n          rootEglBase.getEglBaseContext(), true /* enableIntelVp8Encoder */, enableH264HighProfile);\r\n      decoderFactory = new DefaultVideoDecoderFactory(rootEglBase.getEglBaseContext());\r\n    } else {\r\n      encoderFactory = new SoftwareVideoEncoderFactory();\r\n      decoderFactory = new SoftwareVideoDecoderFactory();\r\n    }\r\n\r\n    factory = PeerConnectionFactory.builder()\r\n                  .setOptions(options)\r\n                  .setAudioDeviceModule(adm)\r\n                  .setVideoEncoderFactory(encoderFactory)\r\n                  .setVideoDecoderFactory(decoderFactory)\r\n                  .createPeerConnectionFactory();\r\n    Log.d(TAG, \"Peer connection factory created.\");\r\n    adm.release();\r\n  }\r\n\r\n  AudioDeviceModule createLegacyAudioDevice() {\r\n    // Enable/disable OpenSL ES playback.\r\n    if (!peerConnectionParameters.useOpenSLES) {\r\n      Log.d(TAG, \"Disable OpenSL ES audio even if device supports it\");\r\n      WebRtcAudioManager.setBlacklistDeviceForOpenSLESUsage(true /* enable */);\r\n    } else {\r\n      Log.d(TAG, \"Allow OpenSL ES audio if device supports it\");\r\n      WebRtcAudioManager.setBlacklistDeviceForOpenSLESUsage(false);\r\n    }\r\n\r\n    if (peerConnectionParameters.disableBuiltInAEC) {\r\n      Log.d(TAG, \"Disable built-in AEC even if device supports it\");\r\n      WebRtcAudioUtils.setWebRtcBasedAcousticEchoCanceler(true);\r\n    } else {\r\n      Log.d(TAG, \"Enable built-in AEC if device supports it\");\r\n      WebRtcAudioUtils.setWebRtcBasedAcousticEchoCanceler(false);\r\n    }\r\n\r\n    if (peerConnectionParameters.disableBuiltInNS) {\r\n      Log.d(TAG, \"Disable built-in NS even if device supports it\");\r\n      WebRtcAudioUtils.setWebRtcBasedNoiseSuppressor(true);\r\n    } else {\r\n      Log.d(TAG, \"Enable built-in NS if device supports it\");\r\n      WebRtcAudioUtils.setWebRtcBasedNoiseSuppressor(false);\r\n    }\r\n\r\n    WebRtcAudioRecord.setOnAudioSamplesReady(saveRecordedAudioToFile);\r\n\r\n    // Set audio record error callbacks.\r\n    WebRtcAudioRecord.setErrorCallback(new WebRtcAudioRecordErrorCallback() {\r\n      @Override\r\n      public void onWebRtcAudioRecordInitError(String errorMessage) {\r\n        Log.e(TAG, \"onWebRtcAudioRecordInitError: \" + errorMessage);\r\n        reportError(errorMessage);\r\n      }\r\n\r\n      @Override\r\n      public void onWebRtcAudioRecordStartError(\r\n          AudioRecordStartErrorCode errorCode, String errorMessage) {\r\n        Log.e(TAG, \"onWebRtcAudioRecordStartError: \" + errorCode + \". \" + errorMessage);\r\n        reportError(errorMessage);\r\n      }\r\n\r\n      @Override\r\n      public void onWebRtcAudioRecordError(String errorMessage) {\r\n        Log.e(TAG, \"onWebRtcAudioRecordError: \" + errorMessage);\r\n        reportError(errorMessage);\r\n      }\r\n    });\r\n\r\n    WebRtcAudioTrack.setErrorCallback(new WebRtcAudioTrack.ErrorCallback() {\r\n      @Override\r\n      public void onWebRtcAudioTrackInitError(String errorMessage) {\r\n        Log.e(TAG, \"onWebRtcAudioTrackInitError: \" + errorMessage);\r\n        reportError(errorMessage);\r\n      }\r\n\r\n      @Override\r\n      public void onWebRtcAudioTrackStartError(\r\n          AudioTrackStartErrorCode errorCode, String errorMessage) {\r\n        Log.e(TAG, \"onWebRtcAudioTrackStartError: \" + errorCode + \". \" + errorMessage);\r\n        reportError(errorMessage);\r\n      }\r\n\r\n      @Override\r\n      public void onWebRtcAudioTrackError(String errorMessage) {\r\n        Log.e(TAG, \"onWebRtcAudioTrackError: \" + errorMessage);\r\n        reportError(errorMessage);\r\n      }\r\n    });\r\n\r\n    return new LegacyAudioDeviceModule();\r\n  }\r\n\r\n  AudioDeviceModule createJavaAudioDevice() {\r\n    // Enable/disable OpenSL ES playback.\r\n    if (!peerConnectionParameters.useOpenSLES) {\r\n      Log.w(TAG, \"External OpenSLES ADM not implemented yet.\");\r\n      // TODO(magjed): Add support for external OpenSLES ADM.\r\n    }\r\n\r\n    // Set audio record error callbacks.\r\n    AudioRecordErrorCallback audioRecordErrorCallback = new AudioRecordErrorCallback() {\r\n      @Override\r\n      public void onWebRtcAudioRecordInitError(String errorMessage) {\r\n        Log.e(TAG, \"onWebRtcAudioRecordInitError: \" + errorMessage);\r\n        reportError(errorMessage);\r\n      }\r\n\r\n      @Override\r\n      public void onWebRtcAudioRecordStartError(\r\n          JavaAudioDeviceModule.AudioRecordStartErrorCode errorCode, String errorMessage) {\r\n        Log.e(TAG, \"onWebRtcAudioRecordStartError: \" + errorCode + \". \" + errorMessage);\r\n        reportError(errorMessage);\r\n      }\r\n\r\n      @Override\r\n      public void onWebRtcAudioRecordError(String errorMessage) {\r\n        Log.e(TAG, \"onWebRtcAudioRecordError: \" + errorMessage);\r\n        reportError(errorMessage);\r\n      }\r\n    };\r\n\r\n    AudioTrackErrorCallback audioTrackErrorCallback = new AudioTrackErrorCallback() {\r\n      @Override\r\n      public void onWebRtcAudioTrackInitError(String errorMessage) {\r\n        Log.e(TAG, \"onWebRtcAudioTrackInitError: \" + errorMessage);\r\n        reportError(errorMessage);\r\n      }\r\n\r\n      @Override\r\n      public void onWebRtcAudioTrackStartError(\r\n          JavaAudioDeviceModule.AudioTrackStartErrorCode errorCode, String errorMessage) {\r\n        Log.e(TAG, \"onWebRtcAudioTrackStartError: \" + errorCode + \". \" + errorMessage);\r\n        reportError(errorMessage);\r\n      }\r\n\r\n      @Override\r\n      public void onWebRtcAudioTrackError(String errorMessage) {\r\n        Log.e(TAG, \"onWebRtcAudioTrackError: \" + errorMessage);\r\n        reportError(errorMessage);\r\n      }\r\n    };\r\n\r\n    return JavaAudioDeviceModule.builder(appContext)\r\n        .setSamplesReadyCallback(saveRecordedAudioToFile)\r\n        .setUseHardwareAcousticEchoCanceler(!peerConnectionParameters.disableBuiltInAEC)\r\n        .setUseHardwareNoiseSuppressor(!peerConnectionParameters.disableBuiltInNS)\r\n        .setAudioRecordErrorCallback(audioRecordErrorCallback)\r\n        .setAudioTrackErrorCallback(audioTrackErrorCallback)\r\n        .createAudioDeviceModule();\r\n  }\r\n\r\n  private void createMediaConstraintsInternal() {\r\n    // Create video constraints if video call is enabled.\r\n    if (isVideoCallEnabled()) {\r\n      videoWidth = peerConnectionParameters.videoWidth;\r\n      videoHeight = peerConnectionParameters.videoHeight;\r\n      videoFps = peerConnectionParameters.videoFps;\r\n\r\n      // If video resolution is not specified, default to HD.\r\n      if (videoWidth == 0 || videoHeight == 0) {\r\n        videoWidth = HD_VIDEO_WIDTH;\r\n        videoHeight = HD_VIDEO_HEIGHT;\r\n      }\r\n\r\n      // If fps is not specified, default to 30.\r\n      if (videoFps == 0) {\r\n        videoFps = 30;\r\n      }\r\n      Logging.d(TAG, \"Capturing format: \" + videoWidth + \"x\" + videoHeight + \"@\" + videoFps);\r\n    }\r\n\r\n    // Create audio constraints.\r\n    audioConstraints = new MediaConstraints();\r\n    // added for audio performance measurements\r\n    if (peerConnectionParameters.noAudioProcessing) {\r\n      Log.d(TAG, \"Disabling audio processing\");\r\n      audioConstraints.mandatory.add(\r\n          new MediaConstraints.KeyValuePair(AUDIO_ECHO_CANCELLATION_CONSTRAINT, \"false\"));\r\n      audioConstraints.mandatory.add(\r\n          new MediaConstraints.KeyValuePair(AUDIO_AUTO_GAIN_CONTROL_CONSTRAINT, \"false\"));\r\n      audioConstraints.mandatory.add(\r\n          new MediaConstraints.KeyValuePair(AUDIO_HIGH_PASS_FILTER_CONSTRAINT, \"false\"));\r\n      audioConstraints.mandatory.add(\r\n          new MediaConstraints.KeyValuePair(AUDIO_NOISE_SUPPRESSION_CONSTRAINT, \"false\"));\r\n    }\r\n    // Create SDP constraints.\r\n    sdpMediaConstraints = new MediaConstraints();\r\n    sdpMediaConstraints.mandatory.add(\r\n        new MediaConstraints.KeyValuePair(\"OfferToReceiveAudio\", \"true\"));\r\n    sdpMediaConstraints.mandatory.add(new MediaConstraints.KeyValuePair(\r\n        \"OfferToReceiveVideo\", Boolean.toString(isVideoCallEnabled())));\r\n  }\r\n\r\n  private void createPeerConnectionInternal() {\r\n    if (factory == null || isError) {\r\n      Log.e(TAG, \"Peerconnection factory is not created\");\r\n      return;\r\n    }\r\n    Log.d(TAG, \"Create peer connection.\");\r\n\r\n    queuedRemoteCandidates = new ArrayList<>();\r\n\r\n    PeerConnection.RTCConfiguration rtcConfig =\r\n        new PeerConnection.RTCConfiguration(signalingParameters.iceServers);\r\n    // TCP candidates are only useful when connecting to a server that supports\r\n    // ICE-TCP.\r\n    rtcConfig.tcpCandidatePolicy = PeerConnection.TcpCandidatePolicy.DISABLED;\r\n    rtcConfig.bundlePolicy = PeerConnection.BundlePolicy.MAXBUNDLE;\r\n    rtcConfig.rtcpMuxPolicy = PeerConnection.RtcpMuxPolicy.REQUIRE;\r\n    rtcConfig.continualGatheringPolicy = PeerConnection.ContinualGatheringPolicy.GATHER_CONTINUALLY;\r\n    // Use ECDSA encryption.\r\n    rtcConfig.keyType = PeerConnection.KeyType.ECDSA;\r\n    // Enable DTLS for normal calls and disable for loopback calls.\r\n    rtcConfig.enableDtlsSrtp = !peerConnectionParameters.loopback;\r\n    rtcConfig.sdpSemantics = PeerConnection.SdpSemantics.UNIFIED_PLAN;\r\n\r\n    peerConnection = factory.createPeerConnection(rtcConfig, pcObserver);\r\n\r\n    if (dataChannelEnabled) {\r\n      DataChannel.Init init = new DataChannel.Init();\r\n      init.ordered = peerConnectionParameters.dataChannelParameters.ordered;\r\n      init.negotiated = peerConnectionParameters.dataChannelParameters.negotiated;\r\n      init.maxRetransmits = peerConnectionParameters.dataChannelParameters.maxRetransmits;\r\n      init.maxRetransmitTimeMs = peerConnectionParameters.dataChannelParameters.maxRetransmitTimeMs;\r\n      init.id = peerConnectionParameters.dataChannelParameters.id;\r\n      init.protocol = peerConnectionParameters.dataChannelParameters.protocol;\r\n      dataChannel = peerConnection.createDataChannel(\"ApprtcDemo data\", init);\r\n    }\r\n    isInitiator = false;\r\n\r\n    // Set INFO libjingle logging.\r\n    // NOTE: this _must_ happen while |factory| is alive!\r\n    Logging.enableLogToDebugOutput(Logging.Severity.LS_INFO);\r\n\r\n    List<String> mediaStreamLabels = Collections.singletonList(\"ARDAMS\");\r\n    if (isVideoCallEnabled()) {\r\n      peerConnection.addTrack(createVideoTrack(videoCapturer), mediaStreamLabels);\r\n      // We can add the renderers right away because we don't need to wait for an\r\n      // answer to get the remote track.\r\n      remoteVideoTrack = getRemoteVideoTrack();\r\n      remoteVideoTrack.setEnabled(renderVideo);\r\n      for (VideoSink remoteSink : remoteSinks) {\r\n        remoteVideoTrack.addSink(remoteSink);\r\n      }\r\n    }\r\n    peerConnection.addTrack(createAudioTrack(), mediaStreamLabels);\r\n    if (isVideoCallEnabled()) {\r\n      findVideoSender();\r\n    }\r\n\r\n    if (peerConnectionParameters.aecDump) {\r\n      try {\r\n        ParcelFileDescriptor aecDumpFileDescriptor =\r\n            ParcelFileDescriptor.open(new File(Environment.getExternalStorageDirectory().getPath()\r\n                                          + File.separator + \"Download/audio.aecdump\"),\r\n                ParcelFileDescriptor.MODE_READ_WRITE | ParcelFileDescriptor.MODE_CREATE\r\n                    | ParcelFileDescriptor.MODE_TRUNCATE);\r\n        factory.startAecDump(aecDumpFileDescriptor.detachFd(), -1);\r\n      } catch (IOException e) {\r\n        Log.e(TAG, \"Can not open aecdump file\", e);\r\n      }\r\n    }\r\n\r\n    if (saveRecordedAudioToFile != null) {\r\n      if (saveRecordedAudioToFile.start()) {\r\n        Log.d(TAG, \"Recording input audio to file is activated\");\r\n      }\r\n    }\r\n    Log.d(TAG, \"Peer connection created.\");\r\n  }\r\n\r\n  private File createRtcEventLogOutputFile() {\r\n    DateFormat dateFormat = new SimpleDateFormat(\"yyyyMMdd_hhmm_ss\", Locale.getDefault());\r\n    Date date = new Date();\r\n    final String outputFileName = \"event_log_\" + dateFormat.format(date) + \".log\";\r\n    return new File(\r\n        appContext.getDir(RTCEVENTLOG_OUTPUT_DIR_NAME, Context.MODE_PRIVATE), outputFileName);\r\n  }\r\n\r\n  private void maybeCreateAndStartRtcEventLog() {\r\n    if (appContext == null || peerConnection == null) {\r\n      return;\r\n    }\r\n    if (!peerConnectionParameters.enableRtcEventLog) {\r\n      Log.d(TAG, \"RtcEventLog is disabled.\");\r\n      return;\r\n    }\r\n    rtcEventLog = new RtcEventLog(peerConnection);\r\n    rtcEventLog.start(createRtcEventLogOutputFile());\r\n  }\r\n\r\n  private void closeInternal() {\r\n    if (factory != null && peerConnectionParameters.aecDump) {\r\n      factory.stopAecDump();\r\n    }\r\n    Log.d(TAG, \"Closing peer connection.\");\r\n    statsTimer.cancel();\r\n    if (dataChannel != null) {\r\n      dataChannel.dispose();\r\n      dataChannel = null;\r\n    }\r\n    if (rtcEventLog != null) {\r\n      // RtcEventLog should stop before the peer connection is disposed.\r\n      rtcEventLog.stop();\r\n      rtcEventLog = null;\r\n    }\r\n    if (peerConnection != null) {\r\n      peerConnection.dispose();\r\n      peerConnection = null;\r\n    }\r\n    Log.d(TAG, \"Closing audio source.\");\r\n    if (audioSource != null) {\r\n      audioSource.dispose();\r\n      audioSource = null;\r\n    }\r\n    Log.d(TAG, \"Stopping capture.\");\r\n    if (videoCapturer != null) {\r\n      try {\r\n        videoCapturer.stopCapture();\r\n      } catch (InterruptedException e) {\r\n        throw new RuntimeException(e);\r\n      }\r\n      videoCapturerStopped = true;\r\n      videoCapturer.dispose();\r\n      videoCapturer = null;\r\n    }\r\n    Log.d(TAG, \"Closing video source.\");\r\n    if (videoSource != null) {\r\n      videoSource.dispose();\r\n      videoSource = null;\r\n    }\r\n    if (surfaceTextureHelper != null) {\r\n      surfaceTextureHelper.dispose();\r\n      surfaceTextureHelper = null;\r\n    }\r\n    if (saveRecordedAudioToFile != null) {\r\n      Log.d(TAG, \"Closing audio file for recorded input audio.\");\r\n      saveRecordedAudioToFile.stop();\r\n      saveRecordedAudioToFile = null;\r\n    }\r\n    localRender = null;\r\n    remoteSinks = null;\r\n    Log.d(TAG, \"Closing peer connection factory.\");\r\n    if (factory != null) {\r\n      factory.dispose();\r\n      factory = null;\r\n    }\r\n    rootEglBase.release();\r\n    Log.d(TAG, \"Closing peer connection done.\");\r\n    events.onPeerConnectionClosed();\r\n    PeerConnectionFactory.stopInternalTracingCapture();\r\n    PeerConnectionFactory.shutdownInternalTracer();\r\n  }\r\n\r\n  public boolean isHDVideo() {\r\n    return isVideoCallEnabled() && videoWidth * videoHeight >= 1280 * 720;\r\n  }\r\n\r\n  @SuppressWarnings(\"deprecation\") // TODO(sakal): getStats is deprecated.\r\n  private void getStats() {\r\n    if (peerConnection == null || isError) {\r\n      return;\r\n    }\r\n    boolean success = peerConnection.getStats(new StatsObserver() {\r\n      @Override\r\n      public void onComplete(final StatsReport[] reports) {\r\n        events.onPeerConnectionStatsReady(reports);\r\n      }\r\n    }, null);\r\n    if (!success) {\r\n      Log.e(TAG, \"getStats() returns false!\");\r\n    }\r\n  }\r\n\r\n  public void enableStatsEvents(boolean enable, int periodMs) {\r\n    if (enable) {\r\n      try {\r\n        statsTimer.schedule(new TimerTask() {\r\n          @Override\r\n          public void run() {\r\n            executor.execute(() -> getStats());\r\n          }\r\n        }, 0, periodMs);\r\n      } catch (Exception e) {\r\n        Log.e(TAG, \"Can not schedule statistics timer\", e);\r\n      }\r\n    } else {\r\n      statsTimer.cancel();\r\n    }\r\n  }\r\n\r\n  public void setAudioEnabled(final boolean enable) {\r\n    executor.execute(() -> {\r\n      enableAudio = enable;\r\n      if (localAudioTrack != null) {\r\n        localAudioTrack.setEnabled(enableAudio);\r\n      }\r\n    });\r\n  }\r\n\r\n  public void setVideoEnabled(final boolean enable) {\r\n    executor.execute(() -> {\r\n      renderVideo = enable;\r\n      if (localVideoTrack != null) {\r\n        localVideoTrack.setEnabled(renderVideo);\r\n      }\r\n      if (remoteVideoTrack != null) {\r\n        remoteVideoTrack.setEnabled(renderVideo);\r\n      }\r\n    });\r\n  }\r\n\r\n  public void createOffer() {\r\n    executor.execute(() -> {\r\n      if (peerConnection != null && !isError) {\r\n        Log.d(TAG, \"PC Create OFFER\");\r\n        isInitiator = true;\r\n        peerConnection.createOffer(sdpObserver, sdpMediaConstraints);\r\n      }\r\n    });\r\n  }\r\n\r\n  public void createAnswer() {\r\n    executor.execute(() -> {\r\n      if (peerConnection != null && !isError) {\r\n        Log.d(TAG, \"PC create ANSWER\");\r\n        isInitiator = false;\r\n        peerConnection.createAnswer(sdpObserver, sdpMediaConstraints);\r\n      }\r\n    });\r\n  }\r\n\r\n  public void addRemoteIceCandidate(final IceCandidate candidate) {\r\n    executor.execute(() -> {\r\n      if (peerConnection != null && !isError) {\r\n        if (queuedRemoteCandidates != null) {\r\n          queuedRemoteCandidates.add(candidate);\r\n        } else {\r\n          peerConnection.addIceCandidate(candidate);\r\n        }\r\n      }\r\n    });\r\n  }\r\n\r\n  public void removeRemoteIceCandidates(final IceCandidate[] candidates) {\r\n    executor.execute(() -> {\r\n      if (peerConnection == null || isError) {\r\n        return;\r\n      }\r\n      // Drain the queued remote candidates if there is any so that\r\n      // they are processed in the proper order.\r\n      drainCandidates();\r\n      peerConnection.removeIceCandidates(candidates);\r\n    });\r\n  }\r\n\r\n  public void setRemoteDescription(final SessionDescription sdp) {\r\n    executor.execute(() -> {\r\n      if (peerConnection == null || isError) {\r\n        return;\r\n      }\r\n      String sdpDescription = sdp.description;\r\n      if (preferIsac) {\r\n        sdpDescription = preferCodec(sdpDescription, AUDIO_CODEC_ISAC, true);\r\n      }\r\n      if (isVideoCallEnabled()) {\r\n        sdpDescription =\r\n            preferCodec(sdpDescription, getSdpVideoCodecName(peerConnectionParameters), false);\r\n      }\r\n      if (peerConnectionParameters.audioStartBitrate > 0) {\r\n        sdpDescription = setStartBitrate(\r\n            AUDIO_CODEC_OPUS, false, sdpDescription, peerConnectionParameters.audioStartBitrate);\r\n      }\r\n      Log.d(TAG, \"Set remote SDP.\");\r\n      SessionDescription sdpRemote = new SessionDescription(sdp.type, sdpDescription);\r\n      peerConnection.setRemoteDescription(sdpObserver, sdpRemote);\r\n    });\r\n  }\r\n\r\n  public void stopVideoSource() {\r\n    executor.execute(() -> {\r\n      if (videoCapturer != null && !videoCapturerStopped) {\r\n        Log.d(TAG, \"Stop video source.\");\r\n        try {\r\n          videoCapturer.stopCapture();\r\n        } catch (InterruptedException e) {\r\n        }\r\n        videoCapturerStopped = true;\r\n      }\r\n    });\r\n  }\r\n\r\n  public void startVideoSource() {\r\n    executor.execute(() -> {\r\n      if (videoCapturer != null && videoCapturerStopped) {\r\n        Log.d(TAG, \"Restart video source.\");\r\n        videoCapturer.startCapture(videoWidth, videoHeight, videoFps);\r\n        videoCapturerStopped = false;\r\n      }\r\n    });\r\n  }\r\n\r\n  public void setVideoMaxBitrate(@Nullable final Integer maxBitrateKbps) {\r\n    executor.execute(() -> {\r\n      if (peerConnection == null || localVideoSender == null || isError) {\r\n        return;\r\n      }\r\n      Log.d(TAG, \"Requested max video bitrate: \" + maxBitrateKbps);\r\n      if (localVideoSender == null) {\r\n        Log.w(TAG, \"Sender is not ready.\");\r\n        return;\r\n      }\r\n\r\n      RtpParameters parameters = localVideoSender.getParameters();\r\n      if (parameters.encodings.size() == 0) {\r\n        Log.w(TAG, \"RtpParameters are not ready.\");\r\n        return;\r\n      }\r\n\r\n      for (RtpParameters.Encoding encoding : parameters.encodings) {\r\n        // Null value means no limit.\r\n        encoding.maxBitrateBps = maxBitrateKbps == null ? null : maxBitrateKbps * BPS_IN_KBPS;\r\n      }\r\n      if (!localVideoSender.setParameters(parameters)) {\r\n        Log.e(TAG, \"RtpSender.setParameters failed.\");\r\n      }\r\n      Log.d(TAG, \"Configured max video bitrate to: \" + maxBitrateKbps);\r\n    });\r\n  }\r\n\r\n  private void reportError(final String errorMessage) {\r\n    Log.e(TAG, \"Peerconnection error: \" + errorMessage);\r\n    executor.execute(() -> {\r\n      if (!isError) {\r\n        events.onPeerConnectionError(errorMessage);\r\n        isError = true;\r\n      }\r\n    });\r\n  }\r\n\r\n  @Nullable\r\n  private AudioTrack createAudioTrack() {\r\n    audioSource = factory.createAudioSource(audioConstraints);\r\n    localAudioTrack = factory.createAudioTrack(AUDIO_TRACK_ID, audioSource);\r\n    localAudioTrack.setEnabled(enableAudio);\r\n    return localAudioTrack;\r\n  }\r\n\r\n  @Nullable\r\n  private VideoTrack createVideoTrack(VideoCapturer capturer) {\r\n    surfaceTextureHelper =\r\n        SurfaceTextureHelper.create(\"CaptureThread\", rootEglBase.getEglBaseContext());\r\n    videoSource = factory.createVideoSource(capturer.isScreencast());\r\n    capturer.initialize(surfaceTextureHelper, appContext, videoSource.getCapturerObserver());\r\n    capturer.startCapture(videoWidth, videoHeight, videoFps);\r\n\r\n    localVideoTrack = factory.createVideoTrack(VIDEO_TRACK_ID, videoSource);\r\n    localVideoTrack.setEnabled(renderVideo);\r\n    localVideoTrack.addSink(localRender);\r\n    return localVideoTrack;\r\n  }\r\n\r\n  private void findVideoSender() {\r\n    for (RtpSender sender : peerConnection.getSenders()) {\r\n      if (sender.track() != null) {\r\n        String trackType = sender.track().kind();\r\n        if (trackType.equals(VIDEO_TRACK_TYPE)) {\r\n          Log.d(TAG, \"Found video sender.\");\r\n          localVideoSender = sender;\r\n        }\r\n      }\r\n    }\r\n  }\r\n\r\n  // Returns the remote VideoTrack, assuming there is only one.\r\n  private @Nullable VideoTrack getRemoteVideoTrack() {\r\n    for (RtpTransceiver transceiver : peerConnection.getTransceivers()) {\r\n      MediaStreamTrack track = transceiver.getReceiver().track();\r\n      if (track instanceof VideoTrack) {\r\n        return (VideoTrack) track;\r\n      }\r\n    }\r\n    return null;\r\n  }\r\n\r\n  private static String getSdpVideoCodecName(PeerConnectionParameters parameters) {\r\n    switch (parameters.videoCodec) {\r\n      case VIDEO_CODEC_VP8:\r\n        return VIDEO_CODEC_VP8;\r\n      case VIDEO_CODEC_VP9:\r\n        return VIDEO_CODEC_VP9;\r\n      case VIDEO_CODEC_H264_HIGH:\r\n      case VIDEO_CODEC_H264_BASELINE:\r\n        return VIDEO_CODEC_H264;\r\n      default:\r\n        return VIDEO_CODEC_VP8;\r\n    }\r\n  }\r\n\r\n  private static String getFieldTrials(PeerConnectionParameters peerConnectionParameters) {\r\n    String fieldTrials = \"\";\r\n    if (peerConnectionParameters.videoFlexfecEnabled) {\r\n      fieldTrials += VIDEO_FLEXFEC_FIELDTRIAL;\r\n      Log.d(TAG, \"Enable FlexFEC field trial.\");\r\n    }\r\n    fieldTrials += VIDEO_VP8_INTEL_HW_ENCODER_FIELDTRIAL;\r\n    if (peerConnectionParameters.disableWebRtcAGCAndHPF) {\r\n      fieldTrials += DISABLE_WEBRTC_AGC_FIELDTRIAL;\r\n      Log.d(TAG, \"Disable WebRTC AGC field trial.\");\r\n    }\r\n    return fieldTrials;\r\n  }\r\n\r\n  @SuppressWarnings(\"StringSplitter\")\r\n  private static String setStartBitrate(\r\n      String codec, boolean isVideoCodec, String sdpDescription, int bitrateKbps) {\r\n    String[] lines = sdpDescription.split(\"\\r\\n\");\r\n    int rtpmapLineIndex = -1;\r\n    boolean sdpFormatUpdated = false;\r\n    String codecRtpMap = null;\r\n    // Search for codec rtpmap in format\r\n    // a=rtpmap:<payload type> <encoding name>/<clock rate> [/<encoding parameters>]\r\n    String regex = \"^a=rtpmap:(\\\\d+) \" + codec + \"(/\\\\d+)+[\\r]?$\";\r\n    Pattern codecPattern = Pattern.compile(regex);\r\n    for (int i = 0; i < lines.length; i++) {\r\n      Matcher codecMatcher = codecPattern.matcher(lines[i]);\r\n      if (codecMatcher.matches()) {\r\n        codecRtpMap = codecMatcher.group(1);\r\n        rtpmapLineIndex = i;\r\n        break;\r\n      }\r\n    }\r\n    if (codecRtpMap == null) {\r\n      Log.w(TAG, \"No rtpmap for \" + codec + \" codec\");\r\n      return sdpDescription;\r\n    }\r\n    Log.d(TAG, \"Found \" + codec + \" rtpmap \" + codecRtpMap + \" at \" + lines[rtpmapLineIndex]);\r\n\r\n    // Check if a=fmtp string already exist in remote SDP for this codec and\r\n    // update it with new bitrate parameter.\r\n    regex = \"^a=fmtp:\" + codecRtpMap + \" \\\\w+=\\\\d+.*[\\r]?$\";\r\n    codecPattern = Pattern.compile(regex);\r\n    for (int i = 0; i < lines.length; i++) {\r\n      Matcher codecMatcher = codecPattern.matcher(lines[i]);\r\n      if (codecMatcher.matches()) {\r\n        Log.d(TAG, \"Found \" + codec + \" \" + lines[i]);\r\n        if (isVideoCodec) {\r\n          lines[i] += \"; \" + VIDEO_CODEC_PARAM_START_BITRATE + \"=\" + bitrateKbps;\r\n        } else {\r\n          lines[i] += \"; \" + AUDIO_CODEC_PARAM_BITRATE + \"=\" + (bitrateKbps * 1000);\r\n        }\r\n        Log.d(TAG, \"Update remote SDP line: \" + lines[i]);\r\n        sdpFormatUpdated = true;\r\n        break;\r\n      }\r\n    }\r\n\r\n    StringBuilder newSdpDescription = new StringBuilder();\r\n    for (int i = 0; i < lines.length; i++) {\r\n      newSdpDescription.append(lines[i]).append(\"\\r\\n\");\r\n      // Append new a=fmtp line if no such line exist for a codec.\r\n      if (!sdpFormatUpdated && i == rtpmapLineIndex) {\r\n        String bitrateSet;\r\n        if (isVideoCodec) {\r\n          bitrateSet =\r\n              \"a=fmtp:\" + codecRtpMap + \" \" + VIDEO_CODEC_PARAM_START_BITRATE + \"=\" + bitrateKbps;\r\n        } else {\r\n          bitrateSet = \"a=fmtp:\" + codecRtpMap + \" \" + AUDIO_CODEC_PARAM_BITRATE + \"=\"\r\n              + (bitrateKbps * 1000);\r\n        }\r\n        Log.d(TAG, \"Add remote SDP line: \" + bitrateSet);\r\n        newSdpDescription.append(bitrateSet).append(\"\\r\\n\");\r\n      }\r\n    }\r\n    return newSdpDescription.toString();\r\n  }\r\n\r\n  /** Returns the line number containing \"m=audio|video\", or -1 if no such line exists. */\r\n  private static int findMediaDescriptionLine(boolean isAudio, String[] sdpLines) {\r\n    final String mediaDescription = isAudio ? \"m=audio \" : \"m=video \";\r\n    for (int i = 0; i < sdpLines.length; ++i) {\r\n      if (sdpLines[i].startsWith(mediaDescription)) {\r\n        return i;\r\n      }\r\n    }\r\n    return -1;\r\n  }\r\n\r\n  private static String joinString(\r\n      Iterable<? extends CharSequence> s, String delimiter, boolean delimiterAtEnd) {\r\n    Iterator<? extends CharSequence> iter = s.iterator();\r\n    if (!iter.hasNext()) {\r\n      return \"\";\r\n    }\r\n    StringBuilder buffer = new StringBuilder(iter.next());\r\n    while (iter.hasNext()) {\r\n      buffer.append(delimiter).append(iter.next());\r\n    }\r\n    if (delimiterAtEnd) {\r\n      buffer.append(delimiter);\r\n    }\r\n    return buffer.toString();\r\n  }\r\n\r\n  private static @Nullable String movePayloadTypesToFront(\r\n      List<String> preferredPayloadTypes, String mLine) {\r\n    // The format of the media description line should be: m=<media> <port> <proto> <fmt> ...\r\n    final List<String> origLineParts = Arrays.asList(mLine.split(\" \"));\r\n    if (origLineParts.size() <= 3) {\r\n      Log.e(TAG, \"Wrong SDP media description format: \" + mLine);\r\n      return null;\r\n    }\r\n    final List<String> header = origLineParts.subList(0, 3);\r\n    final List<String> unpreferredPayloadTypes =\r\n        new ArrayList<>(origLineParts.subList(3, origLineParts.size()));\r\n    unpreferredPayloadTypes.removeAll(preferredPayloadTypes);\r\n    // Reconstruct the line with |preferredPayloadTypes| moved to the beginning of the payload\r\n    // types.\r\n    final List<String> newLineParts = new ArrayList<>();\r\n    newLineParts.addAll(header);\r\n    newLineParts.addAll(preferredPayloadTypes);\r\n    newLineParts.addAll(unpreferredPayloadTypes);\r\n    return joinString(newLineParts, \" \", false /* delimiterAtEnd */);\r\n  }\r\n\r\n  private static String preferCodec(String sdpDescription, String codec, boolean isAudio) {\r\n    final String[] lines = sdpDescription.split(\"\\r\\n\");\r\n    final int mLineIndex = findMediaDescriptionLine(isAudio, lines);\r\n    if (mLineIndex == -1) {\r\n      Log.w(TAG, \"No mediaDescription line, so can't prefer \" + codec);\r\n      return sdpDescription;\r\n    }\r\n    // A list with all the payload types with name |codec|. The payload types are integers in the\r\n    // range 96-127, but they are stored as strings here.\r\n    final List<String> codecPayloadTypes = new ArrayList<>();\r\n    // a=rtpmap:<payload type> <encoding name>/<clock rate> [/<encoding parameters>]\r\n    final Pattern codecPattern = Pattern.compile(\"^a=rtpmap:(\\\\d+) \" + codec + \"(/\\\\d+)+[\\r]?$\");\r\n    for (String line : lines) {\r\n      Matcher codecMatcher = codecPattern.matcher(line);\r\n      if (codecMatcher.matches()) {\r\n        codecPayloadTypes.add(codecMatcher.group(1));\r\n      }\r\n    }\r\n    if (codecPayloadTypes.isEmpty()) {\r\n      Log.w(TAG, \"No payload types with name \" + codec);\r\n      return sdpDescription;\r\n    }\r\n\r\n    final String newMLine = movePayloadTypesToFront(codecPayloadTypes, lines[mLineIndex]);\r\n    if (newMLine == null) {\r\n      return sdpDescription;\r\n    }\r\n    Log.d(TAG, \"Change media description from: \" + lines[mLineIndex] + \" to \" + newMLine);\r\n    lines[mLineIndex] = newMLine;\r\n    return joinString(Arrays.asList(lines), \"\\r\\n\", true /* delimiterAtEnd */);\r\n  }\r\n\r\n  private void drainCandidates() {\r\n    if (queuedRemoteCandidates != null) {\r\n      Log.d(TAG, \"Add \" + queuedRemoteCandidates.size() + \" remote candidates\");\r\n      for (IceCandidate candidate : queuedRemoteCandidates) {\r\n        peerConnection.addIceCandidate(candidate);\r\n      }\r\n      queuedRemoteCandidates = null;\r\n    }\r\n  }\r\n\r\n  private void switchCameraInternal() {\r\n    if (videoCapturer instanceof CameraVideoCapturer) {\r\n      if (!isVideoCallEnabled() || isError) {\r\n        Log.e(TAG,\r\n            \"Failed to switch camera. Video: \" + isVideoCallEnabled() + \". Error : \" + isError);\r\n        return; // No video is sent or only one camera is available or error happened.\r\n      }\r\n      Log.d(TAG, \"Switch camera\");\r\n      CameraVideoCapturer cameraVideoCapturer = (CameraVideoCapturer) videoCapturer;\r\n      cameraVideoCapturer.switchCamera(null);\r\n    } else {\r\n      Log.d(TAG, \"Will not switch camera, video caputurer is not a camera\");\r\n    }\r\n  }\r\n\r\n  public void switchCamera() {\r\n    executor.execute(this ::switchCameraInternal);\r\n  }\r\n\r\n  public void changeCaptureFormat(final int width, final int height, final int framerate) {\r\n    executor.execute(() -> changeCaptureFormatInternal(width, height, framerate));\r\n  }\r\n\r\n  private void changeCaptureFormatInternal(int width, int height, int framerate) {\r\n    if (!isVideoCallEnabled() || isError || videoCapturer == null) {\r\n      Log.e(TAG,\r\n          \"Failed to change capture format. Video: \" + isVideoCallEnabled()\r\n              + \". Error : \" + isError);\r\n      return;\r\n    }\r\n    Log.d(TAG, \"changeCaptureFormat: \" + width + \"x\" + height + \"@\" + framerate);\r\n    videoSource.adaptOutputFormat(width, height, framerate);\r\n  }\r\n\r\n  // Implementation detail: observe ICE & stream changes and react accordingly.\r\n  private class PCObserver implements PeerConnection.Observer {\r\n    @Override\r\n    public void onIceCandidate(final IceCandidate candidate) {\r\n      executor.execute(() -> events.onIceCandidate(candidate));\r\n    }\r\n\r\n    @Override\r\n    public void onIceCandidatesRemoved(final IceCandidate[] candidates) {\r\n      executor.execute(() -> events.onIceCandidatesRemoved(candidates));\r\n    }\r\n\r\n    @Override\r\n    public void onSignalingChange(PeerConnection.SignalingState newState) {\r\n      Log.d(TAG, \"SignalingState: \" + newState);\r\n    }\r\n\r\n    @Override\r\n    public void onIceConnectionChange(final IceConnectionState newState) {\r\n      executor.execute(() -> {\r\n        Log.d(TAG, \"IceConnectionState: \" + newState);\r\n        if (newState == IceConnectionState.CONNECTED) {\r\n          events.onIceConnected();\r\n        } else if (newState == IceConnectionState.DISCONNECTED) {\r\n          events.onIceDisconnected();\r\n        } else if (newState == IceConnectionState.FAILED) {\r\n          reportError(\"ICE connection failed.\");\r\n        }\r\n      });\r\n    }\r\n\r\n    @Override\r\n    public void onIceGatheringChange(PeerConnection.IceGatheringState newState) {\r\n      Log.d(TAG, \"IceGatheringState: \" + newState);\r\n    }\r\n\r\n    @Override\r\n    public void onIceConnectionReceivingChange(boolean receiving) {\r\n      Log.d(TAG, \"IceConnectionReceiving changed to \" + receiving);\r\n    }\r\n\r\n    @Override\r\n    public void onAddStream(final MediaStream stream) {}\r\n\r\n    @Override\r\n    public void onRemoveStream(final MediaStream stream) {}\r\n\r\n    @Override\r\n    public void onDataChannel(final DataChannel dc) {\r\n      Log.d(TAG, \"New Data channel \" + dc.label());\r\n\r\n      if (!dataChannelEnabled)\r\n        return;\r\n\r\n      dc.registerObserver(new DataChannel.Observer() {\r\n        @Override\r\n        public void onBufferedAmountChange(long previousAmount) {\r\n          Log.d(TAG, \"Data channel buffered amount changed: \" + dc.label() + \": \" + dc.state());\r\n        }\r\n\r\n        @Override\r\n        public void onStateChange() {\r\n          Log.d(TAG, \"Data channel state changed: \" + dc.label() + \": \" + dc.state());\r\n        }\r\n\r\n        @Override\r\n        public void onMessage(final DataChannel.Buffer buffer) {\r\n          if (buffer.binary) {\r\n            Log.d(TAG, \"Received binary msg over \" + dc);\r\n            return;\r\n          }\r\n          ByteBuffer data = buffer.data;\r\n          final byte[] bytes = new byte[data.capacity()];\r\n          data.get(bytes);\r\n          String strData = new String(bytes, Charset.forName(\"UTF-8\"));\r\n          Log.d(TAG, \"Got msg: \" + strData + \" over \" + dc);\r\n        }\r\n      });\r\n    }\r\n\r\n    @Override\r\n    public void onRenegotiationNeeded() {\r\n      // No need to do anything; AppRTC follows a pre-agreed-upon\r\n      // signaling/negotiation protocol.\r\n    }\r\n\r\n    @Override\r\n    public void onAddTrack(final RtpReceiver receiver, final MediaStream[] mediaStreams) {}\r\n  }\r\n\r\n  // Implementation detail: handle offer creation/signaling and answer setting,\r\n  // as well as adding remote ICE candidates once the answer SDP is set.\r\n  private class SDPObserver implements SdpObserver {\r\n    @Override\r\n    public void onCreateSuccess(final SessionDescription origSdp) {\r\n      if (localSdp != null) {\r\n        reportError(\"Multiple SDP create.\");\r\n        return;\r\n      }\r\n      String sdpDescription = origSdp.description;\r\n      if (preferIsac) {\r\n        sdpDescription = preferCodec(sdpDescription, AUDIO_CODEC_ISAC, true);\r\n      }\r\n      if (isVideoCallEnabled()) {\r\n        sdpDescription =\r\n            preferCodec(sdpDescription, getSdpVideoCodecName(peerConnectionParameters), false);\r\n      }\r\n      final SessionDescription sdp = new SessionDescription(origSdp.type, sdpDescription);\r\n      localSdp = sdp;\r\n      executor.execute(() -> {\r\n        if (peerConnection != null && !isError) {\r\n          Log.d(TAG, \"Set local SDP from \" + sdp.type);\r\n          peerConnection.setLocalDescription(sdpObserver, sdp);\r\n        }\r\n      });\r\n    }\r\n\r\n    @Override\r\n    public void onSetSuccess() {\r\n      executor.execute(() -> {\r\n        if (peerConnection == null || isError) {\r\n          return;\r\n        }\r\n        if (isInitiator) {\r\n          // For offering peer connection we first create offer and set\r\n          // local SDP, then after receiving answer set remote SDP.\r\n          if (peerConnection.getRemoteDescription() == null) {\r\n            // We've just set our local SDP so time to send it.\r\n            Log.d(TAG, \"Local SDP set succesfully\");\r\n            events.onLocalDescription(localSdp);\r\n          } else {\r\n            // We've just set remote description, so drain remote\r\n            // and send local ICE candidates.\r\n            Log.d(TAG, \"Remote SDP set succesfully\");\r\n            drainCandidates();\r\n          }\r\n        } else {\r\n          // For answering peer connection we set remote SDP and then\r\n          // create answer and set local SDP.\r\n          if (peerConnection.getLocalDescription() != null) {\r\n            // We've just set our local SDP so time to send it, drain\r\n            // remote and send local ICE candidates.\r\n            Log.d(TAG, \"Local SDP set succesfully\");\r\n            events.onLocalDescription(localSdp);\r\n            drainCandidates();\r\n          } else {\r\n            // We've just set remote SDP - do nothing for now -\r\n            // answer will be created soon.\r\n            Log.d(TAG, \"Remote SDP set succesfully\");\r\n          }\r\n        }\r\n      });\r\n    }\r\n\r\n    @Override\r\n    public void onCreateFailure(final String error) {\r\n      reportError(\"createSDP error: \" + error);\r\n    }\r\n\r\n    @Override\r\n    public void onSetFailure(final String error) {\r\n      reportError(\"setSDP error: \" + error);\r\n    }\r\n  }\r\n}\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- webrtc/src/main/java/org/appspot/apprtc/PeerConnectionClient.java	(revision bf540945d88389d00f5acde8206c98ded8cdb2e7)
+++ webrtc/src/main/java/org/appspot/apprtc/PeerConnectionClient.java	(date 1605939779078)
@@ -583,6 +583,7 @@
         .createAudioDeviceModule();
   }
 
+  //!!!! 여기 느낌 있음
   private void createMediaConstraintsInternal() {
     // Create video constraints if video call is enabled.
     if (isVideoCallEnabled()) {
@@ -668,9 +669,11 @@
 
     List<String> mediaStreamLabels = Collections.singletonList("ARDAMS");
     if (isVideoCallEnabled()) {
+
       peerConnection.addTrack(createVideoTrack(videoCapturer), mediaStreamLabels);
       // We can add the renderers right away because we don't need to wait for an
       // answer to get the remote track.
+      // 얘도 아님 for문
       remoteVideoTrack = getRemoteVideoTrack();
       remoteVideoTrack.setEnabled(renderVideo);
       for (VideoSink remoteSink : remoteSinks) {
@@ -832,6 +835,7 @@
     });
   }
 
+  // 얘도 아님
   public void setVideoEnabled(final boolean enable) {
     executor.execute(() -> {
       renderVideo = enable;
@@ -951,6 +955,7 @@
         return;
       }
 
+      //얘도 아님
       for (RtpParameters.Encoding encoding : parameters.encodings) {
         // Null value means no limit.
         encoding.maxBitrateBps = maxBitrateKbps == null ? null : maxBitrateKbps * BPS_IN_KBPS;
@@ -980,6 +985,7 @@
     return localAudioTrack;
   }
 
+  // 얘는 아님 frame 보내는 게
   @Nullable
   private VideoTrack createVideoTrack(VideoCapturer capturer) {
     surfaceTextureHelper =
@@ -994,6 +1000,7 @@
     return localVideoTrack;
   }
 
+  // 얘도 아님
   private void findVideoSender() {
     for (RtpSender sender : peerConnection.getSenders()) {
       if (sender.track() != null) {
@@ -1006,6 +1013,7 @@
     }
   }
 
+  // 얘도 아님
   // Returns the remote VideoTrack, assuming there is only one.
   private @Nullable VideoTrack getRemoteVideoTrack() {
     for (RtpTransceiver transceiver : peerConnection.getTransceivers()) {
